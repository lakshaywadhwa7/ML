{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU7-dxYMhWW9"
      },
      "source": [
        "# Get data from twitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxqPkHdAKl_L"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/Museum-Barberini/twint.git@origin/master#egg=twint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjlAxxDVKugE"
      },
      "outputs": [],
      "source": [
        "!pip install nest_asyncio -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTys1Qj8LZo8"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2j08YAtKT5e"
      },
      "outputs": [],
      "source": [
        "import twint\n",
        "import sys\n",
        "module = sys.modules[\"twint.storage.write\"]\n",
        "\n",
        "tweets = []\n",
        "\n",
        "\n",
        "def Json(obj, config):\n",
        "  tweet = obj.__dict__\n",
        "  tweets.append(tweet)\n",
        "\n",
        "module.Json = Json\n",
        "\n",
        "def getRecentTweetsForGivenTopic(topic, limit=500, language='en'):\n",
        "  global tweets\n",
        "  \n",
        "  config = twint.Config()\n",
        "  config.Search = topic\n",
        "  config.Limit = limit\n",
        "  config.Output = \"tweets.json\"\n",
        "  config.Store_json = True\n",
        "  config.Hide_output = True\n",
        "  config.Lang = language\n",
        "\n",
        "  twint.run.Search(config)\n",
        "  copied_tweets = tweets.copy()\n",
        "  tweets = []\n",
        "  print(topic,\"Done\")\n",
        "  return copied_tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr9RNdADKjte"
      },
      "outputs": [],
      "source": [
        "ipl = getRecentTweetsForGivenTopic('IPL 2022')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRwqpE_ta4gA"
      },
      "outputs": [],
      "source": [
        "!pip install emoji -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCsTy3lga2nx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import emoji\n",
        "import nltk\n",
        "nltk.download('words')\n",
        "words = set(nltk.corpus.words.words())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nAaCRYSZ08G"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Sentiment Models Results on IPL 2022.csv\")\n",
        "ipl = df['Tweets'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx-_lc1baHE6"
      },
      "outputs": [],
      "source": [
        "ipl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-h8P2GzhejJ"
      },
      "source": [
        "# Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7yUt-C_aNs2"
      },
      "outputs": [],
      "source": [
        "def cleaner(tweet):\n",
        "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
        "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
        "    tweet = \" \".join(tweet.split())\n",
        "    tweet = ''.join(c for c in tweet if c not in emoji.UNICODE_EMOJI) #Remove Emojis\n",
        "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
        "    # tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) \\\n",
        "    #      if w.lower() in words or not w.isalpha())\n",
        "    return tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6cdMvTnal5I"
      },
      "outputs": [],
      "source": [
        "tweet = ipl[7]\n",
        "tweet, cleaner(tweet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9WholxEhh45"
      },
      "source": [
        "# Setting up models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_CQbfxvL4Gk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f974bbc-0c32-4682-a761-f86c65f5f0f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████                           | 184 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 296 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 4.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece==0.1.95 -q\n",
        "!pip install transformers==4.12.3 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9WBL8cZbedm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f0ce90-a296-4c1a-bd94-8c7eddb1c5f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "mkdir: cannot create directory ‘models’: File exists\n",
            "/content/models\n",
            "/content/models/model_files\n",
            "Error: Failed to call git rev-parse --git-dir --show-toplevel: \"fatal: not a git repository (or any of the parent directories): .git\\n\"\n",
            "Git LFS initialized.\n",
            "Cloning into 'bert-base-multilingual-uncased-sentiment'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 39 (delta 14), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (39/39), done.\n",
            "Filtering content: 100% (3/3), 1.87 GiB | 64.57 MiB/s, done.\n",
            "Error: Failed to call git rev-parse --git-dir --show-toplevel: \"fatal: not a git repository (or any of the parent directories): .git\\n\"\n",
            "Git LFS initialized.\n",
            "Cloning into 'bertweet-base-sentiment-analysis'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 28 (delta 8), reused 24 (delta 7), pack-reused 0\n",
            "Unpacking objects: 100% (28/28), done.\n",
            "Filtering content: 100% (2/2), 1.00 GiB | 63.32 MiB/s, done.\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!mkdir models\n",
        "%cd models\n",
        "!mkdir model_files\n",
        "%cd model_files\n",
        "\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment\n",
        "\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis\n",
        "\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QirGS5E-dTG8"
      },
      "outputs": [],
      "source": [
        "# %cd /content/models/model_files\n",
        "# !git lfs install\n",
        "# !git clone https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbmKbC5Udpzz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a12dc43-d14d-4f2a-bd65-6c152bc95722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7wFPf_Aht_8"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TNL_ii6LGqw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import pipeline\n",
        "\n",
        "from scipy.special import softmax\n",
        "\n",
        "SENTIMENT_ANALYSIS_CONFIG = {\n",
        "    \"sentiment_model_path\": \"./models/model_files/bertweet-base-sentiment-analysis\",\n",
        "    \"sentiment_mapping\": {\"0\": \"NEGATIVE\", \"1\": \"NEUTRAL\", \"2\": \"POSITIVE\"}\n",
        "}\n",
        "\n",
        "SENTIMENT_ANALYSIS_5_CLASS_CONFIG = {\n",
        "    \"sentiment_model_path\": \"./models/model_files/bert-base-multilingual-uncased-sentiment\",\n",
        "}\n",
        "\n",
        "\n",
        "class Sentiment:\n",
        "    def __init__(self, config=SENTIMENT_ANALYSIS_CONFIG):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        print(f\"Transformers version : {transformers.__version__}\")\n",
        "        print(f\"Using device : {self.device}\")\n",
        "\n",
        "        model_dir = config[\"sentiment_model_path\"]\n",
        "        self.mapping = config[\"sentiment_mapping\"]\n",
        "        print(model_dir)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_dir).to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "        print(\"Transformer model from path %s loaded successfully\", model_dir)\n",
        "\n",
        "    def inference(self, input_text):\n",
        "        # print(f\"Received text: {input_text}\")\n",
        "        input_text = input_text.encode().decode(\"utf-8\")\n",
        "        max_length = 128\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            input_text,\n",
        "            max_length=max_length,\n",
        "            pad_to_max_length=True,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        input_ids = inputs[\"input_ids\"].to(self.device)\n",
        "        attention_mask = inputs[\"attention_mask\"].to(self.device)\n",
        "\n",
        "        predictions = self.model(input_ids, attention_mask)\n",
        "\n",
        "        prob_dict = {}\n",
        "\n",
        "        out = predictions[0][0].unsqueeze(0)\n",
        "        out = softmax(out.cpu().detach().numpy())[0]\n",
        "\n",
        "        for i, prob in enumerate(out):\n",
        "            prob_dict[self.mapping[str(i)]] = eval(str(prob))\n",
        "\n",
        "        return max(prob_dict, key=prob_dict.get)\n",
        "\n",
        "\n",
        "class Sentiment_5_Class:\n",
        "    def __init__(self, config=SENTIMENT_ANALYSIS_5_CLASS_CONFIG):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        print(f\"Transformers version : {transformers.__version__}\")\n",
        "        print(f\"Using device : {self.device}\")\n",
        "\n",
        "        model_dir = config[\"sentiment_model_path\"]\n",
        "        print(model_dir)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_dir).to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "        print(\"Transformer model from path %s loaded successfully\", model_dir)\n",
        "\n",
        "        self.classifier = pipeline('sentiment-analysis', model=self.model,\n",
        "                                   tokenizer=self.tokenizer)\n",
        "\n",
        "    def inference(self, input_text):\n",
        "        # print(f\"Received text: {input_text}\")\n",
        "        input_text = input_text.encode().decode(\"utf-8\")\n",
        "        max_length = 128\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            input_text,\n",
        "            max_length=max_length,\n",
        "            pad_to_max_length=True,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        input_ids = inputs[\"input_ids\"].to(self.device)\n",
        "        attention_mask = inputs[\"attention_mask\"].to(self.device)\n",
        "\n",
        "        predictions = self.model(input_ids, attention_mask)\n",
        "\n",
        "        prob_dict = {}\n",
        "\n",
        "        scores = predictions[0][0]\n",
        "        scores = softmax(scores.cpu().detach().numpy())\n",
        "\n",
        "        prob_dict['NEGATIVE'] = float(scores[0] + scores[1])\n",
        "        prob_dict['NEUTRAL'] = float(scores[2])\n",
        "        prob_dict['POSITIVE'] = float(scores[3] + scores[4])\n",
        "\n",
        "        return max(prob_dict, key=prob_dict.get)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhYBnZB7LrbQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3619a44c-bbd8-4d8a-9daa-ee2987dc9da2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers version : 4.12.3\n",
            "Using device : cuda\n",
            "./models/model_files/bertweet-base-sentiment-analysis\n",
            "Transformer model from path %s loaded successfully ./models/model_files/bertweet-base-sentiment-analysis\n"
          ]
        }
      ],
      "source": [
        "sa1 = Sentiment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Jkjv5vEN6st",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a71a5e-01f6-4eb3-a21e-5e9f05fd9c62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers version : 4.12.3\n",
            "Using device : cuda\n",
            "./models/model_files/bert-base-multilingual-uncased-sentiment\n",
            "Transformer model from path %s loaded successfully ./models/model_files/bert-base-multilingual-uncased-sentiment\n"
          ]
        }
      ],
      "source": [
        "sa2 = Sentiment_5_Class()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGV6sD_aQQYj"
      },
      "outputs": [],
      "source": [
        "sa1.inference(ipl[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyJNM09VfXIZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "b3c548b2-d3c7-4c1e-bd32-25e1511bc051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "sa1.inference(\"Congratulations Gujarat Titans!   The 2022 Indian Premier League final was played on 29 May 2022 at the Narendra Modi Stadium in Ahmedabad.  GT beat RR by 7 wickets in the final.  #gt #congratulations #gujarat #ipl #narendramodi #stadium #ahmedabad #t20 #win #winner #tournament  https://t.co/vlB4GGy3CV\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfjZYC1Aeuhv"
      },
      "outputs": [],
      "source": [
        "results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8v4DVrVfr8B"
      },
      "outputs": [],
      "source": [
        "cleaned_tweets = [cleaner(tweet) for tweet in ipl]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAqxnCiBijES"
      },
      "outputs": [],
      "source": [
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PZ9YdcuQGT8"
      },
      "outputs": [],
      "source": [
        "s = time()\n",
        "df['BERTweet_clean'] = [sa1.inference(tweet) for tweet in cleaned_tweets]\n",
        "f = time()\n",
        "\n",
        "print(\"Time taken: \", f-s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DultIb9Be6_U"
      },
      "outputs": [],
      "source": [
        "s = time()\n",
        "df['bert-base-multilingual-uncased-sentiment_clean'] = [sa2.inference(tweet) for tweet in cleaned_tweets]\n",
        "f = time()\n",
        "\n",
        "print(\"Time taken: \", f-s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuUn-8-jfBx7"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Midc-UHZmej1"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"results.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avzlLenzhqY4"
      },
      "source": [
        "## Roberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MO7dzwFUmsqR"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "import csv\n",
        "import urllib.request\n",
        "\n",
        "task='sentiment'\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "\n",
        "# download label mapping\n",
        "# labels=[]\n",
        "# mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
        "# with urllib.request.urlopen(mapping_link) as f:\n",
        "#     html = f.read().decode('utf-8').split(\"\\n\")\n",
        "#     csvreader = csv.reader(html, delimiter='\\t')\n",
        "# labels = [row[1] for row in csvreader if len(row) > 1]\n",
        "labels = ['NEGATIVE', 'NEUTRAL', 'POSITIVE']\n",
        "\n",
        "# PT\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "model.save_pretrained(MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-k1R088nJXH"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxnj1678mzRQ"
      },
      "outputs": [],
      "source": [
        "def roberta_inference(text):\n",
        "  print(f\"Recieved text : {text}\")\n",
        "  encoded_input = tokenizer(text, return_tensors='pt')\n",
        "  output = model(**encoded_input)\n",
        "  scores = output[0][0].detach().numpy()\n",
        "  scores = softmax(scores)\n",
        "\n",
        "\n",
        "  ranking = np.argsort(scores)\n",
        "  ranking = ranking[::-1]\n",
        "  return labels[ranking[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAWGly5En-Dz"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aehpq8IXnw7A"
      },
      "outputs": [],
      "source": [
        "s = time()\n",
        "df['twitter-roberta'] = [roberta_inference(tweet) for tweet in ipl]\n",
        "f = time()\n",
        "\n",
        "print(\"Time taken: \", f-s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6ikrsUAnaS2"
      },
      "outputs": [],
      "source": [
        "s = time()\n",
        "df['twitter-roberta_clean'] = [roberta_inference(tweet) for tweet in cleaned_tweets]\n",
        "f = time()\n",
        "\n",
        "print(\"Time taken: \", f-s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeWjOieasRgo"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQQt6oEotGy2"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhYMYGtQtLjV"
      },
      "outputs": [],
      "source": [
        "def vader_inference(text):\n",
        "  r = sid.polarity_scores(text)\n",
        "  del r['compound']\n",
        "  return max(r, key=r.get)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzkYk3gKxduA"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DKByyrrxWMJ"
      },
      "outputs": [],
      "source": [
        "s = time()\n",
        "df['VADER'] = [vader_inference(tweet) for tweet in ipl]\n",
        "f = time()\n",
        "\n",
        "print(\"Time taken: \", f-s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhHIy1g2xvAn"
      },
      "outputs": [],
      "source": [
        "s = time()\n",
        "df['VADER_clean'] = [vader_inference(tweet) for tweet in cleaned_tweets]\n",
        "f = time()\n",
        "\n",
        "print(\"Time taken: \", f-s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWMPobjWx4yS"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TssUUBOLzVUw"
      },
      "outputs": [],
      "source": [
        "df.to_excel(\"Sentiment models.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2bhlnoWQ55b"
      },
      "outputs": [],
      "source": [
        "results['Tweets'] = [i['tweet'] for i in ipl ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GPNtx4xRGNH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d99wT5KzRJnq"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(results).to_csv(\"Sentiment Models Results on IPL 2022.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLt2csPjRM8O"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrxSk1mEhzDt"
      },
      "source": [
        "# [RETWEET](https://www.kaggle.com/datasets/soroosharasteh/retweet)\n",
        "Dataset of Tweets and overall predominant sentiment of their Replies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4U2tToAiYlG"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luhX2Lqgh7sq"
      },
      "outputs": [],
      "source": [
        "def get_tweet_from_id(id):\n",
        "  print(id)\n",
        "  url = f\"https://publish.twitter.com/oembed?dnt=true&omit_script=true&url=https://mobile.twitter.com/i/status/{id}\"\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "    \n",
        "    text = r.json()['html']\n",
        "    tweet_url = r.json()['url']\n",
        "\n",
        "    text = text.split(\"</p\")[0]\n",
        "    text = text.split(\"pic.twitter.com\")[0]\n",
        "    \n",
        "    return text, tweet_url\n",
        "\n",
        "  except Exception as e:\n",
        "    print(id, e)\n",
        "    return '', ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCo8LPOri_RW"
      },
      "outputs": [],
      "source": [
        "get_tweet_from_id(1163887022504906752)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw_N9dBDjBNz"
      },
      "outputs": [],
      "source": [
        "get_tweet_from_id(1179631197405642753)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9x7-mXbjdIK"
      },
      "outputs": [],
      "source": [
        "def clean_html(html_text):\n",
        "  # CLEANR = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
        "  # cleantext = re.sub(CLEANR, '', html_text)\n",
        "  # return cleantext\n",
        "  cleantext = BeautifulSoup(html_text, \"html.parser\").text\n",
        "\n",
        "  return cleantext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyJNCg2yj7dQ"
      },
      "outputs": [],
      "source": [
        "clean_html(get_tweet_from_id(1544677961777152000)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfkaTq3Wlax9"
      },
      "source": [
        "## Get training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3Gf575bj-g-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tI_Z-UhElh_p"
      },
      "outputs": [],
      "source": [
        "training_df = pd.read_csv(\"train_final_label.txt\", delimiter='\\t')\n",
        "training_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VIHXc58l9p9"
      },
      "outputs": [],
      "source": [
        "training_df['id'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L-WdeHdmNWJ"
      },
      "outputs": [],
      "source": [
        "clean_df = training_df.drop_duplicates('id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAG_QTrumDsi"
      },
      "outputs": [],
      "source": [
        "clean_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BG4K2JziqT0Z"
      },
      "outputs": [],
      "source": [
        "df1 = clean_df[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hSqgABwmLXt"
      },
      "outputs": [],
      "source": [
        "clean_df['url'] = clean_df.id.apply(get_tweet_from_id).str[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKDaXcE8pcTX"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shRtwN3qorN6"
      },
      "outputs": [],
      "source": [
        "urls = []\n",
        "html = []\n",
        "cleaned_tweets = []\n",
        "\n",
        "for id in tqdm(df1.id.values):\n",
        "  tweet, url = get_tweet_from_id(id)\n",
        "  clean_tweet = clean_html(tweet)\n",
        "\n",
        "  html.append(tweet)\n",
        "  urls.append(url)\n",
        "  cleaned_tweets.append(clean_tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37YR9UtPpe_m"
      },
      "outputs": [],
      "source": [
        "cleaned_tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-upXr8rpouA"
      },
      "outputs": [],
      "source": [
        "df1['url'] = urls\n",
        "df1['html_tweet'] = html\n",
        "df1['tweet'] = cleaned_tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXjt_VcNrOMj"
      },
      "outputs": [],
      "source": [
        "df1.to_csv(\"RETWEET Sample training data.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_-KW4xZrOwH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x990VtHD8L9G"
      },
      "source": [
        "# Training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04yP6UUU_DNE"
      },
      "outputs": [],
      "source": [
        "!pip install fasttext emoji -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cBqd3hc8NhH"
      },
      "outputs": [],
      "source": [
        "import fasttext\n",
        "import sys\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import re\n",
        "import itertools\n",
        "import emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MitiYGHK-7bm"
      },
      "outputs": [],
      "source": [
        "def load_dict_smileys():\n",
        "    \n",
        "    return {\n",
        "        \":‑)\":\"smiley\",\n",
        "        \":-]\":\"smiley\",\n",
        "        \":-3\":\"smiley\",\n",
        "        \":->\":\"smiley\",\n",
        "        \"8-)\":\"smiley\",\n",
        "        \":-}\":\"smiley\",\n",
        "        \":)\":\"smiley\",\n",
        "        \":]\":\"smiley\",\n",
        "        \":3\":\"smiley\",\n",
        "        \":>\":\"smiley\",\n",
        "        \"8)\":\"smiley\",\n",
        "        \":}\":\"smiley\",\n",
        "        \":o)\":\"smiley\",\n",
        "        \":c)\":\"smiley\",\n",
        "        \":^)\":\"smiley\",\n",
        "        \"=]\":\"smiley\",\n",
        "        \"=)\":\"smiley\",\n",
        "        \":-))\":\"smiley\",\n",
        "        \":‑D\":\"smiley\",\n",
        "        \"8‑D\":\"smiley\",\n",
        "        \"x‑D\":\"smiley\",\n",
        "        \"X‑D\":\"smiley\",\n",
        "        \":D\":\"smiley\",\n",
        "        \"8D\":\"smiley\",\n",
        "        \"xD\":\"smiley\",\n",
        "        \"XD\":\"smiley\",\n",
        "        \":‑(\":\"sad\",\n",
        "        \":‑c\":\"sad\",\n",
        "        \":‑<\":\"sad\",\n",
        "        \":‑[\":\"sad\",\n",
        "        \":(\":\"sad\",\n",
        "        \":c\":\"sad\",\n",
        "        \":<\":\"sad\",\n",
        "        \":[\":\"sad\",\n",
        "        \":-||\":\"sad\",\n",
        "        \">:[\":\"sad\",\n",
        "        \":{\":\"sad\",\n",
        "        \":@\":\"sad\",\n",
        "        \">:(\":\"sad\",\n",
        "        \":'‑(\":\"sad\",\n",
        "        \":'(\":\"sad\",\n",
        "        \":‑P\":\"playful\",\n",
        "        \"X‑P\":\"playful\",\n",
        "        \"x‑p\":\"playful\",\n",
        "        \":‑p\":\"playful\",\n",
        "        \":‑Þ\":\"playful\",\n",
        "        \":‑þ\":\"playful\",\n",
        "        \":‑b\":\"playful\",\n",
        "        \":P\":\"playful\",\n",
        "        \"XP\":\"playful\",\n",
        "        \"xp\":\"playful\",\n",
        "        \":p\":\"playful\",\n",
        "        \":Þ\":\"playful\",\n",
        "        \":þ\":\"playful\",\n",
        "        \":b\":\"playful\",\n",
        "        \"<3\":\"love\"\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJuPlBRu_HZ3"
      },
      "outputs": [],
      "source": [
        "def load_dict_contractions():\n",
        "    \n",
        "    return {\n",
        "        \"ain't\":\"is not\",\n",
        "        \"amn't\":\"am not\",\n",
        "        \"aren't\":\"are not\",\n",
        "        \"can't\":\"cannot\",\n",
        "        \"'cause\":\"because\",\n",
        "        \"couldn't\":\"could not\",\n",
        "        \"couldn't've\":\"could not have\",\n",
        "        \"could've\":\"could have\",\n",
        "        \"daren't\":\"dare not\",\n",
        "        \"daresn't\":\"dare not\",\n",
        "        \"dasn't\":\"dare not\",\n",
        "        \"didn't\":\"did not\",\n",
        "        \"doesn't\":\"does not\",\n",
        "        \"don't\":\"do not\",\n",
        "        \"e'er\":\"ever\",\n",
        "        \"em\":\"them\",\n",
        "        \"everyone's\":\"everyone is\",\n",
        "        \"finna\":\"fixing to\",\n",
        "        \"gimme\":\"give me\",\n",
        "        \"gonna\":\"going to\",\n",
        "        \"gon't\":\"go not\",\n",
        "        \"gotta\":\"got to\",\n",
        "        \"hadn't\":\"had not\",\n",
        "        \"hasn't\":\"has not\",\n",
        "        \"haven't\":\"have not\",\n",
        "        \"he'd\":\"he would\",\n",
        "        \"he'll\":\"he will\",\n",
        "        \"he's\":\"he is\",\n",
        "        \"he've\":\"he have\",\n",
        "        \"how'd\":\"how would\",\n",
        "        \"how'll\":\"how will\",\n",
        "        \"how're\":\"how are\",\n",
        "        \"how's\":\"how is\",\n",
        "        \"I'd\":\"I would\",\n",
        "        \"I'll\":\"I will\",\n",
        "        \"I'm\":\"I am\",\n",
        "        \"I'm'a\":\"I am about to\",\n",
        "        \"I'm'o\":\"I am going to\",\n",
        "        \"isn't\":\"is not\",\n",
        "        \"it'd\":\"it would\",\n",
        "        \"it'll\":\"it will\",\n",
        "        \"it's\":\"it is\",\n",
        "        \"I've\":\"I have\",\n",
        "        \"kinda\":\"kind of\",\n",
        "        \"let's\":\"let us\",\n",
        "        \"mayn't\":\"may not\",\n",
        "        \"may've\":\"may have\",\n",
        "        \"mightn't\":\"might not\",\n",
        "        \"might've\":\"might have\",\n",
        "        \"mustn't\":\"must not\",\n",
        "        \"mustn't've\":\"must not have\",\n",
        "        \"must've\":\"must have\",\n",
        "        \"needn't\":\"need not\",\n",
        "        \"ne'er\":\"never\",\n",
        "        \"o'\":\"of\",\n",
        "        \"o'er\":\"over\",\n",
        "        \"ol'\":\"old\",\n",
        "        \"oughtn't\":\"ought not\",\n",
        "        \"shalln't\":\"shall not\",\n",
        "        \"shan't\":\"shall not\",\n",
        "        \"she'd\":\"she would\",\n",
        "        \"she'll\":\"she will\",\n",
        "        \"she's\":\"she is\",\n",
        "        \"shouldn't\":\"should not\",\n",
        "        \"shouldn't've\":\"should not have\",\n",
        "        \"should've\":\"should have\",\n",
        "        \"somebody's\":\"somebody is\",\n",
        "        \"someone's\":\"someone is\",\n",
        "        \"something's\":\"something is\",\n",
        "        \"that'd\":\"that would\",\n",
        "        \"that'll\":\"that will\",\n",
        "        \"that're\":\"that are\",\n",
        "        \"that's\":\"that is\",\n",
        "        \"there'd\":\"there would\",\n",
        "        \"there'll\":\"there will\",\n",
        "        \"there're\":\"there are\",\n",
        "        \"there's\":\"there is\",\n",
        "        \"these're\":\"these are\",\n",
        "        \"they'd\":\"they would\",\n",
        "        \"they'll\":\"they will\",\n",
        "        \"they're\":\"they are\",\n",
        "        \"they've\":\"they have\",\n",
        "        \"this's\":\"this is\",\n",
        "        \"those're\":\"those are\",\n",
        "        \"'tis\":\"it is\",\n",
        "        \"'twas\":\"it was\",\n",
        "        \"wanna\":\"want to\",\n",
        "        \"wasn't\":\"was not\",\n",
        "        \"we'd\":\"we would\",\n",
        "        \"we'd've\":\"we would have\",\n",
        "        \"we'll\":\"we will\",\n",
        "        \"we're\":\"we are\",\n",
        "        \"weren't\":\"were not\",\n",
        "        \"we've\":\"we have\",\n",
        "        \"what'd\":\"what did\",\n",
        "        \"what'll\":\"what will\",\n",
        "        \"what're\":\"what are\",\n",
        "        \"what's\":\"what is\",\n",
        "        \"what've\":\"what have\",\n",
        "        \"when's\":\"when is\",\n",
        "        \"where'd\":\"where did\",\n",
        "        \"where're\":\"where are\",\n",
        "        \"where's\":\"where is\",\n",
        "        \"where've\":\"where have\",\n",
        "        \"which's\":\"which is\",\n",
        "        \"who'd\":\"who would\",\n",
        "        \"who'd've\":\"who would have\",\n",
        "        \"who'll\":\"who will\",\n",
        "        \"who're\":\"who are\",\n",
        "        \"who's\":\"who is\",\n",
        "        \"who've\":\"who have\",\n",
        "        \"why'd\":\"why did\",\n",
        "        \"why're\":\"why are\",\n",
        "        \"why's\":\"why is\",\n",
        "        \"won't\":\"will not\",\n",
        "        \"wouldn't\":\"would not\",\n",
        "        \"would've\":\"would have\",\n",
        "        \"y'all\":\"you all\",\n",
        "        \"you'd\":\"you would\",\n",
        "        \"you'll\":\"you will\",\n",
        "        \"you're\":\"you are\",\n",
        "        \"you've\":\"you have\",\n",
        "        \"Whatcha\":\"What are you\",\n",
        "        \"luv\":\"love\",\n",
        "        \"sux\":\"sucks\"\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6dv6ya__J_Y"
      },
      "outputs": [],
      "source": [
        "def strip_accents(text):\n",
        "    if 'ø' in text or  'Ø' in text:\n",
        "        #Do nothing when finding ø \n",
        "        return text   \n",
        "    text = text.encode('ascii', 'ignore')\n",
        "    text = text.decode(\"utf-8\")\n",
        "    return str(text)\n",
        "\n",
        "def tweet_cleaning_for_sentiment_analysis(tweet):    \n",
        "    \n",
        "    #Escaping HTML characters\n",
        "    tweet = BeautifulSoup(tweet).get_text()\n",
        "    #Special case not handled previously.\n",
        "    tweet = tweet.replace('\\x92',\"'\")\n",
        "    #Removal of hastags/account\n",
        "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", tweet).split())\n",
        "    #Removal of address\n",
        "    tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
        "    #Removal of Punctuation\n",
        "    tweet = ' '.join(re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=]\", \" \", tweet).split())\n",
        "    #Lower case\n",
        "    tweet = tweet.lower()\n",
        "    #CONTRACTIONS source: https://en.wikipedia.org/wiki/Contraction_%28grammar%29\n",
        "    CONTRACTIONS = load_dict_contractions()\n",
        "    tweet = tweet.replace(\"’\",\"'\")\n",
        "    words = tweet.split()\n",
        "    reformed = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    # Standardizing words\n",
        "    tweet = ''.join(''.join(s)[:2] for _, s in itertools.groupby(tweet))\n",
        "    #Deal with smileys\n",
        "    #source: https://en.wikipedia.org/wiki/List_of_emoticons\n",
        "    SMILEY = load_dict_smileys()  \n",
        "    words = tweet.split()\n",
        "    reformed = [SMILEY[word] if word in SMILEY else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    #Deal with emojis\n",
        "    tweet = emoji.demojize(tweet)\n",
        "    #Strip accents\n",
        "    tweet= strip_accents(tweet)\n",
        "    tweet = tweet.replace(\":\",\" \")\n",
        "    tweet = ' '.join(tweet.split())\n",
        "    \n",
        "    # DO NOT REMOVE STOP WORDS FOR SENTIMENT ANALYSIS - OR AT LEAST NOT NEGATIVE ONES\n",
        "\n",
        "    return tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iINsfSdH_NUk"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "# sklearn\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn import model_selection, preprocessing, metrics, linear_model, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from imblearn.over_sampling import BorderlineSMOTE, SMOTE, ADASYN, SMOTENC, RandomOverSampler\n",
        "from imblearn.under_sampling import (RandomUnderSampler, \n",
        "                                    NearMiss, \n",
        "                                    InstanceHardnessThreshold,\n",
        "                                    CondensedNearestNeighbour,\n",
        "                                    EditedNearestNeighbours,\n",
        "                                    RepeatedEditedNearestNeighbours,\n",
        "                                    AllKNN,\n",
        "                                    NeighbourhoodCleaningRule,\n",
        "                                    OneSidedSelection,\n",
        "                                    TomekLinks)\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljGjq231FTi0"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"train.tsv\", delimiter='\\t')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frL9RUuFFtC-"
      },
      "outputs": [],
      "source": [
        "data.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocTZsfjfGpy3"
      },
      "outputs": [],
      "source": [
        "data[data.label == -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAxOblsQHI3E"
      },
      "outputs": [],
      "source": [
        "# data['label'] = data['label'].replace('positive',1)\n",
        "# data['label'] = data['label'].replace('negative',-1)\n",
        "# data['label'] = data['label'].replace('neutral',0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PVZ-r-hH4Ew"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuLPyNvNHe7T"
      },
      "outputs": [],
      "source": [
        "data['cleaned_tweets'] = data.tweet.apply(tweet_cleaning_for_sentiment_analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuc5fvZBGz7d"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "  \n",
        "# Create a reference variable for Class TweetTokenizer\n",
        "tt = TweetTokenizer()\n",
        "data['tokenized_tweets'] = data['cleaned_tweets'].apply(tt.tokenize)\n",
        "data['tokenized_tweets'].head()\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpHNDJfFHxDo"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "st = nltk.PorterStemmer()\n",
        "def stemming_on_text(data):\n",
        "    text = [st.stem(word) for word in data]\n",
        "    return text\n",
        "\n",
        "data['stemmed_tweets']= data['tokenized_tweets'].apply(lambda x: stemming_on_text(x))\n",
        "#data['stemmed_tweets'].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtetvMjaIITT"
      },
      "outputs": [],
      "source": [
        "X = data.cleaned_tweets\n",
        "y = data.label\n",
        "y = np.array(y)\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 2022, stratify = y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp0zgVelIrYe"
      },
      "outputs": [],
      "source": [
        "tfidf_vect = TfidfVectorizer()\n",
        "tfidf_vect.fit(X)\n",
        "X_train_tfidf =  tfidf_vect.transform(X_train)\n",
        "X_test_tfidf =  tfidf_vect.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ka_i0jaJIzwb"
      },
      "outputs": [],
      "source": [
        "def train_model(name_of_classifier,classifier, feature_vector_train, label, feature_vector_test):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_test)\n",
        "    f1_micro = metrics.f1_score(y_test,predictions,average = 'micro')\n",
        "    f1_macro = metrics.f1_score(y_test,predictions,average = 'macro')\n",
        "    f1_weighted = metrics.f1_score(y_test,predictions,average = 'weighted')\n",
        "    accuracy = accuracy_score(y_test,predictions)\n",
        "    return pd.DataFrame({'model':[name_of_classifier],'f1_micro':[f1_micro],'f1_macro':[f1_macro],'f1_weighted':[f1_weighted],'accuracy':[accuracy]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LboVFvrjI3dE"
      },
      "outputs": [],
      "source": [
        "first = train_model('logistc_regression',LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),X_train_tfidf, y_train, X_test_tfidf)\n",
        "#print (\"LR Baseline, WordLevel TFIDF: \", accuracyORIGINAL)\n",
        "second = train_model('SVM',LinearSVC(),X_train_tfidf, y_train, X_test_tfidf)\n",
        "third =  train_model('BernoulliNB',BernoulliNB(),X_train_tfidf, y_train, X_test_tfidf)\n",
        "fourth =  train_model('MultinomialNB',MultinomialNB(),X_train_tfidf, y_train, X_test_tfidf)\n",
        "\n",
        "frames = [first,second,third,fourth]\n",
        "combined = pd.concat(frames)\n",
        "combined.reset_index(drop=True, inplace=True)\n",
        "display(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_P5uKa3I5rr"
      },
      "outputs": [],
      "source": [
        "ros = RandomOverSampler(random_state=777)\n",
        "ros_X_train_tfidf, ros_y_train = ros.fit_resample(X_train_tfidf, y_train)\n",
        "\n",
        "first = train_model('logistc_regression',LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),ros_X_train_tfidf, ros_y_train, X_test_tfidf)\n",
        "#print (\"LR Baseline, WordLevel TFIDF: \", accuracyORIGINAL)\n",
        "second = train_model('SVM',LinearSVC(),ros_X_train_tfidf, ros_y_train, X_test_tfidf)\n",
        "third =  train_model('BernoulliNB',BernoulliNB(),ros_X_train_tfidf, ros_y_train, X_test_tfidf)\n",
        "fourth =  train_model('MultinomialNB',MultinomialNB(),ros_X_train_tfidf, ros_y_train, X_test_tfidf)\n",
        "\n",
        "frames = [first,second,third,fourth]\n",
        "combined = pd.concat(frames)\n",
        "combined.reset_index(drop=True, inplace=True)\n",
        "display(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ytE4rm5I9Es"
      },
      "outputs": [],
      "source": [
        "sm = SMOTE(random_state=777)\n",
        "sm_X_train_tfidf, sm_y_train = sm.fit_resample(X_train_tfidf, y_train)\n",
        "\n",
        "first = train_model('logistc_regression',LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),sm_X_train_tfidf, sm_y_train, X_test_tfidf)\n",
        "#print (\"LR Baseline, WordLevel TFIDF: \", accuracyORIGINAL)\n",
        "second = train_model('SVM',LinearSVC(),sm_X_train_tfidf, sm_y_train, X_test_tfidf)\n",
        "third =  train_model('BernoulliNB',BernoulliNB(),sm_X_train_tfidf, sm_y_train, X_test_tfidf)\n",
        "fourth =  train_model('MultinomialNB',MultinomialNB(),sm_X_train_tfidf, sm_y_train, X_test_tfidf)\n",
        "\n",
        "frames = [first,second,third,fourth]\n",
        "combined = pd.concat(frames)\n",
        "combined.reset_index(drop=True, inplace=True)\n",
        "display(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ShTH2mDJBY9"
      },
      "outputs": [],
      "source": [
        "#ADASYN\n",
        "ad = ADASYN(random_state=777)\n",
        "ad_xtrain_tfidf, ad_train_y = ad.fit_resample(X_train_tfidf, y_train)\n",
        "\n",
        "first = train_model('logistc_regression',LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),ad_xtrain_tfidf, ad_train_y, X_test_tfidf)\n",
        "#print (\"LR Baseline, WordLevel TFIDF: \", accuracyORIGINAL)\n",
        "second = train_model('SVM',LinearSVC(),ad_xtrain_tfidf, ad_train_y, X_test_tfidf)\n",
        "third =  train_model('BernoulliNB',BernoulliNB(),ad_xtrain_tfidf, ad_train_y, X_test_tfidf)\n",
        "fourth =  train_model('MultinomialNB',MultinomialNB(),ad_xtrain_tfidf, ad_train_y, X_test_tfidf)\n",
        "\n",
        "frames = [first,second,third,fourth]\n",
        "combined = pd.concat(frames)\n",
        "combined.reset_index(drop=True, inplace=True)\n",
        "display(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKtumio-JFQX"
      },
      "outputs": [],
      "source": [
        "bsm = BorderlineSMOTE()\n",
        "bsm_xtrain_tfidf, bsm_train_y = bsm.fit_resample(X_train_tfidf, y_train)\n",
        "\n",
        "first = train_model('logistc_regression',LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),bsm_xtrain_tfidf, bsm_train_y, X_test_tfidf)\n",
        "#print (\"LR Baseline, WordLevel TFIDF: \", accuracyORIGINAL)\n",
        "second = train_model('SVM',LinearSVC(),bsm_xtrain_tfidf, bsm_train_y, X_test_tfidf)\n",
        "third =  train_model('BernoulliNB',BernoulliNB(),bsm_xtrain_tfidf, bsm_train_y, X_test_tfidf)\n",
        "fourth =  train_model('MultinomialNB',MultinomialNB(),bsm_xtrain_tfidf, bsm_train_y, X_test_tfidf)\n",
        "\n",
        "frames = [first,second,third,fourth]\n",
        "combined = pd.concat(frames)\n",
        "combined.reset_index(drop=True, inplace=True)\n",
        "display(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Aa111BtJHUW"
      },
      "outputs": [],
      "source": [
        "rus = RandomUnderSampler(random_state=0, replacement=True)\n",
        "rus_xtrain_tfidf, rus_train_y = rus.fit_resample(X_train_tfidf, y_train)\n",
        "\n",
        "first = train_model('logistc_regression',LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),rus_xtrain_tfidf, rus_train_y ,X_test_tfidf)\n",
        "#print (\"LR Baseline, WordLevel TFIDF: \", accuracyORIGINAL)\n",
        "second = train_model('SVM',LinearSVC(),rus_xtrain_tfidf, rus_train_y, X_test_tfidf)\n",
        "third =  train_model('BernoulliNB',BernoulliNB(),rus_xtrain_tfidf, rus_train_y, X_test_tfidf)\n",
        "fourth =  train_model('MultinomialNB',MultinomialNB(),rus_xtrain_tfidf, rus_train_y, X_test_tfidf)\n",
        "\n",
        "frames = [first,second,third,fourth]\n",
        "combined = pd.concat(frames)\n",
        "combined.reset_index(drop=True, inplace=True)\n",
        "display(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C32lG8HJKLN"
      },
      "outputs": [],
      "source": [
        "tl = TomekLinks()\n",
        "tl_xtrain_tfidf, tl_train_y = tl.fit_resample(X_train_tfidf, y_train)\n",
        "\n",
        "first = train_model('logistc_regression',LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),tl_xtrain_tfidf, tl_train_y ,X_test_tfidf)\n",
        "#print (\"LR Baseline, WordLevel TFIDF: \", accuracyORIGINAL)\n",
        "second = train_model('SVM',LinearSVC(),tl_xtrain_tfidf, tl_train_y , X_test_tfidf)\n",
        "third =  train_model('BernoulliNB',BernoulliNB(),tl_xtrain_tfidf, tl_train_y, X_test_tfidf)\n",
        "fourth =  train_model('MultinomialNB',MultinomialNB(),tl_xtrain_tfidf, tl_train_y , X_test_tfidf)\n",
        "\n",
        "frames = [first,second,third,fourth]\n",
        "combined = pd.concat(frames)\n",
        "combined.reset_index(drop=True, inplace=True)\n",
        "display(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGqOsWMHOkaU"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-addons==0.16.1\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC520YMYJL4A"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import Word\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter\n",
        "import wordcloud\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split \n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3kdHFCFNM5M"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9crP9P-CMx-g"
      },
      "outputs": [],
      "source": [
        "def lemma(data):\n",
        "    return \" \".join([Word(word).lemmatize() for word in data])\n",
        "\n",
        "data['lemmatized_tweets'] = data['tokenized_tweets'].apply(lambda x: lemma(x))\n",
        "data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEPPZOVsMh66"
      },
      "outputs": [],
      "source": [
        "Y = pd.get_dummies(data.label).values\n",
        "\n",
        "print('Shape of label tensor:', Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHLg4xpSNgBv"
      },
      "outputs": [],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89Zjz1vBNiRo"
      },
      "outputs": [],
      "source": [
        "MAX_NB_WORDS = 500\n",
        "# Max number of words in each tweets.\n",
        "MAX_SEQUENCE_LENGTH = 50\n",
        "# This is fixed.\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, split=' ') \n",
        "tokenizer.fit_on_texts(data.lemmatized_tweets.values)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_mQsE-yNmKf"
      },
      "outputs": [],
      "source": [
        "X = tokenizer.texts_to_sequences(data.lemmatized_tweets.values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1875mliNqV4"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 2022, stratify=Y)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGotkbuLOTgZ"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(2)\n",
        "f1 = tfa.metrics.F1Score(36,'micro' or 'macro')\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',f1])\n",
        "\n",
        "epochs = 7\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74pjy0MROcKc"
      },
      "outputs": [],
      "source": [
        "history_1 = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pciy1JLkRk52"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "seed(1)\n",
        "\n",
        "tensorflow.random.set_seed(2)\n",
        "f1 = tfa.metrics.F1Score(36,'micro' or 'macro')\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "opt = Adam(learning_rate=0.0005)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy',f1])\n",
        "\n",
        "epochs = 7\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9X4Im5jRiPe"
      },
      "outputs": [],
      "source": [
        "history_2 = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCCDLVpEO5ez"
      },
      "outputs": [],
      "source": [
        "accr = model.evaluate(X_test,Y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWcC4tUyRFQY"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.title('Loss')\n",
        "plt.plot(history_1.history['loss'], label='train')\n",
        "plt.plot(history_1.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9O9zs4BVTLRO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.title('Loss')\n",
        "plt.plot(history_2.history['loss'], label='train')\n",
        "plt.plot(history_2.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEhYXajBRJfN"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.title('Accuracy')\n",
        "plt.plot(history_1.history['accuracy'], label='train')\n",
        "plt.plot(history_1.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK"
      ],
      "metadata": {
        "id": "Q-nMLLNDIzuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext emoji -q"
      ],
      "metadata": {
        "id": "AF29GD4sPwfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2f771e-8713-4313-ba46-eb95ea93c2d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 68 kB 3.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 197 kB 10.8 MB/s \n",
            "\u001b[?25h  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning data"
      ],
      "metadata": {
        "id": "w6dy29bCI1c8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import sys\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import re\n",
        "import itertools\n",
        "import emoji"
      ],
      "metadata": {
        "id": "vhILB2bvI4NL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01a37758-8cd7-4ca4-b37a-e963c6008b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dict_smileys():\n",
        "    \n",
        "    return {\n",
        "        \":‑)\":\"smiley\",\n",
        "        \":-]\":\"smiley\",\n",
        "        \":-3\":\"smiley\",\n",
        "        \":->\":\"smiley\",\n",
        "        \"8-)\":\"smiley\",\n",
        "        \":-}\":\"smiley\",\n",
        "        \":)\":\"smiley\",\n",
        "        \":]\":\"smiley\",\n",
        "        \":3\":\"smiley\",\n",
        "        \":>\":\"smiley\",\n",
        "        \"8)\":\"smiley\",\n",
        "        \":}\":\"smiley\",\n",
        "        \":o)\":\"smiley\",\n",
        "        \":c)\":\"smiley\",\n",
        "        \":^)\":\"smiley\",\n",
        "        \"=]\":\"smiley\",\n",
        "        \"=)\":\"smiley\",\n",
        "        \":-))\":\"smiley\",\n",
        "        \":‑D\":\"smiley\",\n",
        "        \"8‑D\":\"smiley\",\n",
        "        \"x‑D\":\"smiley\",\n",
        "        \"X‑D\":\"smiley\",\n",
        "        \":D\":\"smiley\",\n",
        "        \"8D\":\"smiley\",\n",
        "        \"xD\":\"smiley\",\n",
        "        \"XD\":\"smiley\",\n",
        "        \":‑(\":\"sad\",\n",
        "        \":‑c\":\"sad\",\n",
        "        \":‑<\":\"sad\",\n",
        "        \":‑[\":\"sad\",\n",
        "        \":(\":\"sad\",\n",
        "        \":c\":\"sad\",\n",
        "        \":<\":\"sad\",\n",
        "        \":[\":\"sad\",\n",
        "        \":-||\":\"sad\",\n",
        "        \">:[\":\"sad\",\n",
        "        \":{\":\"sad\",\n",
        "        \":@\":\"sad\",\n",
        "        \">:(\":\"sad\",\n",
        "        \":'‑(\":\"sad\",\n",
        "        \":'(\":\"sad\",\n",
        "        \":‑P\":\"playful\",\n",
        "        \"X‑P\":\"playful\",\n",
        "        \"x‑p\":\"playful\",\n",
        "        \":‑p\":\"playful\",\n",
        "        \":‑Þ\":\"playful\",\n",
        "        \":‑þ\":\"playful\",\n",
        "        \":‑b\":\"playful\",\n",
        "        \":P\":\"playful\",\n",
        "        \"XP\":\"playful\",\n",
        "        \"xp\":\"playful\",\n",
        "        \":p\":\"playful\",\n",
        "        \":Þ\":\"playful\",\n",
        "        \":þ\":\"playful\",\n",
        "        \":b\":\"playful\",\n",
        "        \"<3\":\"love\"\n",
        "        }\n",
        "\n",
        "def load_dict_contractions():\n",
        "    \n",
        "    return {\n",
        "        \"ain't\":\"is not\",\n",
        "        \"amn't\":\"am not\",\n",
        "        \"aren't\":\"are not\",\n",
        "        \"can't\":\"cannot\",\n",
        "        \"'cause\":\"because\",\n",
        "        \"couldn't\":\"could not\",\n",
        "        \"couldn't've\":\"could not have\",\n",
        "        \"could've\":\"could have\",\n",
        "        \"daren't\":\"dare not\",\n",
        "        \"daresn't\":\"dare not\",\n",
        "        \"dasn't\":\"dare not\",\n",
        "        \"didn't\":\"did not\",\n",
        "        \"doesn't\":\"does not\",\n",
        "        \"don't\":\"do not\",\n",
        "        \"e'er\":\"ever\",\n",
        "        \"em\":\"them\",\n",
        "        \"everyone's\":\"everyone is\",\n",
        "        \"finna\":\"fixing to\",\n",
        "        \"gimme\":\"give me\",\n",
        "        \"gonna\":\"going to\",\n",
        "        \"gon't\":\"go not\",\n",
        "        \"gotta\":\"got to\",\n",
        "        \"hadn't\":\"had not\",\n",
        "        \"hasn't\":\"has not\",\n",
        "        \"haven't\":\"have not\",\n",
        "        \"he'd\":\"he would\",\n",
        "        \"he'll\":\"he will\",\n",
        "        \"he's\":\"he is\",\n",
        "        \"he've\":\"he have\",\n",
        "        \"how'd\":\"how would\",\n",
        "        \"how'll\":\"how will\",\n",
        "        \"how're\":\"how are\",\n",
        "        \"how's\":\"how is\",\n",
        "        \"I'd\":\"I would\",\n",
        "        \"I'll\":\"I will\",\n",
        "        \"I'm\":\"I am\",\n",
        "        \"I'm'a\":\"I am about to\",\n",
        "        \"I'm'o\":\"I am going to\",\n",
        "        \"isn't\":\"is not\",\n",
        "        \"it'd\":\"it would\",\n",
        "        \"it'll\":\"it will\",\n",
        "        \"it's\":\"it is\",\n",
        "        \"I've\":\"I have\",\n",
        "        \"kinda\":\"kind of\",\n",
        "        \"let's\":\"let us\",\n",
        "        \"mayn't\":\"may not\",\n",
        "        \"may've\":\"may have\",\n",
        "        \"mightn't\":\"might not\",\n",
        "        \"might've\":\"might have\",\n",
        "        \"mustn't\":\"must not\",\n",
        "        \"mustn't've\":\"must not have\",\n",
        "        \"must've\":\"must have\",\n",
        "        \"needn't\":\"need not\",\n",
        "        \"ne'er\":\"never\",\n",
        "        \"o'\":\"of\",\n",
        "        \"o'er\":\"over\",\n",
        "        \"ol'\":\"old\",\n",
        "        \"oughtn't\":\"ought not\",\n",
        "        \"shalln't\":\"shall not\",\n",
        "        \"shan't\":\"shall not\",\n",
        "        \"she'd\":\"she would\",\n",
        "        \"she'll\":\"she will\",\n",
        "        \"she's\":\"she is\",\n",
        "        \"shouldn't\":\"should not\",\n",
        "        \"shouldn't've\":\"should not have\",\n",
        "        \"should've\":\"should have\",\n",
        "        \"somebody's\":\"somebody is\",\n",
        "        \"someone's\":\"someone is\",\n",
        "        \"something's\":\"something is\",\n",
        "        \"that'd\":\"that would\",\n",
        "        \"that'll\":\"that will\",\n",
        "        \"that're\":\"that are\",\n",
        "        \"that's\":\"that is\",\n",
        "        \"there'd\":\"there would\",\n",
        "        \"there'll\":\"there will\",\n",
        "        \"there're\":\"there are\",\n",
        "        \"there's\":\"there is\",\n",
        "        \"these're\":\"these are\",\n",
        "        \"they'd\":\"they would\",\n",
        "        \"they'll\":\"they will\",\n",
        "        \"they're\":\"they are\",\n",
        "        \"they've\":\"they have\",\n",
        "        \"this's\":\"this is\",\n",
        "        \"those're\":\"those are\",\n",
        "        \"'tis\":\"it is\",\n",
        "        \"'twas\":\"it was\",\n",
        "        \"wanna\":\"want to\",\n",
        "        \"wasn't\":\"was not\",\n",
        "        \"we'd\":\"we would\",\n",
        "        \"we'd've\":\"we would have\",\n",
        "        \"we'll\":\"we will\",\n",
        "        \"we're\":\"we are\",\n",
        "        \"weren't\":\"were not\",\n",
        "        \"we've\":\"we have\",\n",
        "        \"what'd\":\"what did\",\n",
        "        \"what'll\":\"what will\",\n",
        "        \"what're\":\"what are\",\n",
        "        \"what's\":\"what is\",\n",
        "        \"what've\":\"what have\",\n",
        "        \"when's\":\"when is\",\n",
        "        \"where'd\":\"where did\",\n",
        "        \"where're\":\"where are\",\n",
        "        \"where's\":\"where is\",\n",
        "        \"where've\":\"where have\",\n",
        "        \"which's\":\"which is\",\n",
        "        \"who'd\":\"who would\",\n",
        "        \"who'd've\":\"who would have\",\n",
        "        \"who'll\":\"who will\",\n",
        "        \"who're\":\"who are\",\n",
        "        \"who's\":\"who is\",\n",
        "        \"who've\":\"who have\",\n",
        "        \"why'd\":\"why did\",\n",
        "        \"why're\":\"why are\",\n",
        "        \"why's\":\"why is\",\n",
        "        \"won't\":\"will not\",\n",
        "        \"wouldn't\":\"would not\",\n",
        "        \"would've\":\"would have\",\n",
        "        \"y'all\":\"you all\",\n",
        "        \"you'd\":\"you would\",\n",
        "        \"you'll\":\"you will\",\n",
        "        \"you're\":\"you are\",\n",
        "        \"you've\":\"you have\",\n",
        "        \"Whatcha\":\"What are you\",\n",
        "        \"luv\":\"love\",\n",
        "        \"sux\":\"sucks\"\n",
        "        }\n",
        "\n",
        "def strip_accents(text):\n",
        "    if 'ø' in text or  'Ø' in text:\n",
        "        #Do nothing when finding ø \n",
        "        return text   \n",
        "    text = text.encode('ascii', 'ignore')\n",
        "    text = text.decode(\"utf-8\")\n",
        "    return str(text)\n",
        "\n",
        "def tweet_cleaning_for_sentiment_analysis(tweet):    \n",
        "    \n",
        "    #Escaping HTML characters\n",
        "    tweet = BeautifulSoup(tweet).get_text()\n",
        "    #Special case not handled previously.\n",
        "    tweet = tweet.replace('\\x92',\"'\")\n",
        "    #Removal of hastags/account\n",
        "    #tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", tweet).split())\n",
        "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)\", \"USER\", tweet).split())\n",
        "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \")\n",
        "    #Removal of address\n",
        "    tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
        "    #Removal of Punctuation\n",
        "    tweet = ' '.join(re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=]\", \" \", tweet).split())\n",
        "    #Lower case\n",
        "    tweet = tweet.lower()\n",
        "    #CONTRACTIONS source: https://en.wikipedia.org/wiki/Contraction_%28grammar%29\n",
        "    CONTRACTIONS = load_dict_contractions()\n",
        "    tweet = tweet.replace(\"’\",\"'\")\n",
        "    words = tweet.split()\n",
        "    reformed = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    # Standardizing words\n",
        "    tweet = ''.join(''.join(s)[:2] for _, s in itertools.groupby(tweet))\n",
        "    #Deal with smileys\n",
        "    #source: https://en.wikipedia.org/wiki/List_of_emoticons\n",
        "    SMILEY = load_dict_smileys()  \n",
        "    words = tweet.split()\n",
        "    reformed = [SMILEY[word] if word in SMILEY else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    #Deal with emojis\n",
        "    tweet = emoji.demojize(tweet)\n",
        "    #Strip accents\n",
        "    tweet= strip_accents(tweet)\n",
        "    tweet = tweet.replace(\":\",\" \")\n",
        "    tweet = ' '.join(tweet.split())\n",
        "    \n",
        "    # DO NOT REMOVE STOP WORDS FOR SENTIMENT ANALYSIS - OR AT LEAST NOT NEGATIVE ONES\n",
        "\n",
        "    return tweet"
      ],
      "metadata": {
        "id": "KOKy5XnTIcdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdXuZVS4RK6V"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "PBqj60X7I8dZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "3SNJR0fZI-U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"train.tsv\", delimiter='\\t')\n",
        "data"
      ],
      "metadata": {
        "id": "IWlqozYODfqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['cleaned_tweets'] = data.tweet.apply(tweet_cleaning_for_sentiment_analysis)\n",
        "data"
      ],
      "metadata": {
        "id": "G2F5ZXoVIhnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word embeddings"
      ],
      "metadata": {
        "id": "JCPsA4VNDdak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import fasttext.util"
      ],
      "metadata": {
        "id": "Bjwdv4JkEyaE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "96110c3a-3b75-4ac0-eaf3-84a5843085aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7b44d059074f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download embedddings"
      ],
      "metadata": {
        "id": "rHtsIxxwDxrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!mkdir fasttext-embeddings\n",
        "%cd fasttext-embeddings\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
        "!unzip crawl-300d-2M-subword.zip\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "dKQlL3xmDojn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "275a73d7-fdd9-4c7b-fc68-66ef61f4fc85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fasttext-embeddings\n",
            "--2022-07-28 10:32:34--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5828358084 (5.4G) [application/zip]\n",
            "Saving to: ‘crawl-300d-2M-subword.zip’\n",
            "\n",
            "crawl-300d-2M-subwo 100%[===================>]   5.43G  37.0MB/s    in 2m 34s  \n",
            "\n",
            "2022-07-28 10:35:08 (36.2 MB/s) - ‘crawl-300d-2M-subword.zip’ saved [5828358084/5828358084]\n",
            "\n",
            "Archive:  crawl-300d-2M-subword.zip\n",
            "  inflating: crawl-300d-2M-subword.vec  \n",
            "  inflating: crawl-300d-2M-subword.bin  \n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir fasttext-embeddings\n",
        "%cd fasttext-embeddings\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
        "!unzip crawl-300d-2M.vec.zip"
      ],
      "metadata": {
        "id": "fvHBqWhfJ90J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "id": "DtPZvEA8EAGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading model"
      ],
      "metadata": {
        "id": "5AmvXtaIJwAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_emb = fasttext.FastText.load_model('./fasttext-embeddings/crawl-300d-2M-subword.bin')"
      ],
      "metadata": {
        "id": "6oqcyFZqEB28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d10bc4-fba8-4362-c095-a0c409ec128a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_emb.get_nearest_neighbors(\"🌝\")"
      ],
      "metadata": {
        "id": "bnDOMcctF5Dl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9401fb6-2b1c-4155-ff4c-d9ca4a218430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.9520852565765381, '🌚'),\n",
              " (0.9374086856842041, '🌛'),\n",
              " (0.9264683723449707, '🌑'),\n",
              " (0.9218981266021729, '🌕'),\n",
              " (0.921410858631134, '👐'),\n",
              " (0.9210396409034729, '🕊'),\n",
              " (0.9206425547599792, '🌇'),\n",
              " (0.9184413552284241, '🌬'),\n",
              " (0.9166590571403503, '🙆'),\n",
              " (0.914670467376709, '🕶')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying word embeddings"
      ],
      "metadata": {
        "id": "-5nT_uwuJy-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['sent_vec'] = data.cleaned_tweets.apply(fasttext_emb.get_sentence_vector)"
      ],
      "metadata": {
        "id": "VM656F5SGQgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "-y_lstkvNESC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(list(data.sent_vec.apply(lambda x: list(x)).values))"
      ],
      "metadata": {
        "id": "gLEt2R0mtthe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and validation data"
      ],
      "metadata": {
        "id": "qRG83VU_ObDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
      ],
      "metadata": {
        "id": "P5nYFXg6TX31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(list(data.sent_vec.apply(lambda x: list(x)).values))"
      ],
      "metadata": {
        "id": "6UkVeaP7vEHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, Xval, ytrain, yval = train_test_split(X, data.label.values, random_state=2022,test_size=0.2, stratify=data.label.values)"
      ],
      "metadata": {
        "id": "oXUiaKs1OaGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(ytrain).value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "goXcnVGbQIfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(yval).value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "eZXKH0oLyb-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain.shape, ytrain.shape"
      ],
      "metadata": {
        "id": "dgNdVo-IP5je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "count_vect.fit(data['tweet'])\n",
        "\n",
        "# transform the training and validation data using count vectorizer object\n",
        "\n",
        "x_count =  count_vect.transform(data['tweet'])"
      ],
      "metadata": {
        "id": "1dVvnqKvTRp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_count"
      ],
      "metadata": {
        "id": "T1kekepDUBFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_count_train, X_count_val, y_count_train, y_count_val = train_test_split(x_count, data.label, random_state=2022,test_size=0.2, stratify=data.label)"
      ],
      "metadata": {
        "id": "rpag66TrT6O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_count_train.shape"
      ],
      "metadata": {
        "id": "5_JVtDRhUJ4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "OZHOoTFjWFGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_model = XGBClassifier(max_depth=6, n_estimators=1000).fit(X_count_train, y_count_train) \n",
        "prediction = xgb_model.predict(Xval) \n",
        "f1_score(yval, prediction)"
      ],
      "metadata": {
        "id": "KBP0e3oHPqeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "classes_weights = class_weight.compute_sample_weight(\n",
        "    class_weight='balanced',\n",
        "    y=ytrain\n",
        ")"
      ],
      "metadata": {
        "id": "MvIsQhkdv9Rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
        "                                                 classes = np.unique(ytrain),\n",
        "                                                 y = ytrain)\n",
        "class_weights"
      ],
      "metadata": {
        "id": "eAAFoL8oS4Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_model = XGBClassifier(max_depth=6, n_estimators=1000).fit(Xtrain, ytrain, sample_weight=classes_weights) \n",
        "prediction = xgb_model.predict(Xval)"
      ],
      "metadata": {
        "id": "wlfKrdZtuQC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = xgb_model.predict(X_count_val) \n"
      ],
      "metadata": {
        "id": "YqQLn4NXP2Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "xQh7WS5dVCaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(prediction, y_count_val)) #Count Vectorizer"
      ],
      "metadata": {
        "id": "XAQn07_RVOLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(prediction, yval)) #Fasttext"
      ],
      "metadata": {
        "id": "u5_dwJKxVTve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(prediction, yval)) #Sample weight"
      ],
      "metadata": {
        "id": "OTXeoD_2yFxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(prediction, yval)) #Sample weight"
      ],
      "metadata": {
        "id": "3-EO9y66adjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "-5KW2Xym2CxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = xgb.DMatrix(Xtrain, ytrain)\n",
        "test = xgb.DMatrix(Xval, yval)\n",
        "\n",
        "# We need to define parameters as dict\n",
        "params = {\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"max_depth\": 3\n",
        "}\n",
        "# training, we set the early stopping rounds parameter\n",
        "model_xgb = xgb.train(params, \n",
        "          train, evals=[(train, \"train\"), (test, \"validation\")], \n",
        "          num_boost_round=100, early_stopping_rounds=20)"
      ],
      "metadata": {
        "id": "gLBDrZXE1aei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_xgb.best_ntree_limit"
      ],
      "metadata": {
        "id": "iUy7z9FR163B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model_xgb.predict(test, ntree_limit=model_xgb.best_ntree_limit)"
      ],
      "metadata": {
        "id": "ix3vUkUM2IvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(prediction, yval)) #Sample weight"
      ],
      "metadata": {
        "id": "FMe_zWAC2Pt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model.save_model(\"xgboost_model.json\")"
      ],
      "metadata": {
        "id": "qQufP0nq2Veh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "4r4GNmfX3Vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def randomsearch():\n",
        "  n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 15)]\n",
        "  # Number of features to consider at every split\n",
        "  max_features = ['auto', 'sqrt']\n",
        "  # Maximum number of levels in tree\n",
        "  max_depth = [int(x) for x in np.linspace(10, 200, num = 10)]\n",
        "  max_depth.append(None)\n",
        "  # Minimum number of samples required to split a node\n",
        "  min_samples_split = [2, 4, 8, 16,32]\n",
        "  # Minimum number of samples required at each leaf node\n",
        "  min_samples_leaf = [1, 2, 4,8,16]\n",
        "  # Method of selecting samples for training each tree\n",
        "  bootstrap = [True, False]# Create the random grid\n",
        "  random_grid = {'n_estimators': n_estimators,\n",
        "                'max_features': max_features,\n",
        "                'max_depth': max_depth,\n",
        "                'min_samples_split': min_samples_split,\n",
        "                'min_samples_leaf': min_samples_leaf,\n",
        "                'bootstrap': bootstrap}\n",
        "                \n",
        "  pprint(random_grid,compact=True)\n",
        "  \n",
        "  return random_grid\n",
        "\n",
        "_ =randomsearch()"
      ],
      "metadata": {
        "id": "FJY7LMKk3Pu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "aVVUKYdX35fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_grid = randomsearch()\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=4, random_state=2022, n_jobs = -1)# Fit the random search model\n",
        "rf_random.fit(Xtrain, ytrain)\n",
        "\n",
        "\n",
        "best_random = rf_random.best_estimator_\n",
        "\n",
        "print(\"Paramters:\")\n",
        "pprint(rf_random.best_params_)\n",
        "\n",
        "print(\"Training\")\n",
        "print(classification_report(ytrain,best_random.predict(Xtrain)))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Testing\")\n",
        "print(classification_report(yval,best_random.predict(Xval)))"
      ],
      "metadata": {
        "id": "Bavs15bJ2msB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " rf = RandomForestClassifier(max_features='log2', class_weight='balanced', random_state=2022, n_jobs=-1)\n",
        " rf.fit(Xtrain, ytrain)"
      ],
      "metadata": {
        "id": "pNcdCTAw36Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = rf.predict(Xval)"
      ],
      "metadata": {
        "id": "gsd6TjMh58eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(predictions, yval)) #Random forest"
      ],
      "metadata": {
        "id": "eFMNlORY-iHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'n_estimators':[500],\n",
        "    'min_child_weight':[4,5], \n",
        "    'gamma':[i/10.0 for i in range(3,6)],  \n",
        "    'subsample':[i/10.0 for i in range(6,11)],\n",
        "    'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
        "    'max_depth': [2,3,4,6,7],\n",
        "    'objective': ['reg:squarederror', 'reg:tweedie'],\n",
        "    'booster': ['gbtree', 'gblinear'],\n",
        "    'eval_metric': ['rmse'],\n",
        "    'eta': [i/10.0 for i in range(3,6)],\n",
        "}\n",
        "\n",
        "reg = XGBRegressor(nthread=-1)\n",
        "\n",
        "# run randomized search\n",
        "n_iter_search = 100\n",
        "random_search = RandomizedSearchCV(reg, param_distributions=params,\n",
        "                                   n_iter=n_iter_search, cv=3, iid=False, scoring='neg_mean_squared_error')\n",
        "\n"
      ],
      "metadata": {
        "id": "z71ewVOm59AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test data"
      ],
      "metadata": {
        "id": "33L_Q64GVJQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(\"test.tsv\", delimiter='\\t')\n",
        "test"
      ],
      "metadata": {
        "id": "ByeBhuOkU32x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.label.value_counts()"
      ],
      "metadata": {
        "id": "OliYzUt-pnWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "387wWxCPpnOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['cleaned_tweets'] = test.tweet.apply(tweet_cleaning_for_sentiment_analysis)\n",
        "#test['sent_vec'] = test.cleaned_tweets.apply(fasttext_emb.get_sentence_vector)"
      ],
      "metadata": {
        "id": "Rs9VLM2uVLSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array(list(test.sent_vec.apply(lambda x: list(x)).values))\n",
        "y_test = test.label.values"
      ],
      "metadata": {
        "id": "86zzOee7VaEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "7zwMJFDuVoeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "eTitMqHCkY90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = rf.predict(X_test)\n",
        "print(classification_report(predictions, y_test)) #Random forest"
      ],
      "metadata": {
        "id": "yYwn5tZSU9Zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "eT8gSWn0kalw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = xgb_model.predict(X_test)\n",
        "print(classification_report(predictions, y_test)) #xgboost"
      ],
      "metadata": {
        "id": "pAiOieJNgMNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERTweet"
      ],
      "metadata": {
        "id": "SGyETvfJkdtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test['BERTweet'] = test['cleaned_tweets'].apply(sa1.inference)"
      ],
      "metadata": {
        "id": "UHZ0hP4aV8Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "_cCEa-wchYa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['BERTweet'] = test['BERTweet'].replace('NEUTRAL', 0)\n",
        "test['BERTweet'] = test['BERTweet'].replace('NEGATIVE', -1)\n",
        "test['BERTweet'] = test['BERTweet'].replace('POSITIVE', 1)\n",
        "\n",
        "test"
      ],
      "metadata": {
        "id": "hhpgkxpnheqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test.label, test.BERTweet)) #BERTweet"
      ],
      "metadata": {
        "id": "1u7bJCHOjdlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT base"
      ],
      "metadata": {
        "id": "8NbNwCetkg8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test['bert-base-multilingual-uncased-sentiment_clean'] = test['cleaned_tweets'].apply(sa2.inference)"
      ],
      "metadata": {
        "id": "Yp62jhNXjoXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "WVeFSVQfkjXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['bert-base-multilingual-uncased-sentiment_clean'] = test['bert-base-multilingual-uncased-sentiment_clean'].replace('NEUTRAL', 0)\n",
        "test['bert-base-multilingual-uncased-sentiment_clean'] = test['bert-base-multilingual-uncased-sentiment_clean'].replace('NEGATIVE', -1)\n",
        "test['bert-base-multilingual-uncased-sentiment_clean'] = test['bert-base-multilingual-uncased-sentiment_clean'].replace('POSITIVE', 1)\n",
        "\n",
        "test"
      ],
      "metadata": {
        "id": "w3_aiyjjkkf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test.label, test['bert-base-multilingual-uncased-sentiment_clean'])) #BERTweet"
      ],
      "metadata": {
        "id": "K0ovVmfAksJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmark dataset"
      ],
      "metadata": {
        "id": "B1g8bhBZgU1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df = pd.read_excel(\"Sentiment models.xlsx\", engine='openpyxl')\n",
        "benchmark_df"
      ],
      "metadata": {
        "id": "MeUHhsC9a1xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df = benchmark_df[['Tweets']]"
      ],
      "metadata": {
        "id": "ToTIi9YRbmw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df['cleaned_tweets'] = benchmark_df.Tweets.apply(tweet_cleaning_for_sentiment_analysis)\n",
        "benchmark_df['sent_vec'] = benchmark_df.cleaned_tweets.apply(fasttext_emb.get_sentence_vector)"
      ],
      "metadata": {
        "id": "WhXhmYxpa94g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df"
      ],
      "metadata": {
        "id": "JihU4caub0kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(list(benchmark_df.sent_vec.apply(lambda x: list(x)).values))\n",
        "benchmark_df['Random Forest'] = rf.predict(X)"
      ],
      "metadata": {
        "id": "j5mdPXNmb448"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df['Random Forest'] = benchmark_df['Random Forest'].replace(0, 'Neutral')\n",
        "benchmark_df['Random Forest'] = benchmark_df['Random Forest'].replace(-1, 'Negative')\n",
        "benchmark_df['Random Forest'] = benchmark_df['Random Forest'].replace(1, 'Positive')\n",
        "\n",
        "benchmark_df"
      ],
      "metadata": {
        "id": "75cWpi8IcPpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df['XGBoost'] = xgb_model.predict(X) \n",
        "benchmark_df"
      ],
      "metadata": {
        "id": "mHFwaI2UcRWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df['XGBoost'] = benchmark_df['XGBoost'].replace(0, 'Neutral')\n",
        "benchmark_df['XGBoost'] = benchmark_df['XGBoost'].replace(-1, 'Negative')\n",
        "benchmark_df['XGBoost'] = benchmark_df['XGBoost'].replace(1, 'Positive')\n",
        "\n",
        "benchmark_df"
      ],
      "metadata": {
        "id": "fWp9SWWrc8wI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df.to_excel(\"Sentiment.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "f5jOzTmrdCh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iL4yNfJIdNVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset curation"
      ],
      "metadata": {
        "id": "5H68CXlf-8s9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests"
      ],
      "metadata": {
        "id": "PdBcakVz_ADG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = []\n",
        "test = []\n",
        "dev = []"
      ],
      "metadata": {
        "id": "Y0womrl8Epts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SST-5"
      ],
      "metadata": {
        "id": "vi9JpWfX--ZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash \n",
        "mkdir SST-5\n",
        "cd SST-5\n",
        "wget https://raw.githubusercontent.com/prrao87/fine-grained-sentiment/master/data/sst/sst_train.txt\n",
        "wget https://raw.githubusercontent.com/prrao87/fine-grained-sentiment/master/data/sst/sst_dev.txt\n",
        "wget https://raw.githubusercontent.com/prrao87/fine-grained-sentiment/master/data/sst/sst_test.txt\n",
        "cd /content"
      ],
      "metadata": {
        "id": "zdOAV-mW_H1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytreebank"
      ],
      "metadata": {
        "id": "3vwXtPRG_jsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/SST-5/sst_train.txt\").readlines()\n",
        "f"
      ],
      "metadata": {
        "id": "Ct2M0MPe-97S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relabel(label):\n",
        "  if int(label[-1]) > 3:\n",
        "    return \"POSITIVE\"\n",
        "  elif int(label[-1]) == 3:\n",
        "    return \"NEUTRAL\"\n",
        "  else:\n",
        "    return \"NEGATIVE\""
      ],
      "metadata": {
        "id": "nHseWHdhCoHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sst5train = pd.read_csv(\"/content/SST-5/sst_train.txt\", delimiter='\\t', names=['label', 'tweet'])\n",
        "sst5test = pd.read_csv(\"/content/SST-5/sst_test.txt\", delimiter='\\t', names=['label', 'tweet'])\n",
        "sst5dev = pd.read_csv(\"/content/SST-5/sst_dev.txt\", delimiter='\\t', names=['label', 'tweet'])"
      ],
      "metadata": {
        "id": "ExTHuA-W_cqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sst5train['label'] = sst5train['label'].apply(relabel)\n",
        "sst5test['label'] = sst5test['label'].apply(relabel)\n",
        "sst5dev['label'] = sst5dev['label'].apply(relabel)"
      ],
      "metadata": {
        "id": "ysBAN1jdDGy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sst5train['label'].value_counts())\n",
        "print(sst5test['label'].value_counts())\n",
        "print(sst5dev['label'].value_counts())"
      ],
      "metadata": {
        "id": "FGAKeopYDgpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.append(sst5train)\n",
        "test.append(sst5test)\n",
        "dev.append(sst5dev)"
      ],
      "metadata": {
        "id": "g-pR9P0KDouc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi domain sentiment analysis"
      ],
      "metadata": {
        "id": "HqziMTDsGWbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.cs.jhu.edu/~mdredze/datasets/sentiment/processed_stars.tar.gz\n",
        "!tar -xf processed_stars.tar.gz"
      ],
      "metadata": {
        "id": "wW4M_zzRGY5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.cs.jhu.edu/~mdredze/datasets/sentiment/unprocessed.tar.gz\n",
        "!tar -xf unprocessed.tar.gz"
      ],
      "metadata": {
        "id": "805AXUjnIbr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf unprocessed.tar.gz.1"
      ],
      "metadata": {
        "id": "GiXP6XocIvrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "bRH8xxGaH5DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path_to_data = \"./sorted_data\"\n",
        "# path_to_processed_data = \"processed\"\n",
        "dirs = []\n",
        "for entry in os.scandir(path_to_data):\n",
        "    if entry.is_dir():\n",
        "        dirs.append(entry.path)\n",
        "dirs"
      ],
      "metadata": {
        "id": "l1MBfXnZIG3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade xml-python"
      ],
      "metadata": {
        "id": "L9T9fAh-Lur5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import re \n",
        "\n",
        "# with open(\"./sorted_data/apparel/unlabeled.review\", encoding='iso-8859-5') as f:\n",
        "#     xml = f.read()\n",
        "# tree = ET.fromstring(re.sub(r\"(<\\?xml[^>]+\\?>)\", r\"\\1<review>\", xml) + \"</review>\")\n",
        "\n",
        "tree = ET.parse('/content/processed_stars/books/all_balanced.review', parser = ET.XMLParser(encoding = 'iso-8859-5'))"
      ],
      "metadata": {
        "id": "llRmluFMJ1Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./sorted_data/apparel/unlabeled.review\", encoding='iso-8859-5') as f:\n",
        "  xml = f.read()\n",
        "\n",
        "\n",
        "data = [(i + \"</review>\").strip(\"\\n\") for i in xml.split(\"</review>\")]"
      ],
      "metadata": {
        "id": "jUCDkAaWNm__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from io import StringIO\n",
        "from lxml import etree\n",
        "parser = lxml.etree.XMLParser(encoding='utf-8', recover=True)\n",
        "\n",
        "def generate_trees(filepath):\n",
        "\n",
        "  with open(filepath, encoding='iso-8859-5') as f:\n",
        "    xml = f.read()\n",
        "\n",
        "\n",
        "  data = [(i + \"</review>\").strip(\"\\n\") for i in xml.split(\"</review>\")]\n",
        "  data = data[:-1]\n",
        "  \n",
        "  data_trees = []\n",
        "  \n",
        "  for i, d in enumerate(data):\n",
        "    #print(i)\n",
        "    with StringIO(d) as f:\n",
        "      #tree = ET.parse(f, parser = ET.XMLParser(encoding = 'utf-8-sig'))\n",
        "      tree = ET.parse(f, parser)\n",
        "    \n",
        "    data_trees.append(tree)\n",
        "\n",
        "  return data_trees"
      ],
      "metadata": {
        "id": "bok-1pkDOlqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_row(tree):\n",
        "  root = tree.getroot()\n",
        "  cols = [\"unique_id\", \"asin\", \"product_name\", \"product_type\", \"helpful\", \"rating\", \"title\", \"date\", \"reviewer\", \"reviewer_location\", \"review_text\"]\n",
        "  rows = []\n",
        "\n",
        "  try:\n",
        "    unique_id = root.find(\"unique_id\").text\n",
        "  except:\n",
        "    unique_id = ''\n",
        "\n",
        "  try:  \n",
        "    asin = root.find(\"asin\").text\n",
        "  except:\n",
        "    asin = ''\n",
        "\n",
        "  try:\n",
        "    product_name = root.find(\"product_name\").text\n",
        "  except:\n",
        "    product_name = ''\n",
        "\n",
        "  try:\n",
        "    product_type = root.find(\"product_type\").text\n",
        "  except:\n",
        "    product_type = ''\n",
        "  \n",
        "  try:\n",
        "    helpful = root.find(\"helpful\").text\n",
        "  except:\n",
        "    helpful = ''\n",
        "\n",
        "  try:\n",
        "    rating = root.find(\"rating\").text\n",
        "  except:\n",
        "    rating = ''\n",
        "\n",
        "  try:  \n",
        "    title = root.find(\"title\").text\n",
        "  except:\n",
        "    title = ''\n",
        "\n",
        "  try:  \n",
        "    date = root.find(\"date\").text\n",
        "  except:\n",
        "    date = ''\n",
        "\n",
        "  try:  \n",
        "    reviewer = root.find(\"reviewer\").text\n",
        "  except:\n",
        "    reviewer = ''\n",
        "  \n",
        "  try:\n",
        "    reviewer_location = root.find(\"reviewer_location\").text\n",
        "  except:\n",
        "    reviewer_location = ''\n",
        "\n",
        "  try:  \n",
        "    review_text = root.find(\"review_text\").text \n",
        "  except:\n",
        "    review_text= ''\n",
        "\n",
        "  rows.append({\"unique_id\": unique_id,\n",
        "                \"asin\": asin,\n",
        "                \"product_name\": product_name,\n",
        "                \"product_type\": product_type,\n",
        "                \"helpful\": helpful, \n",
        "                \"rating\": rating, \n",
        "                \"title\": title, \n",
        "                \"date\": date, \n",
        "                \"reviewer\": reviewer, \n",
        "                \"reviewer_location\": reviewer_location, \n",
        "                \"review_text\": review_text})\n",
        "\n",
        "  df = pd.DataFrame(rows, columns=cols)\n",
        "  \n",
        "  return df"
      ],
      "metadata": {
        "id": "sney_sfuOEfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_row(tree):\n",
        "  root = tree.getroot()\n",
        "  cols = [ \"asin\", \"product_type\", \"helpful\", \"rating\", \"title\",  \"review_text\"]\n",
        "  rows = []\n",
        "\n",
        " \n",
        "  try:  \n",
        "    asin = root.find(\"asin\").text\n",
        "  except:\n",
        "    asin = ''\n",
        "\n",
        "  try:\n",
        "    product_type = root.find(\"product_type\").text\n",
        "  except:\n",
        "    product_type = ''\n",
        "  \n",
        "  try:\n",
        "    helpful = root.find(\"helpful\").text\n",
        "  except:\n",
        "    helpful = ''\n",
        "\n",
        "  try:\n",
        "    rating = root.find(\"rating\").text\n",
        "  except:\n",
        "    rating = ''\n",
        "\n",
        "  try:  \n",
        "    title = root.find(\"title\").text\n",
        "  except:\n",
        "    title = ''\n",
        "\n",
        "  try:  \n",
        "    review_text = root.find(\"review_text\").text \n",
        "  except:\n",
        "    review_text= ''\n",
        "\n",
        "  rows.append({\n",
        "                \"asin\": asin,  \n",
        "                \"product_type\": product_type,\n",
        "                \"helpful\": helpful, \n",
        "                \"rating\": rating, \n",
        "                \"title\": title, \n",
        "                \"review_text\": review_text})\n",
        "\n",
        "  #df = pd.DataFrame(rows, columns=cols)\n",
        "  \n",
        "  return rows"
      ],
      "metadata": {
        "id": "Pv89Fv_buril"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def strip_line_breaks(df):\n",
        "    for i in df.columns:\n",
        "        df[i] = df[i].apply(lambda x : x.strip('\\n'))\n",
        "    return df"
      ],
      "metadata": {
        "id": "tQu3SMlVTPIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_df_from_trees(data_trees):\n",
        "  data = pd.DataFrame()\n",
        "  data_rows = []\n",
        "  for tree in tqdm(data_trees):\n",
        "    row = get_row(tree)\n",
        "    data_rows.extend(row)\n",
        "    \n",
        "  data = pd.DataFrame(data_rows)\n",
        "\n",
        "  return strip_line_breaks(data)"
      ],
      "metadata": {
        "id": "za4OL8Z8RXHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_file(filepath):\n",
        "  data_trees = generate_trees(filepath)\n",
        "  data = generate_df_from_trees(data_trees)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "hsrFyxyfhimL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "iTpHSHUtS-ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"./sorted_data/video/all.review\"\n",
        "test = parse_file(filepath)\n"
      ],
      "metadata": {
        "id": "qpcC4NA8h1TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_processed_data = \"./multi-domain/processed\""
      ],
      "metadata": {
        "id": "IPH6prLLoAo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path_to_data = \"./sorted_data\"\n",
        "# path_to_processed_data = \"processed\"\n",
        "dirs = []\n",
        "for entry in os.scandir(path_to_data):\n",
        "    if entry.is_dir():\n",
        "        dirs.append(entry.path)\n",
        "dirs"
      ],
      "metadata": {
        "id": "S_RF-RQLoRE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "if os.path.exists(path_to_processed_data):\n",
        "     shutil.rmtree(path_to_processed_data)\n",
        "os.mkdir(path_to_processed_data)"
      ],
      "metadata": {
        "id": "ojOuo0YroExy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_dirs = []\n",
        "processed_file_names_dict = {}\n",
        "for dir in dirs[2:]:\n",
        "    product_type = dir.split('/')[-1]\n",
        "    processed_file_names_dict[product_type] = []\n",
        "    for entry in os.scandir(dir):\n",
        "        print(f\"Running {entry.path}\") \n",
        "        try:\n",
        "          df = parse_file(entry.path)\n",
        "          \n",
        "          if tree is not None:\n",
        "              processed_folder = path_to_processed_data + '/' + product_type\n",
        "              if not os.path.exists(processed_folder):\n",
        "                  os.makedirs(processed_folder)\n",
        "                  processed_dirs.append(processed_folder)\n",
        "                  print(\"Generating processed files in folder: \",processed_folder)\n",
        "              \n",
        "              processed_file_name = product_type + \"_\" + ((entry.path).split('/')[-1]).split('.review')[0] + \".csv\"\n",
        "              processed_file_path = processed_folder + \"/\" + processed_file_name\n",
        "              df.to_csv(processed_file_path, index=False)\n",
        "              processed_file_names_dict[product_type].append(processed_file_path)\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "                              "
      ],
      "metadata": {
        "id": "uhs819IaoGqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r multi-domain.zip /content/multi-domain"
      ],
      "metadata": {
        "id": "c2pj4MFLw7iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "d = pd.read_csv(\"/content/multi-domain/processed/baby/baby_all.csv\")"
      ],
      "metadata": {
        "id": "FF2nAo9ayJ-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d.rating.value_counts()"
      ],
      "metadata": {
        "id": "J7z89SHny0rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lxml.etree\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "parser = lxml.etree.XMLParser(encoding='utf-8', recover=True)"
      ],
      "metadata": {
        "id": "S2CYUAbhgxSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis on Financial news"
      ],
      "metadata": {
        "id": "zMr0mQUeYs7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir financial-news"
      ],
      "metadata": {
        "id": "xSRFfQ51YvJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "financial_news = pd.read_csv(\"./financial-news/all-data.csv\", names=['label', 'tweet'], encoding='iso-8859-5')\n",
        "financial_news"
      ],
      "metadata": {
        "id": "7_MLD38rYwWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "financial_news['label'] = financial_news['label'].apply(str.upper)"
      ],
      "metadata": {
        "id": "4E7Xa049Zu2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "financial_news['label'].value_counts()"
      ],
      "metadata": {
        "id": "jP71RuEHZdoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_ratio = 0.7\n",
        "validation_ratio = 0.1\n",
        "test_ratio = 0.2\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely\n",
        "financial_news_train, financial_news_test = train_test_split(financial_news, test_size=1 - train_ratio, stratify=financial_news.label.values)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "financial_news_dev, financial_news_test = train_test_split(financial_news_test, test_size=test_ratio/(test_ratio + validation_ratio), stratify=financial_news_test.label.values) \n",
        "\n",
        "print(financial_news_train, financial_news_dev, financial_news_test)"
      ],
      "metadata": {
        "id": "m6kFhsUKZ610"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "financial_news_test"
      ],
      "metadata": {
        "id": "gUukFg1PaYYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(financial_news_train['label'].value_counts())\n",
        "print(financial_news_test['label'].value_counts())\n",
        "print(financial_news_dev['label'].value_counts())"
      ],
      "metadata": {
        "id": "wPVSJcGRbxJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.append(financial_news_train)\n",
        "test.append(financial_test)\n",
        "dev.append(financial_dev)"
      ],
      "metadata": {
        "id": "3rDqC2hlciuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Financial Sentiment Analysis"
      ],
      "metadata": {
        "id": "Pz559RUC2jTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir financial-sentiment"
      ],
      "metadata": {
        "id": "W2-HsAsY2jTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "financial = pd.read_csv(\"./financial-sentiment/data.csv\", names=['tweet', 'label'], skiprows=1)\n",
        "financial"
      ],
      "metadata": {
        "id": "BbFTxibO2jTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "financial['label'] = financial['label'].apply(str.upper)"
      ],
      "metadata": {
        "id": "wdnNtEu32jTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "financial['label'].value_counts()"
      ],
      "metadata": {
        "id": "wsF8rdDM2jTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_ratio = 0.7\n",
        "validation_ratio = 0.1\n",
        "test_ratio = 0.2\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely\n",
        "financial_train, financial_test = train_test_split(financial, test_size=1 - train_ratio, stratify=financial.label.values)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "financial_dev, financial_test = train_test_split(financial_test, test_size=test_ratio/(test_ratio + validation_ratio), stratify=financial_test.label.values) \n",
        "\n",
        "print(financial_train, financial_dev, financial_test)"
      ],
      "metadata": {
        "id": "f6y5Uinl2jTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "financial_test"
      ],
      "metadata": {
        "id": "P0gs9TBZ2jTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(financial_train['label'].value_counts())\n",
        "print(financial_test['label'].value_counts())\n",
        "print(financial_dev['label'].value_counts())"
      ],
      "metadata": {
        "id": "1sCY1mmf2jT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.append(financial_train)\n",
        "test.append(financial_test)\n",
        "dev.append(financial_dev)"
      ],
      "metadata": {
        "id": "A7H9OsWB2jT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5Dw-G8io2jT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZsgpOxddcpad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CovidSenti"
      ],
      "metadata": {
        "id": "xdZ243gTex_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir CovidSenti\n",
        "%cd CovidSenti\n",
        "!wget https://raw.githubusercontent.com/usmaann/COVIDSenti/main/COVIDSenti.csv"
      ],
      "metadata": {
        "id": "i-80fPGUey8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "id": "ww36MX9de94B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "covidsenti = pd.read_csv(\"./CovidSenti/COVIDSenti.csv\")\n",
        "covidsenti"
      ],
      "metadata": {
        "id": "CNr3m4Swcy-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relabel(label):\n",
        "  if label==\"neu\":\n",
        "    return \"NEUTRAL\"\n",
        "  elif label==\"pos\":\n",
        "    return \"POSITIVE\"\n",
        "  else:\n",
        "    return \"NEGATIVE\""
      ],
      "metadata": {
        "id": "_BFiNt3jffOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "covidsenti['label'] = covidsenti['label'].apply(relabel)"
      ],
      "metadata": {
        "id": "WlHFr9tHcy-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "covidsenti['label'].value_counts()"
      ],
      "metadata": {
        "id": "hjHZEx_hcy-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_ratio = 0.7\n",
        "validation_ratio = 0.1\n",
        "test_ratio = 0.2\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely\n",
        "covidsenti_train, covidsenti_test = train_test_split(covidsenti, test_size=1 - train_ratio, stratify=covidsenti.label.values)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "covidsenti_dev, covidsenti_test = train_test_split(covidsenti_test, test_size=test_ratio/(test_ratio + validation_ratio), stratify=covidsenti_test.label.values) \n",
        "\n",
        "print(covidsenti_train, covidsenti_dev, covidsenti_test)"
      ],
      "metadata": {
        "id": "OWsRYLBtcy_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(covidsenti_train['label'].value_counts())\n",
        "print(covidsenti_test['label'].value_counts())\n",
        "print(covidsenti_dev['label'].value_counts())"
      ],
      "metadata": {
        "id": "Xs3TwpsHcy_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.append(covidsenti_train)\n",
        "test.append(covidsenti_test)\n",
        "dev.append(covidsenti_dev)"
      ],
      "metadata": {
        "id": "YoHgBs5Tcy_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train), len(test), len(dev)"
      ],
      "metadata": {
        "id": "_WNLOxCCeH5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data-save"
      ],
      "metadata": {
        "id": "jGTWwbdLgIKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"./data-save/train.pkl\",\"wb\") as f:\n",
        "  pickle.dump(train, f)\n",
        "\n",
        "with open(\"./data-save/test.pkl\",\"wb\") as f:\n",
        "  pickle.dump(test, f)\n",
        "\n",
        "with open(\"./data-save/dev.pkl\",\"wb\") as f:\n",
        "  pickle.dump(dev, f)"
      ],
      "metadata": {
        "id": "T3wHfg3H1I89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r data-save.zip ./data-save"
      ],
      "metadata": {
        "id": "YaEzlTZs34MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vrEiii9A4JSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMDB"
      ],
      "metadata": {
        "id": "Ty3ZNWDxkOaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_new_df.to_csv(\"data-save-added/test-added.csv\", index=False, encoding='UTF-8')\n",
        "dev_new_df.to_csv(\"data-save-added/dev-added.csv\", index=False, encoding='UTF-8')"
      ],
      "metadata": {
        "id": "VaZQfsxwkPt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK : Collated data sentiment analysis training"
      ],
      "metadata": {
        "id": "UO98f3fiN4s2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext emoji -q"
      ],
      "metadata": {
        "id": "eLXjodj8N4s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwVXcYJQTqUI",
        "outputId": "02e4c1ea-34a7-4ca1-d2d3-a5c35b295874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Internship/Coffeebeans/data/finaldata.zip finaldata.zip\n",
        "!unzip finaldata.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSxJds-KZA2S",
        "outputId": "ee6b77ab-2d9a-42c7-bcdd-821dba6c051f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  finaldata.zip\n",
            "  inflating: dev.csv                 \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Internship/Coffeebeans/data/pickled_data.zip -d /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VO7odQDIMkF",
        "outputId": "892f92df-e00a-47dd-830b-5a1662870e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Internship/Coffeebeans/data/pickled_data.zip\n",
            "replace /content/content/pickled_data/dev.pkl? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Internship/Coffeebeans/data/finaldata.zip -d /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28Cs5X8lgG1l",
        "outputId": "76471aad-f2a8-4b2a-e51e-ba6b30a1522b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Internship/Coffeebeans/data/finaldata.zip\n",
            "  inflating: /content/dev.csv        \n",
            "  inflating: /content/test.csv       \n",
            "  inflating: /content/train.csv      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning data"
      ],
      "metadata": {
        "id": "CptevH6QN4s-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import sys\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import re\n",
        "import itertools\n",
        "import emoji\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "import fasttext\n",
        "import fasttext.util"
      ],
      "metadata": {
        "id": "tcCK2PfTN4tB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb4fcb28-8cfd-45ae-f5e8-5af513d4d461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dict_smileys():\n",
        "    \n",
        "    return {\n",
        "        \":‑)\":\"smiley\",\n",
        "        \":-]\":\"smiley\",\n",
        "        \":-3\":\"smiley\",\n",
        "        \":->\":\"smiley\",\n",
        "        \"8-)\":\"smiley\",\n",
        "        \":-}\":\"smiley\",\n",
        "        \":)\":\"smiley\",\n",
        "        \":]\":\"smiley\",\n",
        "        \":3\":\"smiley\",\n",
        "        \":>\":\"smiley\",\n",
        "        \"8)\":\"smiley\",\n",
        "        \":}\":\"smiley\",\n",
        "        \":o)\":\"smiley\",\n",
        "        \":c)\":\"smiley\",\n",
        "        \":^)\":\"smiley\",\n",
        "        \"=]\":\"smiley\",\n",
        "        \"=)\":\"smiley\",\n",
        "        \":-))\":\"smiley\",\n",
        "        \":‑D\":\"smiley\",\n",
        "        \"8‑D\":\"smiley\",\n",
        "        \"x‑D\":\"smiley\",\n",
        "        \"X‑D\":\"smiley\",\n",
        "        \":D\":\"smiley\",\n",
        "        \"8D\":\"smiley\",\n",
        "        \"xD\":\"smiley\",\n",
        "        \"XD\":\"smiley\",\n",
        "        \":‑(\":\"sad\",\n",
        "        \":‑c\":\"sad\",\n",
        "        \":‑<\":\"sad\",\n",
        "        \":‑[\":\"sad\",\n",
        "        \":(\":\"sad\",\n",
        "        \":c\":\"sad\",\n",
        "        \":<\":\"sad\",\n",
        "        \":[\":\"sad\",\n",
        "        \":-||\":\"sad\",\n",
        "        \">:[\":\"sad\",\n",
        "        \":{\":\"sad\",\n",
        "        \":@\":\"sad\",\n",
        "        \">:(\":\"sad\",\n",
        "        \":'‑(\":\"sad\",\n",
        "        \":'(\":\"sad\",\n",
        "        \":‑P\":\"playful\",\n",
        "        \"X‑P\":\"playful\",\n",
        "        \"x‑p\":\"playful\",\n",
        "        \":‑p\":\"playful\",\n",
        "        \":‑Þ\":\"playful\",\n",
        "        \":‑þ\":\"playful\",\n",
        "        \":‑b\":\"playful\",\n",
        "        \":P\":\"playful\",\n",
        "        \"XP\":\"playful\",\n",
        "        \"xp\":\"playful\",\n",
        "        \":p\":\"playful\",\n",
        "        \":Þ\":\"playful\",\n",
        "        \":þ\":\"playful\",\n",
        "        \":b\":\"playful\",\n",
        "        \"<3\":\"love\"\n",
        "        }\n",
        "\n",
        "def load_dict_contractions():\n",
        "    \n",
        "    return {\n",
        "        \"ain't\":\"is not\",\n",
        "        \"amn't\":\"am not\",\n",
        "        \"aren't\":\"are not\",\n",
        "        \"can't\":\"cannot\",\n",
        "        \"'cause\":\"because\",\n",
        "        \"couldn't\":\"could not\",\n",
        "        \"couldn't've\":\"could not have\",\n",
        "        \"could've\":\"could have\",\n",
        "        \"daren't\":\"dare not\",\n",
        "        \"daresn't\":\"dare not\",\n",
        "        \"dasn't\":\"dare not\",\n",
        "        \"didn't\":\"did not\",\n",
        "        \"doesn't\":\"does not\",\n",
        "        \"don't\":\"do not\",\n",
        "        \"e'er\":\"ever\",\n",
        "        \"em\":\"them\",\n",
        "        \"everyone's\":\"everyone is\",\n",
        "        \"finna\":\"fixing to\",\n",
        "        \"gimme\":\"give me\",\n",
        "        \"gonna\":\"going to\",\n",
        "        \"gon't\":\"go not\",\n",
        "        \"gotta\":\"got to\",\n",
        "        \"hadn't\":\"had not\",\n",
        "        \"hasn't\":\"has not\",\n",
        "        \"haven't\":\"have not\",\n",
        "        \"he'd\":\"he would\",\n",
        "        \"he'll\":\"he will\",\n",
        "        \"he's\":\"he is\",\n",
        "        \"he've\":\"he have\",\n",
        "        \"how'd\":\"how would\",\n",
        "        \"how'll\":\"how will\",\n",
        "        \"how're\":\"how are\",\n",
        "        \"how's\":\"how is\",\n",
        "        \"I'd\":\"I would\",\n",
        "        \"I'll\":\"I will\",\n",
        "        \"I'm\":\"I am\",\n",
        "        \"I'm'a\":\"I am about to\",\n",
        "        \"I'm'o\":\"I am going to\",\n",
        "        \"isn't\":\"is not\",\n",
        "        \"it'd\":\"it would\",\n",
        "        \"it'll\":\"it will\",\n",
        "        \"it's\":\"it is\",\n",
        "        \"I've\":\"I have\",\n",
        "        \"kinda\":\"kind of\",\n",
        "        \"let's\":\"let us\",\n",
        "        \"mayn't\":\"may not\",\n",
        "        \"may've\":\"may have\",\n",
        "        \"mightn't\":\"might not\",\n",
        "        \"might've\":\"might have\",\n",
        "        \"mustn't\":\"must not\",\n",
        "        \"mustn't've\":\"must not have\",\n",
        "        \"must've\":\"must have\",\n",
        "        \"needn't\":\"need not\",\n",
        "        \"ne'er\":\"never\",\n",
        "        \"o'\":\"of\",\n",
        "        \"o'er\":\"over\",\n",
        "        \"ol'\":\"old\",\n",
        "        \"oughtn't\":\"ought not\",\n",
        "        \"shalln't\":\"shall not\",\n",
        "        \"shan't\":\"shall not\",\n",
        "        \"she'd\":\"she would\",\n",
        "        \"she'll\":\"she will\",\n",
        "        \"she's\":\"she is\",\n",
        "        \"shouldn't\":\"should not\",\n",
        "        \"shouldn't've\":\"should not have\",\n",
        "        \"should've\":\"should have\",\n",
        "        \"somebody's\":\"somebody is\",\n",
        "        \"someone's\":\"someone is\",\n",
        "        \"something's\":\"something is\",\n",
        "        \"that'd\":\"that would\",\n",
        "        \"that'll\":\"that will\",\n",
        "        \"that're\":\"that are\",\n",
        "        \"that's\":\"that is\",\n",
        "        \"there'd\":\"there would\",\n",
        "        \"there'll\":\"there will\",\n",
        "        \"there're\":\"there are\",\n",
        "        \"there's\":\"there is\",\n",
        "        \"these're\":\"these are\",\n",
        "        \"they'd\":\"they would\",\n",
        "        \"they'll\":\"they will\",\n",
        "        \"they're\":\"they are\",\n",
        "        \"they've\":\"they have\",\n",
        "        \"this's\":\"this is\",\n",
        "        \"those're\":\"those are\",\n",
        "        \"'tis\":\"it is\",\n",
        "        \"'twas\":\"it was\",\n",
        "        \"wanna\":\"want to\",\n",
        "        \"wasn't\":\"was not\",\n",
        "        \"we'd\":\"we would\",\n",
        "        \"we'd've\":\"we would have\",\n",
        "        \"we'll\":\"we will\",\n",
        "        \"we're\":\"we are\",\n",
        "        \"weren't\":\"were not\",\n",
        "        \"we've\":\"we have\",\n",
        "        \"what'd\":\"what did\",\n",
        "        \"what'll\":\"what will\",\n",
        "        \"what're\":\"what are\",\n",
        "        \"what's\":\"what is\",\n",
        "        \"what've\":\"what have\",\n",
        "        \"when's\":\"when is\",\n",
        "        \"where'd\":\"where did\",\n",
        "        \"where're\":\"where are\",\n",
        "        \"where's\":\"where is\",\n",
        "        \"where've\":\"where have\",\n",
        "        \"which's\":\"which is\",\n",
        "        \"who'd\":\"who would\",\n",
        "        \"who'd've\":\"who would have\",\n",
        "        \"who'll\":\"who will\",\n",
        "        \"who're\":\"who are\",\n",
        "        \"who's\":\"who is\",\n",
        "        \"who've\":\"who have\",\n",
        "        \"why'd\":\"why did\",\n",
        "        \"why're\":\"why are\",\n",
        "        \"why's\":\"why is\",\n",
        "        \"won't\":\"will not\",\n",
        "        \"wouldn't\":\"would not\",\n",
        "        \"would've\":\"would have\",\n",
        "        \"y'all\":\"you all\",\n",
        "        \"you'd\":\"you would\",\n",
        "        \"you'll\":\"you will\",\n",
        "        \"you're\":\"you are\",\n",
        "        \"you've\":\"you have\",\n",
        "        \"Whatcha\":\"What are you\",\n",
        "        \"luv\":\"love\",\n",
        "        \"sux\":\"sucks\"\n",
        "        }\n",
        "\n",
        "def strip_accents(text):\n",
        "    if 'ø' in text or  'Ø' in text:\n",
        "        #Do nothing when finding ø \n",
        "        return text   \n",
        "    text = text.encode('ascii', 'ignore')\n",
        "    text = text.decode(\"utf-8\")\n",
        "    return str(text)\n",
        "\n",
        "def tweet_cleaning_for_sentiment_analysis(tweet):    \n",
        "    \n",
        "    #Escaping HTML characters\n",
        "    tweet = BeautifulSoup(tweet).get_text()\n",
        "    #Special case not handled previously.\n",
        "    tweet = tweet.replace('\\x92',\"'\")\n",
        "    #Removal of hastags/account\n",
        "    #tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", tweet).split())\n",
        "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)\", \"USER\", tweet).split())\n",
        "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \")\n",
        "    #Removal of address\n",
        "    tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
        "    #Removal of Punctuation\n",
        "    tweet = ' '.join(re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=]\", \" \", tweet).split())\n",
        "    #Lower case\n",
        "    tweet = tweet.lower()\n",
        "    #CONTRACTIONS source: https://en.wikipedia.org/wiki/Contraction_%28grammar%29\n",
        "    CONTRACTIONS = load_dict_contractions()\n",
        "    tweet = tweet.replace(\"’\",\"'\")\n",
        "    words = tweet.split()\n",
        "    reformed = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    # Standardizing words\n",
        "    tweet = ''.join(''.join(s)[:2] for _, s in itertools.groupby(tweet))\n",
        "    #Deal with smileys\n",
        "    #source: https://en.wikipedia.org/wiki/List_of_emoticons\n",
        "    SMILEY = load_dict_smileys()  \n",
        "    words = tweet.split()\n",
        "    reformed = [SMILEY[word] if word in SMILEY else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    #Strip accents\n",
        "    tweet= strip_accents(tweet)\n",
        "    tweet = tweet.replace(\":\",\" \")\n",
        "    tweet = ' '.join(tweet.split())\n",
        "    \n",
        "    # DO NOT REMOVE STOP WORDS FOR SENTIMENT ANALYSIS - OR AT LEAST NOT NEGATIVE ONES\n",
        "\n",
        "    return tweet"
      ],
      "metadata": {
        "id": "FpznLawAN4tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkUIvhBSN4tP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word embeddings"
      ],
      "metadata": {
        "id": "2gYoJAjZN4tc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download embedddings"
      ],
      "metadata": {
        "id": "6JncIL3WN4ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir fasttext-embeddings\n",
        "%cd fasttext-embeddings\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
        "!unzip crawl-300d-2M-subword.zip\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "0Px5Lhj-N4tk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67d1694-a8eb-4168-e50d-14d59158710e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fasttext-embeddings\n",
            "--2022-07-21 14:55:23--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5828358084 (5.4G) [application/zip]\n",
            "Saving to: ‘crawl-300d-2M-subword.zip’\n",
            "\n",
            "crawl-300d-2M-subwo 100%[===================>]   5.43G  32.1MB/s    in 3m 13s  \n",
            "\n",
            "2022-07-21 14:58:37 (28.8 MB/s) - ‘crawl-300d-2M-subword.zip’ saved [5828358084/5828358084]\n",
            "\n",
            "Archive:  crawl-300d-2M-subword.zip\n",
            "  inflating: crawl-300d-2M-subword.vec  \n",
            "  inflating: crawl-300d-2M-subword.bin  \n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir fasttext-embeddings\n",
        "%cd fasttext-embeddings\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M-subword.vec.zip\n",
        "!unzip wiki-news-300d-1M-subword.vec.zip\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JNrtdwdW92n",
        "outputId": "8bcb71d8-c025-472c-ad52-096d48ea23c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘fasttext-embeddings’: File exists\n",
            "/content/fasttext-embeddings\n",
            "--2022-07-21 15:24:21--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M-subword.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 587879973 (561M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M-subword.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M-s 100%[===================>] 560.65M  36.8MB/s    in 16s     \n",
            "\n",
            "2022-07-21 15:24:38 (34.7 MB/s) - ‘wiki-news-300d-1M-subword.vec.zip’ saved [587879973/587879973]\n",
            "\n",
            "Archive:  wiki-news-300d-1M-subword.vec.zip\n",
            "  inflating: wiki-news-300d-1M-subword.vec  \n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir fasttext-embeddings\n",
        "%cd fasttext-embeddings\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
        "!gzip -d cc.en.300.bin.gz\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTcdIBuzXr-a",
        "outputId": "8175877b-cad6-429c-bd9f-0f8a22b0431f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘fasttext-embeddings’: File exists\n",
            "/content/fasttext-embeddings\n",
            "--2022-07-21 15:28:31--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.en.300.bin.gz’\n",
            "\n",
            "cc.en.300.bin.gz    100%[===================>]   4.19G  28.1MB/s    in 2m 18s  \n",
            "\n",
            "2022-07-21 15:30:49 (31.2 MB/s) - ‘cc.en.300.bin.gz’ saved [4503593528/4503593528]\n",
            "\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir fasttext-embeddings\n",
        "# %cd fasttext-embeddings\n",
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
        "# !unzip crawl-300d-2M.vec.zip"
      ],
      "metadata": {
        "id": "qR9FR8XxN4tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "id": "uFr0Rl5DN4tq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0153bc2-7425-4713-9807-afa28401dcdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading model"
      ],
      "metadata": {
        "id": "fOm5JIDKN4tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# fasttext_emb = fasttext.load_model('/content/fasttext-embeddings/cc.en.300.bin')\n",
        "# print(ft.get_dimension())\n",
        "\n",
        "# fasttext.util.reduce_model(ft, 100)\n",
        "# print(ft.get_dimension())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "a0qol306Y0vl",
        "outputId": "cc7a0d25-c57a-42e7-8bf4-3cab33cc8ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-f87c31fcc971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfasttext_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/fasttext-embeddings/cc.en.300.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ft' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_emb = fasttext.FastText.load_model('./fasttext-embeddings/crawl-300d-2M-subword.bin')\n",
        "#fasttext_emb = fasttext.FastText.load_model('./fasttext-embeddings/wiki-news-300d-1M-subword.vec')"
      ],
      "metadata": {
        "id": "Q6OSoH3KN4tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_emb.get_nearest_neighbors(\"__user__\")"
      ],
      "metadata": {
        "id": "NQvuZQGPN4tw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd9cee2-f0d5-4ce6-ec61-f2d1ae052f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.6122851371765137, 'intrebari'),\n",
              " (0.6034965515136719, 'vmware-modconfig'),\n",
              " (0.5972209572792053, 'eclipselink-orm.xml'),\n",
              " (0.5965851545333862, 'base-config'),\n",
              " (0.5962321162223816, 'hostnamectl'),\n",
              " (0.5956684350967407, 'myconfig'),\n",
              " (0.593761146068573, 'webpack.config.js'),\n",
              " (0.5922401547431946, 'mkvirtualenv'),\n",
              " (0.5871965289115906, 'libxml2-dev'),\n",
              " (0.5849608182907104, 'jboss-service.xml')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data"
      ],
      "metadata": {
        "id": "lUKBYPK8N4tR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def prepare_data(filepath, embedding):\n",
        "#   data = pd.read_csv(filepath)\n",
        "#   data['cleaned_tweets'] = data.tweet.astype(str).apply(tweet_cleaning_for_sentiment_analysis)\n",
        "#   data['sent_vec'] = data.cleaned_tweets.apply(embedding.get_sentence_vector)\n",
        "\n",
        "#   data = data[['cleaned_tweets', 'sent_vec', 'label']]\n",
        "\n",
        "#   X = data.sent_vec.apply(lambda x: list(x)).values\n",
        "  \n",
        "#   return X, data.label.values"
      ],
      "metadata": {
        "id": "xfwMbs1YO_kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"train.csv\")\n",
        "data['cleaned_tweets'] = data.tweet.astype(str).apply(tweet_cleaning_for_sentiment_analysis)\n",
        "data['sent_vec'] = data.cleaned_tweets.apply(fasttext_emb.get_sentence_vector)\n",
        "\n",
        "\n",
        "with open(\"./pickled_data/train.pkl\", \"wb\") as f:\n",
        "  pickle.dump(data, f)\n",
        "\n",
        "del data"
      ],
      "metadata": {
        "id": "M6rpEQY_N4tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"dev.csv\")\n",
        "data['cleaned_tweets'] = data.tweet.astype(str).apply(tweet_cleaning_for_sentiment_analysis)\n",
        "data['sent_vec'] = data.cleaned_tweets.apply(fasttext_emb.get_sentence_vector)\n",
        "\n",
        "with open(\"./pickled_data/dev.pkl\", \"wb\") as f:\n",
        "  pickle.dump(data, f)\n",
        "\n",
        "del data"
      ],
      "metadata": {
        "id": "a_aucJytbyIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"test.csv\")\n",
        "data['cleaned_tweets'] = data.tweet.astype(str).apply(tweet_cleaning_for_sentiment_analysis)\n",
        "data['sent_vec'] = data.cleaned_tweets.apply(fasttext_emb.get_sentence_vector)\n",
        "\n",
        "with open(\"./pickled_data/test.pkl\", \"wb\") as f:\n",
        "  pickle.dump(data, f)\n",
        "\n",
        "del data"
      ],
      "metadata": {
        "id": "9zD_zuVscQaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(pickle_filepath):\n",
        "  data = pickle.load(open(pickle_filepath,'rb'))\n",
        "  \n",
        "  X = np.array(list(data.sent_vec.apply(lambda x: list(x)).values))\n",
        "  \n",
        "  return X, data.label.values"
      ],
      "metadata": {
        "id": "GFVE65jFcxBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r pickled_data.zip /content/pickled_data\n",
        "!cp pickled_data.zip /content/drive/MyDrive/Internship/Coffeebeans/data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83avitxid6hn",
        "outputId": "12503efd-7a63-49fb-8311-85661de8e707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: /content/pickled_data\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r pickled_data.zip . -i /content/pickled_data)\n",
            "cp: cannot stat 'pickled_data.zip': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/file/d/1KyBIlhLCH4RE6iEWTXRhoiAMe4KwUPFU/view?usp=sharing --fuzzy\n",
        "!unzip pickled_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AafVv6BjkNUV",
        "outputId": "2c1b4c47-8187-4f44-99ef-d9b540931e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KyBIlhLCH4RE6iEWTXRhoiAMe4KwUPFU\n",
            "To: /content/pickled_data.zip\n",
            "100% 226M/226M [00:01<00:00, 191MB/s]\n",
            "Archive:  pickled_data.zip\n",
            "   creating: content/pickled_data/\n",
            "  inflating: content/pickled_data/dev.pkl  \n",
            "  inflating: content/pickled_data/test.pkl  \n",
            "  inflating: content/pickled_data/train.pkl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, ytrain = prepare_data(\"./content/pickled_data/train.pkl\")\n",
        "Xdev, ydev = prepare_data(\"./content/pickled_data/dev.pkl\")"
      ],
      "metadata": {
        "id": "1xNvRWoeN4tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(ytrain).value_counts(\n",
        "  \n",
        ").to_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LQCT9E-TZ_c",
        "outputId": "ceb7cd75-805d-4117-f49e-160d2a2a54d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NEGATIVE': 29782, 'NEUTRAL': 52999, 'POSITIVE': 24242}"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "sampling = {'NEGATIVE': 29782, 'NEUTRAL': 29000, 'POSITIVE': 24242}\n",
        "\n",
        "under = RandomUnderSampler(sampling_strategy=sampling, random_state=2022)# first performing oversampling to minority class\n",
        "\n",
        "\n",
        "\n",
        "Xtrain_under, ytrain_under = under.fit_resample(Xtrain, ytrain)"
      ],
      "metadata": {
        "id": "gYP2LfcYIY6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and validation data"
      ],
      "metadata": {
        "id": "yIdNTEOKN4t5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "krJFni5eN4t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xtrain, Xval, ytrain, yval = train_test_split(X, data.label.values, random_state=2022,test_size=0.2, stratify=data.label.values)"
      ],
      "metadata": {
        "id": "FnGwKxQ8N4t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(ytrain).value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "SRoFskzVN4uA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9645fde-0ec2-4fb5-c593-324e39215a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEUTRAL     0.495211\n",
              "NEGATIVE    0.278277\n",
              "POSITIVE    0.226512\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(ydev).value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "ntmHEMqhN4uB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f375e9-7392-40cc-ad47-ad41abb5a013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEUTRAL     0.497282\n",
              "NEGATIVE    0.277425\n",
              "POSITIVE    0.225293\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain.shape, ytrain.shape"
      ],
      "metadata": {
        "id": "uHP1bSZfN4uF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a06298-6ddf-480b-9f8a-a50a240351bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((107023, 300), (107023,))"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "# count_vect.fit(data['tweet'])\n",
        "\n",
        "# # transform the training and validation data using count vectorizer object\n",
        "\n",
        "# x_count =  count_vect.transform(data['tweet'])\n",
        "\n",
        "# X_count_train, X_count_val, y_count_train, y_count_val = train_test_split(x_count, data.label, random_state=2022,test_size=0.2, stratify=data.label)\n",
        "\n",
        "# X_count_train.shape"
      ],
      "metadata": {
        "id": "L1MNQ4-dN4uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "9hDGSsViN4uP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "5R_1bDJ7eSlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_weights = class_weight.compute_sample_weight(\n",
        "    class_weight='balanced',\n",
        "    y=ytrain\n",
        ")"
      ],
      "metadata": {
        "id": "3Lr1VQo1N4uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
        "                                                 classes = np.unique(ytrain),\n",
        "                                                 y = ytrain)\n",
        "class_weights"
      ],
      "metadata": {
        "id": "SskSq1O9N4uU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cbb0b1b-f3d4-47ef-804c-d5ea6b09407f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.19784881, 0.67311333, 1.471592  ])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_model = XGBClassifier(max_depth=7, \n",
        "                          n_estimators=1000, \n",
        "                          gamma=0.5,\n",
        "                          min_child_weight=5,\n",
        "                          eta=0.5,\n",
        "                          random_state=2022,\n",
        "                          tree_method = \"gpu_hist\", \n",
        "                          single_precision_histogram=True)\n",
        "\n",
        "# 'n_estimators':[500],\n",
        "#     'min_child_weight':[4,5], \n",
        "#     'gamma':[i/10.0 for i in range(3,6)],  \n",
        "#     'subsample':[i/10.0 for i in range(6,11)],\n",
        "#     'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
        "#     'max_depth': [2,3,4,6,7],\n",
        "#     'objective': ['reg:squarederror', 'reg:tweedie'],\n",
        "#     'booster': ['gbtree', 'gblinear'],\n",
        "#     'eval_metric': ['rmse'],\n",
        "#     'eta': [i/10.0 for i in range(3,6)],\n",
        "\n",
        "xgb_model.fit(Xtrain, ytrain, sample_weight=classes_weights) \n"
      ],
      "metadata": {
        "id": "qMBk-p_AN4uV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbe5d7e-0671-4294-9349-581cef243f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(eta=0.5, gamma=0.5, max_depth=7, min_child_weight=5,\n",
              "              n_estimators=1000, objective='multi:softprob', random_state=2022,\n",
              "              single_precision_histogram=True, tree_method='gpu_hist')"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = xgb_model.predict(Xdev)\n",
        "print(classification_report(prediction, ydev)) #Sample weight"
      ],
      "metadata": {
        "id": "0yRZntGCN4uX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f35366-6f93-4f82-fdb2-62e3f3e54717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.68      0.78      0.73      3701\n",
            "     NEUTRAL       0.92      0.82      0.87      8473\n",
            "    POSITIVE       0.74      0.82      0.78      3095\n",
            "\n",
            "    accuracy                           0.81     15269\n",
            "   macro avg       0.78      0.81      0.79     15269\n",
            "weighted avg       0.82      0.81      0.82     15269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = xgb_model.predict(Xdev)\n",
        "print(classification_report(prediction, ydev)) #Sample weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GMwH7exhhT8",
        "outputId": "3d45c64d-ec08-405f-9967-0bb2ed465a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.67      0.79      0.73      3593\n",
            "     NEUTRAL       0.92      0.82      0.87      8609\n",
            "    POSITIVE       0.73      0.82      0.78      3067\n",
            "\n",
            "    accuracy                           0.81     15269\n",
            "   macro avg       0.78      0.81      0.79     15269\n",
            "weighted avg       0.83      0.81      0.82     15269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBClassifier(max_depth=6, n_estimators=1000, objective='multi:softprob',\n",
        "#               single_precision_histogram=True, tree_method='gpu_hist')\n",
        "\n",
        "prediction = xgb_model.predict(Xdev)\n",
        "print(classification_report(ydev, prediction)) #Sample weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJeb6jDph8EL",
        "outputId": "e8ef0e7c-d826-4d6b-9fdd-5e18fb6086c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.78      0.68      0.72      4236\n",
            "     NEUTRAL       0.82      0.91      0.86      7593\n",
            "    POSITIVE       0.81      0.74      0.77      3440\n",
            "\n",
            "    accuracy                           0.81     15269\n",
            "   macro avg       0.80      0.78      0.79     15269\n",
            "weighted avg       0.81      0.81      0.80     15269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBClassifier(eta=0.5, gamma=0.5, max_depth=7, min_child_weight=5,\n",
        "#               n_estimators=1000, objective='multi:softprob',\n",
        "#               single_precision_histogram=True, tree_method='gpu_hist')\n",
        "\n",
        "prediction = xgb_model.predict(Xdev)\n",
        "print(classification_report(ydev, prediction)) #Sample weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZIzsjcJiRG8",
        "outputId": "922f14ff-cc9d-483f-cf2b-4ebe61b91353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.80      0.67      0.73      4236\n",
            "     NEUTRAL       0.82      0.93      0.87      7593\n",
            "    POSITIVE       0.82      0.73      0.78      3440\n",
            "\n",
            "    accuracy                           0.81     15269\n",
            "   macro avg       0.81      0.78      0.79     15269\n",
            "weighted avg       0.81      0.81      0.81     15269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = xgb_model.predict(Xdev)\n",
        "print(classification_report(ydev, prediction)) #Sample weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5SkisR4i1hd",
        "outputId": "fa2f19ae-247f-45a1-b316-dbc39cf79bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.79      0.68      0.73      4236\n",
            "     NEUTRAL       0.82      0.92      0.87      7593\n",
            "    POSITIVE       0.82      0.73      0.78      3440\n",
            "\n",
            "    accuracy                           0.81     15269\n",
            "   macro avg       0.81      0.78      0.79     15269\n",
            "weighted avg       0.81      0.81      0.81     15269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = xgb_model.predict(Xdev)\n",
        "print(classification_report(ydev, prediction)) #Sample weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZjwrG8ek3zN",
        "outputId": "9decbca2-3284-4739-8c1e-9823e940c9e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.77      0.68      0.72      4236\n",
            "     NEUTRAL       0.83      0.90      0.86      7593\n",
            "    POSITIVE       0.79      0.74      0.77      3440\n",
            "\n",
            "    accuracy                           0.80     15269\n",
            "   macro avg       0.79      0.77      0.78     15269\n",
            "weighted avg       0.80      0.80      0.80     15269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model.save_model(\"./models/finaldata_xgboost_model.json\")"
      ],
      "metadata": {
        "id": "hsxKGPLgnr4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(prediction, y_count_val)) #Count Vectorizer"
      ],
      "metadata": {
        "id": "UNLC27deN4ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(prediction, yval)) #Fasttext"
      ],
      "metadata": {
        "id": "xuRHReTIN4uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(prediction, yval)) #Sample weight"
      ],
      "metadata": {
        "id": "aSNFqDyUN4ue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc910d9e-05a3-4ce8-dbc6-90890049db44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.66      0.78      0.72      5028\n",
            "     NEUTRAL       0.92      0.81      0.86     12046\n",
            "    POSITIVE       0.72      0.81      0.76      4331\n",
            "\n",
            "    accuracy                           0.80     21405\n",
            "   macro avg       0.77      0.80      0.78     21405\n",
            "weighted avg       0.82      0.80      0.81     21405\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(prediction, yval)) #Sample weight"
      ],
      "metadata": {
        "id": "7V6Q0SpGN4ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "zsHfYPUON4ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def randomsearch():\n",
        "  n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 15)]\n",
        "  # Number of features to consider at every split\n",
        "  max_features = ['auto', 'sqrt']\n",
        "  # Maximum number of levels in tree\n",
        "  max_depth = [int(x) for x in np.linspace(10, 200, num = 10)]\n",
        "  max_depth.append(None)\n",
        "  # Minimum number of samples required to split a node\n",
        "  min_samples_split = [2, 4, 8, 16,32]\n",
        "  # Minimum number of samples required at each leaf node\n",
        "  min_samples_leaf = [1, 2, 4,8,16]\n",
        "  # Method of selecting samples for training each tree\n",
        "  bootstrap = [True, False]# Create the random grid\n",
        "  random_grid = {'n_estimators': n_estimators,\n",
        "                'max_features': max_features,\n",
        "                'max_depth': max_depth,\n",
        "                'min_samples_split': min_samples_split,\n",
        "                'min_samples_leaf': min_samples_leaf,\n",
        "                'bootstrap': bootstrap}\n",
        "                \n",
        "  pprint(random_grid,compact=True)\n",
        "  \n",
        "  return random_grid\n",
        "\n",
        "_ =randomsearch()"
      ],
      "metadata": {
        "id": "C2tlsKHTN4uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(xgb_model, open(\"/content/models/finaldata_xgboost_model.pkl\", \"wb\"))\n",
        "\n",
        "import joblib\n",
        "joblib.dump(xgb_model, \"/content/models/finaldata_xgboost_model.joblib\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thgp6NTDmBg4",
        "outputId": "c725ec6c-9d9a-405f-ea45-04aa32ad33cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/models/finaldata_xgboost_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost - Undersampling"
      ],
      "metadata": {
        "id": "AqBdDFZpT7Ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "vZqb3W2KT7Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_weights = class_weight.compute_sample_weight(\n",
        "    class_weight='balanced',\n",
        "    y=ytrain_under\n",
        ")"
      ],
      "metadata": {
        "id": "cPUDSYvGT7Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
        "                                                 classes = np.unique(ytrain),\n",
        "                                                 y = ytrain_under)\n",
        "class_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd0e0de-1d72-430b-db25-b6d404957f2e",
        "id": "0lkVgnjQT7Nh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.92924138, 0.95429885, 1.14159998])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_model = XGBClassifier(max_depth=8, \n",
        "                          n_estimators=1000, \n",
        "                          gamma=0.5,\n",
        "                          min_child_weight=5,\n",
        "                          eta=0.5,\n",
        "                          random_state=2022,\n",
        "                          tree_method = \"gpu_hist\", \n",
        "                          single_precision_histogram=True)\n",
        "\n",
        "# 'n_estimators':[500],\n",
        "#     'min_child_weight':[4,5], \n",
        "#     'gamma':[i/10.0 for i in range(3,6)],  \n",
        "#     'subsample':[i/10.0 for i in range(6,11)],\n",
        "#     'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
        "#     'max_depth': [2,3,4,6,7],\n",
        "#     'objective': ['reg:squarederror', 'reg:tweedie'],\n",
        "#     'booster': ['gbtree', 'gblinear'],\n",
        "#     'eval_metric': ['rmse'],\n",
        "#     'eta': [i/10.0 for i in range(3,6)],\n",
        "\n",
        "xgb_model.fit(Xtrain_under, ytrain_under) \n"
      ],
      "metadata": {
        "id": "WTtBClTDT7Ni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b21fa9ef-35f0-4932-8bab-adae5ba6f3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(eta=0.5, gamma=0.5, max_depth=8, min_child_weight=5,\n",
              "              n_estimators=1000, objective='multi:softprob', random_state=2022,\n",
              "              single_precision_histogram=True, tree_method='gpu_hist')"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGgWkht8VwmZ",
        "outputId": "93f1a82c-082c-4754-ec6d-88e7e7a0ab92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(eta=0.5, gamma=0.5, max_depth=8, min_child_weight=5,\n",
              "              n_estimators=1000, objective='multi:softprob', random_state=2022,\n",
              "              single_precision_histogram=True, tree_method='gpu_hist')"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBClassifier(eta=0.5, gamma=0.5, max_depth=7, min_child_weight=5,\n",
        "#               n_estimators=1000, objective='multi:softprob', random_state=2022,\n",
        "#               single_precision_histogram=True, tree_method='gpu_hist')\n",
        "prediction = xgb_model.predict(Xdev)\n",
        "print(classification_report(prediction, ydev)) #Sample weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7baff6fe-4af7-4e0d-ee6f-4d1773ccc8a1",
        "id": "Jdb1NAXHT7Nk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.73      0.74      0.74      4182\n",
            "     NEUTRAL       0.88      0.84      0.86      7929\n",
            "    POSITIVE       0.74      0.81      0.77      3158\n",
            "\n",
            "    accuracy                           0.81     15269\n",
            "   macro avg       0.78      0.80      0.79     15269\n",
            "weighted avg       0.81      0.81      0.81     15269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBClassifier(eta=0.5, gamma=0.5, max_depth=5, min_child_weight=7,\n",
        "#               n_estimators=1000, objective='multi:softprob', random_state=2022,\n",
        "#               single_precision_histogram=True, tree_method='gpu_hist')\n",
        "\n",
        "prediction = xgb_model.predict(Xdev)\n",
        "print(classification_report(prediction, ydev)) #Sample weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e72025c8-3b3d-4444-bbb6-618e9d228852",
        "id": "LLBYhKLBT7Nl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.72      0.73      0.73      4195\n",
            "     NEUTRAL       0.87      0.84      0.85      7806\n",
            "    POSITIVE       0.75      0.79      0.77      3268\n",
            "\n",
            "    accuracy                           0.80     15269\n",
            "   macro avg       0.78      0.79      0.78     15269\n",
            "weighted avg       0.80      0.80      0.80     15269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBClassifier(eta=0.5, gamma=0.5, max_depth=8, min_child_weight=5,\n",
        "#               n_estimators=1000, objective='multi:softprob', random_state=2022,\n",
        "#               single_precision_histogram=True, tree_method='gpu_hist')\n",
        "\n",
        "prediction = xgb_model.predict(Xdev)\n",
        "print(classification_report(ydev, prediction)) #Sample weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a8202d-819f-46d3-c5d7-dfab9694a8e9",
        "id": "pZ-NcgPeT7Nl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.75      0.73      0.74      4236\n",
            "     NEUTRAL       0.84      0.89      0.86      7593\n",
            "    POSITIVE       0.81      0.74      0.78      3440\n",
            "\n",
            "    accuracy                           0.81     15269\n",
            "   macro avg       0.80      0.79      0.79     15269\n",
            "weighted avg       0.81      0.81      0.81     15269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBClassifier(eta=0.5, gamma=0.5, max_depth=7, min_child_weight=5,\n",
        "#               n_estimators=1000, objective='multi:softprob',\n",
        "#               single_precision_histogram=True, tree_method='gpu_hist')\n",
        "\n",
        "prediction = xgb_model.predict(Xdev)\n",
        "print(classification_report(ydev, prediction)) #Sample weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "922f14ff-cc9d-483f-cf2b-4ebe61b91353",
        "id": "7vK-Zz5BT7Nm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.80      0.67      0.73      4236\n",
            "     NEUTRAL       0.82      0.93      0.87      7593\n",
            "    POSITIVE       0.82      0.73      0.78      3440\n",
            "\n",
            "    accuracy                           0.81     15269\n",
            "   macro avg       0.81      0.78      0.79     15269\n",
            "weighted avg       0.81      0.81      0.81     15269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = xgb_model.predict(Xdev)\n",
        "print(classification_report(ydev, prediction)) #Sample weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa2f19ae-247f-45a1-b316-dbc39cf79bed",
        "id": "NdGyJun4T7Nm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.79      0.68      0.73      4236\n",
            "     NEUTRAL       0.82      0.92      0.87      7593\n",
            "    POSITIVE       0.82      0.73      0.78      3440\n",
            "\n",
            "    accuracy                           0.81     15269\n",
            "   macro avg       0.81      0.78      0.79     15269\n",
            "weighted avg       0.81      0.81      0.81     15269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = xgb_model.predict(Xdev)\n",
        "print(classification_report(ydev, prediction)) #Sample weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9decbca2-3284-4739-8c1e-9823e940c9e9",
        "id": "T-San5FWT7Nn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.77      0.68      0.72      4236\n",
            "     NEUTRAL       0.83      0.90      0.86      7593\n",
            "    POSITIVE       0.79      0.74      0.77      3440\n",
            "\n",
            "    accuracy                           0.80     15269\n",
            "   macro avg       0.79      0.77      0.78     15269\n",
            "weighted avg       0.80      0.80      0.80     15269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model.save_model(\"./models/finaldata_xgboost_model.json\")"
      ],
      "metadata": {
        "id": "JoNhKT6vT7No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(prediction, y_count_val)) #Count Vectorizer"
      ],
      "metadata": {
        "id": "0jS2XsqGT7No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(prediction, yval)) #Fasttext"
      ],
      "metadata": {
        "id": "k6_XGOjrT7Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(prediction, yval)) #Sample weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc910d9e-05a3-4ce8-dbc6-90890049db44",
        "id": "FTQRhbEkT7Nq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.66      0.78      0.72      5028\n",
            "     NEUTRAL       0.92      0.81      0.86     12046\n",
            "    POSITIVE       0.72      0.81      0.76      4331\n",
            "\n",
            "    accuracy                           0.80     21405\n",
            "   macro avg       0.77      0.80      0.78     21405\n",
            "weighted avg       0.82      0.80      0.81     21405\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(prediction, yval)) #Sample weight"
      ],
      "metadata": {
        "id": "IbfEc38KT7Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "SUMWfIsLT7Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def randomsearch():\n",
        "  n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 15)]\n",
        "  # Number of features to consider at every split\n",
        "  max_features = ['auto', 'sqrt']\n",
        "  # Maximum number of levels in tree\n",
        "  max_depth = [int(x) for x in np.linspace(10, 200, num = 10)]\n",
        "  max_depth.append(None)\n",
        "  # Minimum number of samples required to split a node\n",
        "  min_samples_split = [2, 4, 8, 16,32]\n",
        "  # Minimum number of samples required at each leaf node\n",
        "  min_samples_leaf = [1, 2, 4,8,16]\n",
        "  # Method of selecting samples for training each tree\n",
        "  bootstrap = [True, False]# Create the random grid\n",
        "  random_grid = {'n_estimators': n_estimators,\n",
        "                'max_features': max_features,\n",
        "                'max_depth': max_depth,\n",
        "                'min_samples_split': min_samples_split,\n",
        "                'min_samples_leaf': min_samples_leaf,\n",
        "                'bootstrap': bootstrap}\n",
        "                \n",
        "  pprint(random_grid,compact=True)\n",
        "  \n",
        "  return random_grid\n",
        "\n",
        "_ =randomsearch()"
      ],
      "metadata": {
        "id": "3_H8FffuT7Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(xgb_model, open(\"/content/models/finaldata_xgboost_model_undersampled.pkl\", \"wb\"))\n",
        "\n",
        "import joblib\n",
        "joblib.dump(xgb_model, \"/content/models/finaldata_xgboost_model_undersampled.joblib\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVQhN897n_Tj",
        "outputId": "8baf3a11-deca-47cf-bb50-36ffbb1ac904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/models/finaldata_xgboost_model_undersampled.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "Z-L5hfXHn7YX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "-esCEttiN4uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_grid = randomsearch()\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=4, random_state=2022, n_jobs = -1)# Fit the random search model\n",
        "rf_random.fit(Xtrain, ytrain)\n",
        "\n",
        "\n",
        "best_random = rf_random.best_estimator_\n",
        "\n",
        "print(\"Paramters:\")\n",
        "pprint(rf_random.best_params_)\n",
        "\n",
        "print(\"Training\")\n",
        "print(classification_report(ytrain,best_random.predict(Xtrain)))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Testing\")\n",
        "print(classification_report(yval,best_random.predict(Xval)))"
      ],
      "metadata": {
        "id": "sBfb9S4gN4ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " rf = RandomForestClassifier(max_features='log2', max_depth=7, class_weight='balanced', random_state=2022, n_jobs=-1)\n",
        " rf.fit(Xtrain, ytrain)"
      ],
      "metadata": {
        "id": "eqbtkSxoN4u_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "954ec842-e14c-4b61-bf32-0f7e9b8df18b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced', max_features='log2', n_jobs=-1,\n",
              "                       random_state=2022)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = rf.predict(Xdev)\n",
        "print(classification_report(ydev, predictions)) #Random forest"
      ],
      "metadata": {
        "id": "35P0FF0xN4vC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8001f25b-d017-4aed-8b8f-2e5478dba469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.75      0.51      0.61      4236\n",
            "     NEUTRAL       0.75      0.96      0.84      7593\n",
            "    POSITIVE       0.81      0.63      0.71      3440\n",
            "\n",
            "    accuracy                           0.76     15269\n",
            "   macro avg       0.77      0.70      0.72     15269\n",
            "weighted avg       0.76      0.76      0.75     15269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(rf, \"./models/finaldata_random_forest.joblib\", compress=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxP3cQNTzkDk",
        "outputId": "961c0153-7707-40a0-cb01-995b9936409f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./models/finaldata_random_forest.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'n_estimators':[500],\n",
        "    'min_child_weight':[4,5], \n",
        "    'gamma':[i/10.0 for i in range(3,6)],  \n",
        "    'subsample':[i/10.0 for i in range(6,11)],\n",
        "    'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
        "    'max_depth': [2,3,4,6,7],\n",
        "    'objective': ['reg:squarederror', 'reg:tweedie'],\n",
        "    'booster': ['gbtree', 'gblinear'],\n",
        "    'eval_metric': ['rmse'],\n",
        "    'eta': [i/10.0 for i in range(3,6)],\n",
        "}\n",
        "\n",
        "reg = XGBClassifier(tree_method = \"gpu_hist\", single_precision_histogram=True)\n",
        "\n",
        "# run randomized search\n",
        "n_iter_search = 100\n",
        "random_search = RandomizedSearchCV(reg, param_distributions=params, random_state = 2022,\n",
        "                                   n_iter=n_iter_search, cv=3, scoring='neg_mean_squared_error')\n",
        "\n"
      ],
      "metadata": {
        "id": "WYkvIIKRN4vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_search.fit(Xtrain, ytrain, sample_weight=classes_weights)"
      ],
      "metadata": {
        "id": "D0xonldifPmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest - Undersampling"
      ],
      "metadata": {
        "id": "DeNWf51kWPeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "kfhvg6YfWPej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_grid = randomsearch()\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=4, random_state=2022, n_jobs = -1)# Fit the random search model\n",
        "rf_random.fit(Xtrain, ytrain)\n",
        "\n",
        "\n",
        "best_random = rf_random.best_estimator_\n",
        "\n",
        "print(\"Paramters:\")\n",
        "pprint(rf_random.best_params_)\n",
        "\n",
        "print(\"Training\")\n",
        "print(classification_report(ytrain,best_random.predict(Xtrain)))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Testing\")\n",
        "print(classification_report(yval,best_random.predict(Xval)))"
      ],
      "metadata": {
        "id": "fHV2JNvOWPel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " rf = RandomForestClassifier(max_features='sqrt', max_depth=9, class_weight='balanced', random_state=2022, n_jobs=-1)\n",
        " rf.fit(Xtrain, ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d6d9cb3-f01a-448a-f47e-fbb817719d52",
        "id": "ri6o7f-IWPem"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced', max_depth=9,\n",
              "                       max_features='sqrt', n_jobs=-1, random_state=2022)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForestClassifier(class_weight='balanced', max_depth=7,\n",
        "#                        max_features='log2', n_jobs=-1, random_state=2022)\n",
        "\n",
        "predictions = rf.predict(Xdev)\n",
        "print(classification_report(ydev, predictions)) #Random forest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63f50c84-6ed9-46c5-db3b-0c7c50a3bd2a",
        "id": "O9vBvhOKWPeo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.74      0.36      0.49      4236\n",
            "     NEUTRAL       0.74      0.94      0.83      7593\n",
            "    POSITIVE       0.63      0.66      0.65      3440\n",
            "\n",
            "    accuracy                           0.71     15269\n",
            "   macro avg       0.70      0.65      0.65     15269\n",
            "weighted avg       0.72      0.71      0.69     15269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForestClassifier(class_weight='balanced', max_depth=7,\n",
        "#                        max_features='sqrt', n_jobs=-1, random_state=2022)\n",
        "\n",
        "predictions = rf.predict(Xdev)\n",
        "print(classification_report(ydev, predictions)) #Random forest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnXQ7iYUWupU",
        "outputId": "567fad66-a058-404a-f1d6-ca99182aa4cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.72      0.40      0.52      4236\n",
            "     NEUTRAL       0.74      0.93      0.83      7593\n",
            "    POSITIVE       0.65      0.64      0.64      3440\n",
            "\n",
            "    accuracy                           0.72     15269\n",
            "   macro avg       0.70      0.66      0.66     15269\n",
            "weighted avg       0.72      0.72      0.70     15269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForestClassifier(class_weight='balanced', max_depth=9,\n",
        "#                        max_features='sqrt', n_jobs=-1, random_state=2022)\n",
        "\n",
        "predictions = rf.predict(Xdev)\n",
        "print(classification_report(ydev, predictions)) #Random forest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRC9B9JLataD",
        "outputId": "7f348266-c12d-4163-9936-0a6961e12ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.74      0.44      0.55      4236\n",
            "     NEUTRAL       0.75      0.94      0.83      7593\n",
            "    POSITIVE       0.68      0.65      0.67      3440\n",
            "\n",
            "    accuracy                           0.74     15269\n",
            "   macro avg       0.72      0.68      0.68     15269\n",
            "weighted avg       0.73      0.74      0.72     15269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(rf, \"./models/finaldata_random_forest_undersampled.joblib\", compress=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ddc334f-f797-4374-e1ab-4aca0398fab3",
        "id": "tCFnVDOWWPep"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./models/finaldata_random_forest_undersampled.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'n_estimators':[500],\n",
        "    'min_child_weight':[4,5], \n",
        "    'gamma':[i/10.0 for i in range(3,6)],  \n",
        "    'subsample':[i/10.0 for i in range(6,11)],\n",
        "    'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
        "    'max_depth': [2,3,4,6,7],\n",
        "    'objective': ['reg:squarederror', 'reg:tweedie'],\n",
        "    'booster': ['gbtree', 'gblinear'],\n",
        "    'eval_metric': ['rmse'],\n",
        "    'eta': [i/10.0 for i in range(3,6)],\n",
        "}\n",
        "\n",
        "reg = XGBClassifier(tree_method = \"gpu_hist\", single_precision_histogram=True)\n",
        "\n",
        "# run randomized search\n",
        "n_iter_search = 100\n",
        "random_search = RandomizedSearchCV(reg, param_distributions=params, random_state = 2022,\n",
        "                                   n_iter=n_iter_search, cv=3, scoring='neg_mean_squared_error')\n",
        "\n"
      ],
      "metadata": {
        "id": "kwmv6DftWPep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_search.fit(Xtrain, ytrain, sample_weight=classes_weights)"
      ],
      "metadata": {
        "id": "iWTxJnUKWPep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test data"
      ],
      "metadata": {
        "id": "iJZWhvIBN4vF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest, ytest = prepare_data(\"./content/pickled_data/test.pkl\")\n",
        "testdf = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "VMxyEuUlN4vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdf = pickle.load(open(\"./content/pickled_data/test.pkl\",\"rb\"))\n",
        "testdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "Laq0m4Ugpphw",
        "outputId": "6830a545-8b0e-42da-b8a8-06ca05287ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          label                                              tweet  \\\n",
              "0       NEUTRAL                     Effective but too-tepid biopic   \n",
              "1      POSITIVE  If you sometimes like to go to the movies to h...   \n",
              "2      POSITIVE  Emerges as something rare , an issue movie tha...   \n",
              "3       NEUTRAL  The film provides some great insight into the ...   \n",
              "4      POSITIVE  Offers that rare combination of entertainment ...   \n",
              "...         ...                                                ...   \n",
              "30545  NEGATIVE  Another Day - this movie requires you to watch...   \n",
              "30546  POSITIVE  Why aren't more films (especially American) mo...   \n",
              "30547  POSITIVE  Any film in the early days of Orson Welles is ...   \n",
              "30548  NEGATIVE  ...and it is this film. I imagine that if inde...   \n",
              "30549  NEGATIVE  Witchcraft/Witchery/La Casa 4/ and whatever el...   \n",
              "\n",
              "                                          cleaned_tweets  \\\n",
              "0                         effective but too tepid biopic   \n",
              "1      if you sometimes like to go to the movies to h...   \n",
              "2      emerges as something rare an issue movie that ...   \n",
              "3      the film provides some great insight into the ...   \n",
              "4      offers that rare combination of entertainment ...   \n",
              "...                                                  ...   \n",
              "30545  another day this movie requires you to watch i...   \n",
              "30546  why are not more films (especially american) m...   \n",
              "30547  any film in the early days of orson welles is ...   \n",
              "30548  and it is this film i imagine that if indeed t...   \n",
              "30549  witchcraft/witchery/la casa 4/ and whatever el...   \n",
              "\n",
              "                                                sent_vec  \n",
              "0      [0.005347706, 0.03154791, 0.07578029, 0.006786...  \n",
              "1      [0.0059573315, -0.03540754, 0.08914839, 0.0086...  \n",
              "2      [-0.009896653, 0.050302777, 0.09962972, 0.0017...  \n",
              "3      [0.00042353253, -0.02886739, 0.10362607, 0.020...  \n",
              "4      [-0.013658461, 0.021052698, 0.112356134, 0.049...  \n",
              "...                                                  ...  \n",
              "30545  [0.0075560594, -0.020790264, 0.080126695, 0.01...  \n",
              "30546  [0.002242105, -0.0093604475, 0.08441061, 0.006...  \n",
              "30547  [0.0020410304, -0.0238668, 0.09020886, 0.01618...  \n",
              "30548  [0.003267039, 0.00955246, 0.08873839, 0.007836...  \n",
              "30549  [-0.0044004945, -0.027519602, 0.09276428, 0.01...  \n",
              "\n",
              "[30550 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b40d0e78-26f8-4cde-acfa-a00e9bd95a48\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned_tweets</th>\n",
              "      <th>sent_vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>effective but too tepid biopic</td>\n",
              "      <td>[0.005347706, 0.03154791, 0.07578029, 0.006786...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>if you sometimes like to go to the movies to h...</td>\n",
              "      <td>[0.0059573315, -0.03540754, 0.08914839, 0.0086...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>emerges as something rare an issue movie that ...</td>\n",
              "      <td>[-0.009896653, 0.050302777, 0.09962972, 0.0017...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>The film provides some great insight into the ...</td>\n",
              "      <td>the film provides some great insight into the ...</td>\n",
              "      <td>[0.00042353253, -0.02886739, 0.10362607, 0.020...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>Offers that rare combination of entertainment ...</td>\n",
              "      <td>offers that rare combination of entertainment ...</td>\n",
              "      <td>[-0.013658461, 0.021052698, 0.112356134, 0.049...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30545</th>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>Another Day - this movie requires you to watch...</td>\n",
              "      <td>another day this movie requires you to watch i...</td>\n",
              "      <td>[0.0075560594, -0.020790264, 0.080126695, 0.01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30546</th>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>Why aren't more films (especially American) mo...</td>\n",
              "      <td>why are not more films (especially american) m...</td>\n",
              "      <td>[0.002242105, -0.0093604475, 0.08441061, 0.006...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30547</th>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>Any film in the early days of Orson Welles is ...</td>\n",
              "      <td>any film in the early days of orson welles is ...</td>\n",
              "      <td>[0.0020410304, -0.0238668, 0.09020886, 0.01618...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30548</th>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>...and it is this film. I imagine that if inde...</td>\n",
              "      <td>and it is this film i imagine that if indeed t...</td>\n",
              "      <td>[0.003267039, 0.00955246, 0.08873839, 0.007836...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30549</th>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>Witchcraft/Witchery/La Casa 4/ and whatever el...</td>\n",
              "      <td>witchcraft/witchery/la casa 4/ and whatever el...</td>\n",
              "      <td>[-0.0044004945, -0.027519602, 0.09276428, 0.01...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30550 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b40d0e78-26f8-4cde-acfa-a00e9bd95a48')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b40d0e78-26f8-4cde-acfa-a00e9bd95a48 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b40d0e78-26f8-4cde-acfa-a00e9bd95a48');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(ytest).value_counts()"
      ],
      "metadata": {
        "id": "n0EjWFRLN4vI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e72e5134-374b-4878-abe1-9f93871caf6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEUTRAL     15119\n",
              "NEGATIVE     8527\n",
              "POSITIVE     6904\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest.shape, ytest.shape"
      ],
      "metadata": {
        "id": "e2wnKq7dN4vN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a7a6565-3cdb-432c-ccd7-0238b4811cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30550, 300), (30550,))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmark dataset"
      ],
      "metadata": {
        "id": "64D0rCvBN4vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df = pd.read_excel(\"Sentiment models.xlsx\", engine='openpyxl')\n",
        "benchmark_df"
      ],
      "metadata": {
        "id": "mnr69VsiN4vk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3fc3982f-9e7c-4096-9cc9-e6d1591a689b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Tweets BERTweet  \\\n",
              "0    #GTvRR फायनल लढतीबाबत भाजपच्या नेत्याचा गंभीर ...  NEUTRAL   \n",
              "1    Umran Malik, Hardik Pandya among XI in Harbhaj...  NEUTRAL   \n",
              "2    दो साल से अर्जुन तेंदुलकर को मौका नहीं दे रही ...  NEUTRAL   \n",
              "3    TV 9 Special Report: सुब्रमण्यम स्वामी म्हणतात...  NEUTRAL   \n",
              "4    #IPL मतलब इंडियन पैसा लीग जीतने पर करोड़ों, हा...  NEUTRAL   \n",
              "..                                                 ...      ...   \n",
              "497  IPL 2022: Prashant Solanki reveals how MS Dhon...  NEUTRAL   \n",
              "498  David Warner was trolled by his fans for his c...  NEUTRAL   \n",
              "499  WATCH: Hardik Pandya consoles his wife Natasa ...  NEUTRAL   \n",
              "500  @humpty_dvn @kaustats Most dot balls in an IPL...  NEUTRAL   \n",
              "501  @kaustats He has also Bowled 200 dot balls in ...  NEUTRAL   \n",
              "\n",
              "    BERTweet_clean bert-base-multilingual-uncased-sentiment  \\\n",
              "0          NEUTRAL                                 POSITIVE   \n",
              "1          NEUTRAL                                 POSITIVE   \n",
              "2          NEUTRAL                                 NEGATIVE   \n",
              "3          NEUTRAL                                 NEGATIVE   \n",
              "4          NEUTRAL                                 NEGATIVE   \n",
              "..             ...                                      ...   \n",
              "497        NEUTRAL                                 POSITIVE   \n",
              "498        NEUTRAL                                 POSITIVE   \n",
              "499        NEUTRAL                                 NEGATIVE   \n",
              "500        NEUTRAL                                 NEGATIVE   \n",
              "501        NEUTRAL                                 POSITIVE   \n",
              "\n",
              "    bert-base-multilingual-uncased-sentiment_clean twitter-roberta  \\\n",
              "0                                         POSITIVE         NEUTRAL   \n",
              "1                                         POSITIVE         NEUTRAL   \n",
              "2                                         NEGATIVE         NEUTRAL   \n",
              "3                                         NEGATIVE         NEUTRAL   \n",
              "4                                         NEGATIVE         NEUTRAL   \n",
              "..                                             ...             ...   \n",
              "497                                       POSITIVE         NEUTRAL   \n",
              "498                                       POSITIVE        NEGATIVE   \n",
              "499                                       POSITIVE         NEUTRAL   \n",
              "500                                       POSITIVE         NEUTRAL   \n",
              "501                                       POSITIVE         NEUTRAL   \n",
              "\n",
              "    twitter-roberta_clean    VADER VADER_clean  \n",
              "0                 NEUTRAL  NEUTRAL     NEUTRAL  \n",
              "1                 NEUTRAL  NEUTRAL     NEUTRAL  \n",
              "2                 NEUTRAL  NEUTRAL     NEUTRAL  \n",
              "3                 NEUTRAL  NEUTRAL     NEUTRAL  \n",
              "4                 NEUTRAL  NEUTRAL     NEUTRAL  \n",
              "..                    ...      ...         ...  \n",
              "497               NEUTRAL  NEUTRAL     NEUTRAL  \n",
              "498               NEUTRAL  NEUTRAL     NEUTRAL  \n",
              "499               NEUTRAL  NEUTRAL     NEUTRAL  \n",
              "500               NEUTRAL  NEUTRAL     NEUTRAL  \n",
              "501               NEUTRAL  NEUTRAL     NEUTRAL  \n",
              "\n",
              "[502 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba257de7-aa00-4533-997e-ca484b3665e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweets</th>\n",
              "      <th>BERTweet</th>\n",
              "      <th>BERTweet_clean</th>\n",
              "      <th>bert-base-multilingual-uncased-sentiment</th>\n",
              "      <th>bert-base-multilingual-uncased-sentiment_clean</th>\n",
              "      <th>twitter-roberta</th>\n",
              "      <th>twitter-roberta_clean</th>\n",
              "      <th>VADER</th>\n",
              "      <th>VADER_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#GTvRR फायनल लढतीबाबत भाजपच्या नेत्याचा गंभीर ...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Umran Malik, Hardik Pandya among XI in Harbhaj...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>दो साल से अर्जुन तेंदुलकर को मौका नहीं दे रही ...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TV 9 Special Report: सुब्रमण्यम स्वामी म्हणतात...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#IPL मतलब इंडियन पैसा लीग जीतने पर करोड़ों, हा...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>IPL 2022: Prashant Solanki reveals how MS Dhon...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>David Warner was trolled by his fans for his c...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>WATCH: Hardik Pandya consoles his wife Natasa ...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>@humpty_dvn @kaustats Most dot balls in an IPL...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>@kaustats He has also Bowled 200 dot balls in ...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>502 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba257de7-aa00-4533-997e-ca484b3665e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba257de7-aa00-4533-997e-ca484b3665e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba257de7-aa00-4533-997e-ca484b3665e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df = benchmark_df[['Tweets']]"
      ],
      "metadata": {
        "id": "qgC02k9vN4vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df['cleaned_tweets'] = benchmark_df.Tweets.apply(tweet_cleaning_for_sentiment_analysis)\n",
        "benchmark_df['sent_vec'] = benchmark_df.cleaned_tweets.apply(fasttext_emb.get_sentence_vector)"
      ],
      "metadata": {
        "id": "0h_cvMCzN4vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df"
      ],
      "metadata": {
        "id": "8QwrAMUON4vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(list(benchmark_df.sent_vec.apply(lambda x: list(x)).values))\n",
        "benchmark_df['Random Forest'] = rf.predict(X)"
      ],
      "metadata": {
        "id": "q2ezksgpN4vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df['Random Forest'] = benchmark_df['Random Forest'].replace(0, 'Neutral')\n",
        "benchmark_df['Random Forest'] = benchmark_df['Random Forest'].replace(-1, 'Negative')\n",
        "benchmark_df['Random Forest'] = benchmark_df['Random Forest'].replace(1, 'Positive')\n",
        "\n",
        "benchmark_df"
      ],
      "metadata": {
        "id": "uF4mxZsaN4vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df['XGBoost'] = xgb_model.predict(X) \n",
        "benchmark_df"
      ],
      "metadata": {
        "id": "sTBusSIjN4vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df['XGBoost'] = benchmark_df['XGBoost'].replace(0, 'Neutral')\n",
        "benchmark_df['XGBoost'] = benchmark_df['XGBoost'].replace(-1, 'Negative')\n",
        "benchmark_df['XGBoost'] = benchmark_df['XGBoost'].replace(1, 'Positive')\n",
        "\n",
        "benchmark_df"
      ],
      "metadata": {
        "id": "WusHb3b8N4vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df.to_excel(\"Sentiment.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "rvMgXDhUN4vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3laV3cblN4vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Twitter custom test dataset"
      ],
      "metadata": {
        "id": "GyI9ZXv5XRwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Y7n84M-UXVaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning data"
      ],
      "metadata": {
        "id": "mw3l7-hmXVmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import sys\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import re\n",
        "import itertools\n",
        "import emoji\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "import fasttext\n",
        "import fasttext.util"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350c91f6-f9c2-4a10-85dd-820ae3338008",
        "id": "sg2Buv6RXVmr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dict_smileys():\n",
        "    \n",
        "    return {\n",
        "        \":‑)\":\"smiley\",\n",
        "        \":-]\":\"smiley\",\n",
        "        \":-3\":\"smiley\",\n",
        "        \":->\":\"smiley\",\n",
        "        \"8-)\":\"smiley\",\n",
        "        \":-}\":\"smiley\",\n",
        "        \":)\":\"smiley\",\n",
        "        \":]\":\"smiley\",\n",
        "        \":3\":\"smiley\",\n",
        "        \":>\":\"smiley\",\n",
        "        \"8)\":\"smiley\",\n",
        "        \":}\":\"smiley\",\n",
        "        \":o)\":\"smiley\",\n",
        "        \":c)\":\"smiley\",\n",
        "        \":^)\":\"smiley\",\n",
        "        \"=]\":\"smiley\",\n",
        "        \"=)\":\"smiley\",\n",
        "        \":-))\":\"smiley\",\n",
        "        \":‑D\":\"smiley\",\n",
        "        \"8‑D\":\"smiley\",\n",
        "        \"x‑D\":\"smiley\",\n",
        "        \"X‑D\":\"smiley\",\n",
        "        \":D\":\"smiley\",\n",
        "        \"8D\":\"smiley\",\n",
        "        \"xD\":\"smiley\",\n",
        "        \"XD\":\"smiley\",\n",
        "        \":‑(\":\"sad\",\n",
        "        \":‑c\":\"sad\",\n",
        "        \":‑<\":\"sad\",\n",
        "        \":‑[\":\"sad\",\n",
        "        \":(\":\"sad\",\n",
        "        \":c\":\"sad\",\n",
        "        \":<\":\"sad\",\n",
        "        \":[\":\"sad\",\n",
        "        \":-||\":\"sad\",\n",
        "        \">:[\":\"sad\",\n",
        "        \":{\":\"sad\",\n",
        "        \":@\":\"sad\",\n",
        "        \">:(\":\"sad\",\n",
        "        \":'‑(\":\"sad\",\n",
        "        \":'(\":\"sad\",\n",
        "        \":‑P\":\"playful\",\n",
        "        \"X‑P\":\"playful\",\n",
        "        \"x‑p\":\"playful\",\n",
        "        \":‑p\":\"playful\",\n",
        "        \":‑Þ\":\"playful\",\n",
        "        \":‑þ\":\"playful\",\n",
        "        \":‑b\":\"playful\",\n",
        "        \":P\":\"playful\",\n",
        "        \"XP\":\"playful\",\n",
        "        \"xp\":\"playful\",\n",
        "        \":p\":\"playful\",\n",
        "        \":Þ\":\"playful\",\n",
        "        \":þ\":\"playful\",\n",
        "        \":b\":\"playful\",\n",
        "        \"<3\":\"love\"\n",
        "        }\n",
        "\n",
        "def load_dict_contractions():\n",
        "    \n",
        "    return {\n",
        "        \"ain't\":\"is not\",\n",
        "        \"amn't\":\"am not\",\n",
        "        \"aren't\":\"are not\",\n",
        "        \"can't\":\"cannot\",\n",
        "        \"'cause\":\"because\",\n",
        "        \"couldn't\":\"could not\",\n",
        "        \"couldn't've\":\"could not have\",\n",
        "        \"could've\":\"could have\",\n",
        "        \"daren't\":\"dare not\",\n",
        "        \"daresn't\":\"dare not\",\n",
        "        \"dasn't\":\"dare not\",\n",
        "        \"didn't\":\"did not\",\n",
        "        \"doesn't\":\"does not\",\n",
        "        \"don't\":\"do not\",\n",
        "        \"e'er\":\"ever\",\n",
        "        \"em\":\"them\",\n",
        "        \"everyone's\":\"everyone is\",\n",
        "        \"finna\":\"fixing to\",\n",
        "        \"gimme\":\"give me\",\n",
        "        \"gonna\":\"going to\",\n",
        "        \"gon't\":\"go not\",\n",
        "        \"gotta\":\"got to\",\n",
        "        \"hadn't\":\"had not\",\n",
        "        \"hasn't\":\"has not\",\n",
        "        \"haven't\":\"have not\",\n",
        "        \"he'd\":\"he would\",\n",
        "        \"he'll\":\"he will\",\n",
        "        \"he's\":\"he is\",\n",
        "        \"he've\":\"he have\",\n",
        "        \"how'd\":\"how would\",\n",
        "        \"how'll\":\"how will\",\n",
        "        \"how're\":\"how are\",\n",
        "        \"how's\":\"how is\",\n",
        "        \"I'd\":\"I would\",\n",
        "        \"I'll\":\"I will\",\n",
        "        \"I'm\":\"I am\",\n",
        "        \"I'm'a\":\"I am about to\",\n",
        "        \"I'm'o\":\"I am going to\",\n",
        "        \"isn't\":\"is not\",\n",
        "        \"it'd\":\"it would\",\n",
        "        \"it'll\":\"it will\",\n",
        "        \"it's\":\"it is\",\n",
        "        \"I've\":\"I have\",\n",
        "        \"kinda\":\"kind of\",\n",
        "        \"let's\":\"let us\",\n",
        "        \"mayn't\":\"may not\",\n",
        "        \"may've\":\"may have\",\n",
        "        \"mightn't\":\"might not\",\n",
        "        \"might've\":\"might have\",\n",
        "        \"mustn't\":\"must not\",\n",
        "        \"mustn't've\":\"must not have\",\n",
        "        \"must've\":\"must have\",\n",
        "        \"needn't\":\"need not\",\n",
        "        \"ne'er\":\"never\",\n",
        "        \"o'\":\"of\",\n",
        "        \"o'er\":\"over\",\n",
        "        \"ol'\":\"old\",\n",
        "        \"oughtn't\":\"ought not\",\n",
        "        \"shalln't\":\"shall not\",\n",
        "        \"shan't\":\"shall not\",\n",
        "        \"she'd\":\"she would\",\n",
        "        \"she'll\":\"she will\",\n",
        "        \"she's\":\"she is\",\n",
        "        \"shouldn't\":\"should not\",\n",
        "        \"shouldn't've\":\"should not have\",\n",
        "        \"should've\":\"should have\",\n",
        "        \"somebody's\":\"somebody is\",\n",
        "        \"someone's\":\"someone is\",\n",
        "        \"something's\":\"something is\",\n",
        "        \"that'd\":\"that would\",\n",
        "        \"that'll\":\"that will\",\n",
        "        \"that're\":\"that are\",\n",
        "        \"that's\":\"that is\",\n",
        "        \"there'd\":\"there would\",\n",
        "        \"there'll\":\"there will\",\n",
        "        \"there're\":\"there are\",\n",
        "        \"there's\":\"there is\",\n",
        "        \"these're\":\"these are\",\n",
        "        \"they'd\":\"they would\",\n",
        "        \"they'll\":\"they will\",\n",
        "        \"they're\":\"they are\",\n",
        "        \"they've\":\"they have\",\n",
        "        \"this's\":\"this is\",\n",
        "        \"those're\":\"those are\",\n",
        "        \"'tis\":\"it is\",\n",
        "        \"'twas\":\"it was\",\n",
        "        \"wanna\":\"want to\",\n",
        "        \"wasn't\":\"was not\",\n",
        "        \"we'd\":\"we would\",\n",
        "        \"we'd've\":\"we would have\",\n",
        "        \"we'll\":\"we will\",\n",
        "        \"we're\":\"we are\",\n",
        "        \"weren't\":\"were not\",\n",
        "        \"we've\":\"we have\",\n",
        "        \"what'd\":\"what did\",\n",
        "        \"what'll\":\"what will\",\n",
        "        \"what're\":\"what are\",\n",
        "        \"what's\":\"what is\",\n",
        "        \"what've\":\"what have\",\n",
        "        \"when's\":\"when is\",\n",
        "        \"where'd\":\"where did\",\n",
        "        \"where're\":\"where are\",\n",
        "        \"where's\":\"where is\",\n",
        "        \"where've\":\"where have\",\n",
        "        \"which's\":\"which is\",\n",
        "        \"who'd\":\"who would\",\n",
        "        \"who'd've\":\"who would have\",\n",
        "        \"who'll\":\"who will\",\n",
        "        \"who're\":\"who are\",\n",
        "        \"who's\":\"who is\",\n",
        "        \"who've\":\"who have\",\n",
        "        \"why'd\":\"why did\",\n",
        "        \"why're\":\"why are\",\n",
        "        \"why's\":\"why is\",\n",
        "        \"won't\":\"will not\",\n",
        "        \"wouldn't\":\"would not\",\n",
        "        \"would've\":\"would have\",\n",
        "        \"y'all\":\"you all\",\n",
        "        \"you'd\":\"you would\",\n",
        "        \"you'll\":\"you will\",\n",
        "        \"you're\":\"you are\",\n",
        "        \"you've\":\"you have\",\n",
        "        \"Whatcha\":\"What are you\",\n",
        "        \"luv\":\"love\",\n",
        "        \"sux\":\"sucks\"\n",
        "        }\n",
        "\n",
        "def strip_accents(text):\n",
        "    if 'ø' in text or  'Ø' in text:\n",
        "        #Do nothing when finding ø \n",
        "        return text   \n",
        "    text = text.encode('ascii', 'ignore')\n",
        "    text = text.decode(\"utf-8\")\n",
        "    return str(text)\n",
        "\n",
        "def tweet_cleaning_for_sentiment_analysis(tweet):    \n",
        "    tweet = re.sub(r\"(http?\\://|https?\\://|www|pic.)\\S+\", \"\", tweet) #Remove http links\n",
        "    #Escaping HTML characters\n",
        "    tweet = BeautifulSoup(tweet).get_text()\n",
        "    #Special case not handled previously.\n",
        "    tweet = tweet.replace('\\x92',\"'\")\n",
        "    #Removal of hastags/account\n",
        "    #tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", tweet).split())\n",
        "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \")\n",
        "    #Removal of address\n",
        "    tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
        "    #Removal of Punctuation\n",
        "    tweet = ' '.join(re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=]\", \" \", tweet).split())\n",
        "    #Lower case\n",
        "    tweet = tweet.lower()\n",
        "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)\", \"USER\", tweet).split())\n",
        "    #CONTRACTIONS source: https://en.wikipedia.org/wiki/Contraction_%28grammar%29\n",
        "    CONTRACTIONS = load_dict_contractions()\n",
        "    tweet = tweet.replace(\"’\",\"'\")\n",
        "    words = tweet.split()\n",
        "    reformed = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    # Standardizing words\n",
        "    tweet = ''.join(''.join(s)[:2] for _, s in itertools.groupby(tweet))\n",
        "    #Deal with smileys\n",
        "    #source: https://en.wikipedia.org/wiki/List_of_emoticons\n",
        "    SMILEY = load_dict_smileys()  \n",
        "    words = tweet.split()\n",
        "    reformed = [SMILEY[word] if word in SMILEY else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    #Deal with emojis\n",
        "    #tweet = emoji.demojize(tweet)\n",
        "    #Strip accents\n",
        "    #tweet= strip_accents(tweet)\n",
        "    tweet = tweet.replace(\":\",\" \")\n",
        "    tweet = ' '.join(tweet.split())\n",
        "    \n",
        "    # DO NOT REMOVE STOP WORDS FOR SENTIMENT ANALYSIS - OR AT LEAST NOT NEGATIVE ONES\n",
        "\n",
        "    return tweet"
      ],
      "metadata": {
        "id": "_mcWqY6sXVmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_cleaning_for_sentiment_analysis(data.iloc[29, :]['tweet'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dluPZ6E6dAnh",
        "outputId": "e7355457-13a8-4288-d8f4-0ef9cd341b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'melusi 4k are you shocked USER USER USER USER USER rainbowsixsiege'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word embeddings"
      ],
      "metadata": {
        "id": "8KnRqZEaXVm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download embedddings"
      ],
      "metadata": {
        "id": "NZsPmbWpXVm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir fasttext-embeddings\n",
        "%cd fasttext-embeddings\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
        "!unzip crawl-300d-2M-subword.zip\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67d1694-a8eb-4168-e50d-14d59158710e",
        "id": "SF5yehQxXVnB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fasttext-embeddings\n",
            "--2022-07-21 14:55:23--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5828358084 (5.4G) [application/zip]\n",
            "Saving to: ‘crawl-300d-2M-subword.zip’\n",
            "\n",
            "crawl-300d-2M-subwo 100%[===================>]   5.43G  32.1MB/s    in 3m 13s  \n",
            "\n",
            "2022-07-21 14:58:37 (28.8 MB/s) - ‘crawl-300d-2M-subword.zip’ saved [5828358084/5828358084]\n",
            "\n",
            "Archive:  crawl-300d-2M-subword.zip\n",
            "  inflating: crawl-300d-2M-subword.vec  \n",
            "  inflating: crawl-300d-2M-subword.bin  \n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir fasttext-embeddings\n",
        "%cd fasttext-embeddings\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M-subword.vec.zip\n",
        "!unzip wiki-news-300d-1M-subword.vec.zip\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcb71d8-c025-472c-ad52-096d48ea23c4",
        "id": "oNxYOu0dXVnC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘fasttext-embeddings’: File exists\n",
            "/content/fasttext-embeddings\n",
            "--2022-07-21 15:24:21--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M-subword.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 587879973 (561M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M-subword.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M-s 100%[===================>] 560.65M  36.8MB/s    in 16s     \n",
            "\n",
            "2022-07-21 15:24:38 (34.7 MB/s) - ‘wiki-news-300d-1M-subword.vec.zip’ saved [587879973/587879973]\n",
            "\n",
            "Archive:  wiki-news-300d-1M-subword.vec.zip\n",
            "  inflating: wiki-news-300d-1M-subword.vec  \n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir fasttext-embeddings\n",
        "%cd fasttext-embeddings\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
        "!gzip -d cc.en.300.bin.gz\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8175877b-cad6-429c-bd9f-0f8a22b0431f",
        "id": "I4lQdPd4XVnE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘fasttext-embeddings’: File exists\n",
            "/content/fasttext-embeddings\n",
            "--2022-07-21 15:28:31--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.en.300.bin.gz’\n",
            "\n",
            "cc.en.300.bin.gz    100%[===================>]   4.19G  28.1MB/s    in 2m 18s  \n",
            "\n",
            "2022-07-21 15:30:49 (31.2 MB/s) - ‘cc.en.300.bin.gz’ saved [4503593528/4503593528]\n",
            "\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir fasttext-embeddings\n",
        "# %cd fasttext-embeddings\n",
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
        "# !unzip crawl-300d-2M.vec.zip"
      ],
      "metadata": {
        "id": "XDToaX9CXVnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0153bc2-7425-4713-9807-afa28401dcdc",
        "id": "d_Pbh_nnXVnK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading model"
      ],
      "metadata": {
        "id": "yG0grO17XVnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# fasttext_emb = fasttext.load_model('/content/fasttext-embeddings/cc.en.300.bin')\n",
        "# print(ft.get_dimension())\n",
        "\n",
        "# fasttext.util.reduce_model(ft, 100)\n",
        "# print(ft.get_dimension())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "cc7a0d25-c57a-42e7-8bf4-3cab33cc8ab6",
        "id": "GhkDytS_XVnN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-f87c31fcc971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfasttext_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/fasttext-embeddings/cc.en.300.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ft' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_emb = fasttext.FastText.load_model('./fasttext-embeddings/crawl-300d-2M-subword.bin')\n",
        "#fasttext_emb = fasttext.FastText.load_model('./fasttext-embeddings/wiki-news-300d-1M-subword.vec')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma1snRFjXVnQ",
        "outputId": "97e66346-9395-43fa-a586-c45abbad7be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_emb.get_nearest_neighbors(\"__user__\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ab89e6e-aa82-483e-9312-36cc32506ad4",
        "id": "LsMEfvXNXVnR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.6122851371765137, 'intrebari'),\n",
              " (0.6034965515136719, 'vmware-modconfig'),\n",
              " (0.5972209572792053, 'eclipselink-orm.xml'),\n",
              " (0.5965851545333862, 'base-config'),\n",
              " (0.5962321162223816, 'hostnamectl'),\n",
              " (0.5956684350967407, 'myconfig'),\n",
              " (0.593761146068573, 'webpack.config.js'),\n",
              " (0.5922401547431946, 'mkvirtualenv'),\n",
              " (0.5871965289115906, 'libxml2-dev'),\n",
              " (0.5849608182907104, 'jboss-service.xml')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing data"
      ],
      "metadata": {
        "id": "u4UVWTrNZLda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"Sentiment models - Labelled Test Data.csv\")\n",
        "\n",
        "data['cleaned_tweets'] = data.tweet.astype(str).apply(tweet_cleaning_for_sentiment_analysis)\n",
        "data['sent_vec'] = data.cleaned_tweets.apply(fasttext_emb.get_sentence_vector)\n",
        "\n",
        "with open(\"twitter-test-data.pkl\", \"wb\") as f:\n",
        "  pickle.dump(data, f)\n",
        "\n",
        "del data"
      ],
      "metadata": {
        "id": "I5hV63GzZB5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(pickle_filepath):\n",
        "  data = pickle.load(open(pickle_filepath,'rb'))\n",
        "  \n",
        "  X = np.array(list(data.sent_vec.apply(lambda x: list(x)).values))\n",
        "  \n",
        "  return X, data.label.values"
      ],
      "metadata": {
        "id": "P3mAd4VRZnwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest, ytest = prepare_data(\"twitter-test-data.pkl\")"
      ],
      "metadata": {
        "id": "DNRLd1P0Zz34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest.shape, ytest.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2g8nk1CcQLu",
        "outputId": "4e101c5c-307a-4b17-eeaf-24c9be4faf5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((62, 300), (62,))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test models"
      ],
      "metadata": {
        "id": "5iiF0SomZ_n4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/file/d/1z6wJGTVLsWQW8lhNGaI1rogqxiAQP2YH/view?usp=sharing --fuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFtMxFdvbdG3",
        "outputId": "d3b2bdfb-d592-4ae9-ea60-6e465d8d247d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1z6wJGTVLsWQW8lhNGaI1rogqxiAQP2YH\n",
            "To: /content/models.rar\n",
            "100% 83.2M/83.2M [00:03<00:00, 21.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar e models.rar /content/models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkqw7aAFbh8d",
        "outputId": "7104b298-2b31-4452-fc0e-6ae964c09210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from models.rar\n",
            "\n",
            "\n",
            "Would you like to replace the existing file /content/models/finaldata_random_forest.joblib\n",
            "26214400 bytes, modified on 2022-07-28 10:50\n",
            "with a new one\n",
            "63981274 bytes, modified on 2022-07-21 17:31\n",
            "\n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit A\n",
            "\n",
            "Extracting  /content/models/finaldata_random_forest.joblib               \b\b\b\b  5%\b\b\b\b 10%\b\b\b\b 15%\b\b\b\b 20%\b\b\b\b 25%\b\b\b\b 30%\b\b\b\b 35%\b\b\b\b 40%\b\b\b\b 45%\b\b\b\b 50%\b\b\b\b 55%\b\b\b\b 60%\b\b\b\b 65%\b\b\b\b 70%\b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_random_forest_undersampled.joblib     \b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_xgboost_model.json                 \b\b\b\b 85%\b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_xgboost_model_undersampled.json     \b\b\b\b 93%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "fzH2s6UzaVfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "uvUzyUTNN4vO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = joblib.load(\"/content/models/finaldata_random_forest.joblib\")"
      ],
      "metadata": {
        "id": "dpQpzll4Z7Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = rf.predict(Xtest)\n",
        "print(classification_report(ytest, predictions)) #Random forest"
      ],
      "metadata": {
        "id": "tY_l-73XN4vP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5d9a87f-a9e3-4231-b216-3c824b52afba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.25      0.15      0.19        20\n",
            "     NEUTRAL       0.20      0.64      0.31        14\n",
            "    POSITIVE       0.50      0.11      0.18        28\n",
            "\n",
            "    accuracy                           0.24        62\n",
            "   macro avg       0.32      0.30      0.22        62\n",
            "weighted avg       0.35      0.24      0.21        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf = pd.DataFrame()"
      ],
      "metadata": {
        "id": "YokXdYl1nQ1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['Random Forest'] = predictions"
      ],
      "metadata": {
        "id": "BdJ-mGSsz-hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest - Undersampled"
      ],
      "metadata": {
        "id": "4vEVg9mRfceH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = joblib.load(\"/content/models/finaldata_random_forest_undersampled.joblib\")"
      ],
      "metadata": {
        "id": "DWmOz7p9gKDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = rf.predict(Xtest)\n",
        "print(classification_report(ytest, predictions)) #Random forest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46315dfd-adc6-4225-9bfe-497e7149dafc",
        "id": "xo_zC9rlfceI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.38      0.40      0.39        20\n",
            "     NEUTRAL       0.21      0.36      0.26        14\n",
            "    POSITIVE       0.65      0.39      0.49        28\n",
            "\n",
            "    accuracy                           0.39        62\n",
            "   macro avg       0.41      0.38      0.38        62\n",
            "weighted avg       0.46      0.39      0.41        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['Random Forest - Undersampled'] = predictions"
      ],
      "metadata": {
        "id": "f4Oy8kvFfceJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "Gg9yucfRN4vR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = xgb_model.predict(Xtest)\n",
        "print(classification_report(ytest, predictions)) #xgboost"
      ],
      "metadata": {
        "id": "jMSfxvm1N4vT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbf92fe2-591a-451e-938b-68a421a3870c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.41      0.35      0.38        20\n",
            "     NEUTRAL       0.17      0.29      0.22        14\n",
            "    POSITIVE       0.59      0.46      0.52        28\n",
            "\n",
            "    accuracy                           0.39        62\n",
            "   macro avg       0.39      0.37      0.37        62\n",
            "weighted avg       0.44      0.39      0.41        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['XGBoost'] = predictions"
      ],
      "metadata": {
        "id": "7QOSRMScwxIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost - Undersampled"
      ],
      "metadata": {
        "id": "0cUBUgxCgjL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = xgb_model.predict(Xtest)\n",
        "print(classification_report(ytest, predictions)) #xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bfbb0e6-ca24-4df1-b2d1-d40f501d56e1",
        "id": "14bsmTblgjL6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.48      0.55      0.51        20\n",
            "     NEUTRAL       0.36      0.36      0.36        14\n",
            "    POSITIVE       0.68      0.61      0.64        28\n",
            "\n",
            "    accuracy                           0.53        62\n",
            "   macro avg       0.51      0.50      0.50        62\n",
            "weighted avg       0.54      0.53      0.54        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['XGBoost - Undersampled'] = predictions"
      ],
      "metadata": {
        "id": "H2FP45dAgjL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jBozm9_Doc_u",
        "outputId": "d49d145f-4387-495c-d50b-e7d14605c499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Random Forest Random Forest - Undersampled   XGBoost XGBoost - Undersampled\n",
              "0        NEUTRAL                     POSITIVE  POSITIVE               POSITIVE\n",
              "1        NEUTRAL                      NEUTRAL   NEUTRAL                NEUTRAL\n",
              "2        NEUTRAL                     POSITIVE  POSITIVE               POSITIVE\n",
              "3        NEUTRAL                      NEUTRAL   NEUTRAL                NEUTRAL\n",
              "4        NEUTRAL                     NEGATIVE  NEGATIVE               NEGATIVE\n",
              "..           ...                          ...       ...                    ...\n",
              "57       NEUTRAL                      NEUTRAL   NEUTRAL               POSITIVE\n",
              "58      NEGATIVE                     NEGATIVE  NEGATIVE               NEGATIVE\n",
              "59       NEUTRAL                     POSITIVE  POSITIVE               POSITIVE\n",
              "60       NEUTRAL                     NEGATIVE   NEUTRAL               NEGATIVE\n",
              "61       NEUTRAL                     POSITIVE  POSITIVE               POSITIVE\n",
              "\n",
              "[62 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba75ad88-4f04-4b78-9b82-7dae9099f5b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>Random Forest - Undersampled</th>\n",
              "      <th>XGBoost</th>\n",
              "      <th>XGBoost - Undersampled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba75ad88-4f04-4b78-9b82-7dae9099f5b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba75ad88-4f04-4b78-9b82-7dae9099f5b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba75ad88-4f04-4b78-9b82-7dae9099f5b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERTweet"
      ],
      "metadata": {
        "id": "p9CyI2xdN4vU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pickle.load(open(\"/content/twitter-test-data.pkl\", \"rb\"))\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "MxmQLW0Coq84",
        "outputId": "c81fcaf9-6cd1-4fec-e2df-97f844117be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                tweet     label  \\\n",
              "0   ‘It has been a really memorable season’ – Jos ...  POSITIVE   \n",
              "1   Mumbai Indians and Titans Cricket batter, Dewa...  POSITIVE   \n",
              "2   There were several uncapped players who proved...  POSITIVE   \n",
              "3   AFTER ARGUING WITH VERIZON REGARDING THE DROPP...  NEGATIVE   \n",
              "4   A usable keyboard actually turns a PDA into a ...  POSITIVE   \n",
              "..                                                ...       ...   \n",
              "57  @satyanadella @Microsoft thanks for celebratin...  POSITIVE   \n",
              "58                         Thatâ€™s the best one wtf?  POSITIVE   \n",
              "59  AOC you make some very ignorant comments\\n Whe...   NEUTRAL   \n",
              "60  oooooh shit i think my motherboard is already ...  POSITIVE   \n",
              "61  NYUMMM DELICIOUS FINALLY SOME GOOD CONTENT NYU...   NEUTRAL   \n",
              "\n",
              "                                       cleaned_tweets  \\\n",
              "0   ‘it has been a really memorable season' – jos ...   \n",
              "1   mumbai indians and titans cricket batter dewal...   \n",
              "2   there were several uncapped players who proved...   \n",
              "3   after arguing with verizon regarding the dropp...   \n",
              "4   a usable keyboard actually turns a pda into a ...   \n",
              "..                                                ...   \n",
              "57  USER USER thanks for celebrating diversity we ...   \n",
              "58                          thatâ€™s the best one wtf   \n",
              "59  aoc you make some very ignorant comments when ...   \n",
              "60  ooh shit i think my motherboard is already com...   \n",
              "61  nyumm delicious finally some good content nyum...   \n",
              "\n",
              "                                             sent_vec  \n",
              "0   [0.0044800234, -0.024687007, 0.03165525, 0.026...  \n",
              "1   [-0.013870388, -0.042408988, 0.0869929, 0.0214...  \n",
              "2   [-0.012238055, -0.05264265, 0.08353262, 0.0121...  \n",
              "3   [0.0059597986, -0.049668398, 0.0746304, 0.0094...  \n",
              "4   [-0.0028914495, 0.009457815, 0.075295255, 0.00...  \n",
              "..                                                ...  \n",
              "57  [-0.0034089629, -0.049936995, 0.08740346, 0.02...  \n",
              "58  [-0.00953177, -0.004613374, 0.10661884, -0.008...  \n",
              "59  [-0.0043282043, -0.063566, 0.087194875, 0.0080...  \n",
              "60  [-0.0018573017, 0.026468603, 0.07860464, 0.002...  \n",
              "61  [-0.0055657444, -0.0040176334, 0.07378124, 0.0...  \n",
              "\n",
              "[62 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7efd74e6-0714-4b81-ae0f-57032e1ac3c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_tweets</th>\n",
              "      <th>sent_vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>‘It has been a really memorable season’ – Jos ...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>‘it has been a really memorable season' – jos ...</td>\n",
              "      <td>[0.0044800234, -0.024687007, 0.03165525, 0.026...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mumbai Indians and Titans Cricket batter, Dewa...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>mumbai indians and titans cricket batter dewal...</td>\n",
              "      <td>[-0.013870388, -0.042408988, 0.0869929, 0.0214...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>There were several uncapped players who proved...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>there were several uncapped players who proved...</td>\n",
              "      <td>[-0.012238055, -0.05264265, 0.08353262, 0.0121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AFTER ARGUING WITH VERIZON REGARDING THE DROPP...</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>after arguing with verizon regarding the dropp...</td>\n",
              "      <td>[0.0059597986, -0.049668398, 0.0746304, 0.0094...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A usable keyboard actually turns a PDA into a ...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>a usable keyboard actually turns a pda into a ...</td>\n",
              "      <td>[-0.0028914495, 0.009457815, 0.075295255, 0.00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>@satyanadella @Microsoft thanks for celebratin...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>USER USER thanks for celebrating diversity we ...</td>\n",
              "      <td>[-0.0034089629, -0.049936995, 0.08740346, 0.02...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>Thatâ€™s the best one wtf?</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>thatâ€™s the best one wtf</td>\n",
              "      <td>[-0.00953177, -0.004613374, 0.10661884, -0.008...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>AOC you make some very ignorant comments\\n Whe...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>aoc you make some very ignorant comments when ...</td>\n",
              "      <td>[-0.0043282043, -0.063566, 0.087194875, 0.0080...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>oooooh shit i think my motherboard is already ...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>ooh shit i think my motherboard is already com...</td>\n",
              "      <td>[-0.0018573017, 0.026468603, 0.07860464, 0.002...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>NYUMMM DELICIOUS FINALLY SOME GOOD CONTENT NYU...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>nyumm delicious finally some good content nyum...</td>\n",
              "      <td>[-0.0055657444, -0.0040176334, 0.07378124, 0.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7efd74e6-0714-4b81-ae0f-57032e1ac3c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7efd74e6-0714-4b81-ae0f-57032e1ac3c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7efd74e6-0714-4b81-ae0f-57032e1ac3c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['BERTweet'] = data['cleaned_tweets'].apply(sa1.inference)"
      ],
      "metadata": {
        "id": "GZjfj02dN4vV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "092099a4-9b2c-4ccc-aa46-04abf6c3930f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(ytest, testdf['BERTweet'].values)) #BERtweet"
      ],
      "metadata": {
        "id": "_HAzU1NoN4va",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6580b10f-e35c-4173-88ed-3f1282aae1a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.48      0.60      0.53        20\n",
            "     NEUTRAL       0.23      0.21      0.22        14\n",
            "    POSITIVE       0.83      0.71      0.77        28\n",
            "\n",
            "    accuracy                           0.56        62\n",
            "   macro avg       0.51      0.51      0.51        62\n",
            "weighted avg       0.58      0.56      0.57        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT base"
      ],
      "metadata": {
        "id": "aoIDaPv1N4vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['bert-base-multilingual-uncased-sentiment_clean'] = data['cleaned_tweets'].apply(sa2.inference)"
      ],
      "metadata": {
        "id": "XWC1WBVMN4vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1745767-da5d-4dde-c98d-548418112136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(ytest, testdf['bert-base-multilingual-uncased-sentiment_clean'].values)) #BERT Base"
      ],
      "metadata": {
        "id": "dgH5NdmuN4vi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86d77ddd-165b-4003-af3d-e8722ae900a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.50      0.70      0.58        20\n",
            "     NEUTRAL       1.00      0.07      0.13        14\n",
            "    POSITIVE       0.70      0.82      0.75        28\n",
            "\n",
            "    accuracy                           0.61        62\n",
            "   macro avg       0.73      0.53      0.49        62\n",
            "weighted avg       0.70      0.61      0.56        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V0yeIzJeq9Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['tweet'] = data['tweet']\n",
        "testdf['label'] = data['label']\n",
        "\n",
        "testdf['cleaned_tweets'] = data['cleaned_tweets']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "Ihr0U3Wxp6kt",
        "outputId": "b6a1d7c3-fa12-4551-b458-325eec2d797c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Random Forest Random Forest - Undersampled   XGBoost  \\\n",
              "0        NEUTRAL                     POSITIVE  POSITIVE   \n",
              "1        NEUTRAL                      NEUTRAL   NEUTRAL   \n",
              "2        NEUTRAL                     POSITIVE  POSITIVE   \n",
              "3        NEUTRAL                      NEUTRAL   NEUTRAL   \n",
              "4        NEUTRAL                     NEGATIVE  NEGATIVE   \n",
              "..           ...                          ...       ...   \n",
              "57       NEUTRAL                      NEUTRAL   NEUTRAL   \n",
              "58      NEGATIVE                     NEGATIVE  NEGATIVE   \n",
              "59       NEUTRAL                     POSITIVE  POSITIVE   \n",
              "60       NEUTRAL                     NEGATIVE   NEUTRAL   \n",
              "61       NEUTRAL                     POSITIVE  POSITIVE   \n",
              "\n",
              "   XGBoost - Undersampled  BERTweet  \\\n",
              "0                POSITIVE  POSITIVE   \n",
              "1                 NEUTRAL  POSITIVE   \n",
              "2                POSITIVE  POSITIVE   \n",
              "3                 NEUTRAL  NEGATIVE   \n",
              "4                NEGATIVE  POSITIVE   \n",
              "..                    ...       ...   \n",
              "57               POSITIVE  POSITIVE   \n",
              "58               NEGATIVE  POSITIVE   \n",
              "59               POSITIVE  NEGATIVE   \n",
              "60               NEGATIVE  NEGATIVE   \n",
              "61               POSITIVE  POSITIVE   \n",
              "\n",
              "   bert-base-multilingual-uncased-sentiment_clean  \\\n",
              "0                                        POSITIVE   \n",
              "1                                        POSITIVE   \n",
              "2                                        POSITIVE   \n",
              "3                                        NEGATIVE   \n",
              "4                                        POSITIVE   \n",
              "..                                            ...   \n",
              "57                                       POSITIVE   \n",
              "58                                       NEGATIVE   \n",
              "59                                       NEGATIVE   \n",
              "60                                       NEGATIVE   \n",
              "61                                       POSITIVE   \n",
              "\n",
              "                                                tweet     label  \n",
              "0   ‘It has been a really memorable season’ – Jos ...  POSITIVE  \n",
              "1   Mumbai Indians and Titans Cricket batter, Dewa...  POSITIVE  \n",
              "2   There were several uncapped players who proved...  POSITIVE  \n",
              "3   AFTER ARGUING WITH VERIZON REGARDING THE DROPP...  NEGATIVE  \n",
              "4   A usable keyboard actually turns a PDA into a ...  POSITIVE  \n",
              "..                                                ...       ...  \n",
              "57  @satyanadella @Microsoft thanks for celebratin...  POSITIVE  \n",
              "58                         Thatâ€™s the best one wtf?  POSITIVE  \n",
              "59  AOC you make some very ignorant comments\\n Whe...   NEUTRAL  \n",
              "60  oooooh shit i think my motherboard is already ...  POSITIVE  \n",
              "61  NYUMMM DELICIOUS FINALLY SOME GOOD CONTENT NYU...   NEUTRAL  \n",
              "\n",
              "[62 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-288ccd28-b2f0-4e14-acf2-beb7d822733e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>Random Forest - Undersampled</th>\n",
              "      <th>XGBoost</th>\n",
              "      <th>XGBoost - Undersampled</th>\n",
              "      <th>BERTweet</th>\n",
              "      <th>bert-base-multilingual-uncased-sentiment_clean</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>‘It has been a really memorable season’ – Jos ...</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>Mumbai Indians and Titans Cricket batter, Dewa...</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>There were several uncapped players who proved...</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>AFTER ARGUING WITH VERIZON REGARDING THE DROPP...</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>A usable keyboard actually turns a PDA into a ...</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>@satyanadella @Microsoft thanks for celebratin...</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>Thatâ€™s the best one wtf?</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>AOC you make some very ignorant comments\\n Whe...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>oooooh shit i think my motherboard is already ...</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>NYUMMM DELICIOUS FINALLY SOME GOOD CONTENT NYU...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-288ccd28-b2f0-4e14-acf2-beb7d822733e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-288ccd28-b2f0-4e14-acf2-beb7d822733e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-288ccd28-b2f0-4e14-acf2-beb7d822733e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf"
      ],
      "metadata": {
        "id": "2GsOHNcjrDrd",
        "outputId": "b61b8c00-cc5b-4fa2-841e-18f922cea59a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Random Forest Random Forest - Undersampled   XGBoost  \\\n",
              "0        NEUTRAL                     POSITIVE  POSITIVE   \n",
              "1        NEUTRAL                      NEUTRAL   NEUTRAL   \n",
              "2        NEUTRAL                     POSITIVE  POSITIVE   \n",
              "3        NEUTRAL                      NEUTRAL   NEUTRAL   \n",
              "4        NEUTRAL                     NEGATIVE  NEGATIVE   \n",
              "..           ...                          ...       ...   \n",
              "57       NEUTRAL                      NEUTRAL   NEUTRAL   \n",
              "58      NEGATIVE                     NEGATIVE  NEGATIVE   \n",
              "59       NEUTRAL                     POSITIVE  POSITIVE   \n",
              "60       NEUTRAL                     NEGATIVE   NEUTRAL   \n",
              "61       NEUTRAL                     POSITIVE  POSITIVE   \n",
              "\n",
              "   XGBoost - Undersampled  BERTweet  \\\n",
              "0                POSITIVE  POSITIVE   \n",
              "1                 NEUTRAL  POSITIVE   \n",
              "2                POSITIVE  POSITIVE   \n",
              "3                 NEUTRAL  NEGATIVE   \n",
              "4                NEGATIVE  POSITIVE   \n",
              "..                    ...       ...   \n",
              "57               POSITIVE  POSITIVE   \n",
              "58               NEGATIVE  POSITIVE   \n",
              "59               POSITIVE  NEGATIVE   \n",
              "60               NEGATIVE  NEGATIVE   \n",
              "61               POSITIVE  POSITIVE   \n",
              "\n",
              "   bert-base-multilingual-uncased-sentiment_clean  \\\n",
              "0                                        POSITIVE   \n",
              "1                                        POSITIVE   \n",
              "2                                        POSITIVE   \n",
              "3                                        NEGATIVE   \n",
              "4                                        POSITIVE   \n",
              "..                                            ...   \n",
              "57                                       POSITIVE   \n",
              "58                                       NEGATIVE   \n",
              "59                                       NEGATIVE   \n",
              "60                                       NEGATIVE   \n",
              "61                                       POSITIVE   \n",
              "\n",
              "                                                tweet     label  \\\n",
              "0   ‘It has been a really memorable season’ – Jos ...  POSITIVE   \n",
              "1   Mumbai Indians and Titans Cricket batter, Dewa...  POSITIVE   \n",
              "2   There were several uncapped players who proved...  POSITIVE   \n",
              "3   AFTER ARGUING WITH VERIZON REGARDING THE DROPP...  NEGATIVE   \n",
              "4   A usable keyboard actually turns a PDA into a ...  POSITIVE   \n",
              "..                                                ...       ...   \n",
              "57  @satyanadella @Microsoft thanks for celebratin...  POSITIVE   \n",
              "58                         Thatâ€™s the best one wtf?  POSITIVE   \n",
              "59  AOC you make some very ignorant comments\\n Whe...   NEUTRAL   \n",
              "60  oooooh shit i think my motherboard is already ...  POSITIVE   \n",
              "61  NYUMMM DELICIOUS FINALLY SOME GOOD CONTENT NYU...   NEUTRAL   \n",
              "\n",
              "                                       cleaned_tweets  \n",
              "0   ‘it has been a really memorable season' – jos ...  \n",
              "1   mumbai indians and titans cricket batter dewal...  \n",
              "2   there were several uncapped players who proved...  \n",
              "3   after arguing with verizon regarding the dropp...  \n",
              "4   a usable keyboard actually turns a pda into a ...  \n",
              "..                                                ...  \n",
              "57  USER USER thanks for celebrating diversity we ...  \n",
              "58                          thatâ€™s the best one wtf  \n",
              "59  aoc you make some very ignorant comments when ...  \n",
              "60  ooh shit i think my motherboard is already com...  \n",
              "61  nyumm delicious finally some good content nyum...  \n",
              "\n",
              "[62 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d27204ee-f672-4bd5-8023-958dca4b68a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>Random Forest - Undersampled</th>\n",
              "      <th>XGBoost</th>\n",
              "      <th>XGBoost - Undersampled</th>\n",
              "      <th>BERTweet</th>\n",
              "      <th>bert-base-multilingual-uncased-sentiment_clean</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>‘It has been a really memorable season’ – Jos ...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>‘it has been a really memorable season' – jos ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>Mumbai Indians and Titans Cricket batter, Dewa...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>mumbai indians and titans cricket batter dewal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>There were several uncapped players who proved...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>there were several uncapped players who proved...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>AFTER ARGUING WITH VERIZON REGARDING THE DROPP...</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>after arguing with verizon regarding the dropp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>A usable keyboard actually turns a PDA into a ...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>a usable keyboard actually turns a pda into a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>@satyanadella @Microsoft thanks for celebratin...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>USER USER thanks for celebrating diversity we ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>Thatâ€™s the best one wtf?</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>thatâ€™s the best one wtf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>AOC you make some very ignorant comments\\n Whe...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>aoc you make some very ignorant comments when ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>oooooh shit i think my motherboard is already ...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>ooh shit i think my motherboard is already com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>NYUMMM DELICIOUS FINALLY SOME GOOD CONTENT NYU...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>nyumm delicious finally some good content nyum...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d27204ee-f672-4bd5-8023-958dca4b68a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d27204ee-f672-4bd5-8023-958dca4b68a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d27204ee-f672-4bd5-8023-958dca4b68a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf.to_excel(\"twitter-sample-data-results.xlsx\")"
      ],
      "metadata": {
        "id": "GIS2hNyqqEUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./test-predictions-undersampled.pkl\",\"wb\") as f:\n",
        "  pickle.dump(testdf, f)"
      ],
      "metadata": {
        "id": "rw2yYdrEwrkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Twitter custom test dataset - Without emojis"
      ],
      "metadata": {
        "id": "dN9vqyi6fGf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext emoji -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0WFniHMfGf7",
        "outputId": "13ab6c36-19f6-4572-ca39-a3297075318b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 68 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 197 kB 34.0 MB/s \n",
            "\u001b[?25h  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning data"
      ],
      "metadata": {
        "id": "lUKEE5IOfGf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import re\n",
        "import itertools\n",
        "import emoji\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "import fasttext\n",
        "import fasttext.util"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6442ed28-eff0-4e06-a709-4f6c6bac7fb8",
        "id": "WH3SbmAyfGf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dict_smileys():\n",
        "    \n",
        "    return {\n",
        "        \":‑)\":\"smiley\",\n",
        "        \":-]\":\"smiley\",\n",
        "        \":-3\":\"smiley\",\n",
        "        \":->\":\"smiley\",\n",
        "        \"8-)\":\"smiley\",\n",
        "        \":-}\":\"smiley\",\n",
        "        \":)\":\"smiley\",\n",
        "        \":]\":\"smiley\",\n",
        "        \":3\":\"smiley\",\n",
        "        \":>\":\"smiley\",\n",
        "        \"8)\":\"smiley\",\n",
        "        \":}\":\"smiley\",\n",
        "        \":o)\":\"smiley\",\n",
        "        \":c)\":\"smiley\",\n",
        "        \":^)\":\"smiley\",\n",
        "        \"=]\":\"smiley\",\n",
        "        \"=)\":\"smiley\",\n",
        "        \":-))\":\"smiley\",\n",
        "        \":‑D\":\"smiley\",\n",
        "        \"8‑D\":\"smiley\",\n",
        "        \"x‑D\":\"smiley\",\n",
        "        \"X‑D\":\"smiley\",\n",
        "        \":D\":\"smiley\",\n",
        "        \"8D\":\"smiley\",\n",
        "        \"xD\":\"smiley\",\n",
        "        \"XD\":\"smiley\",\n",
        "        \":‑(\":\"sad\",\n",
        "        \":‑c\":\"sad\",\n",
        "        \":‑<\":\"sad\",\n",
        "        \":‑[\":\"sad\",\n",
        "        \":(\":\"sad\",\n",
        "        \":c\":\"sad\",\n",
        "        \":<\":\"sad\",\n",
        "        \":[\":\"sad\",\n",
        "        \":-||\":\"sad\",\n",
        "        \">:[\":\"sad\",\n",
        "        \":{\":\"sad\",\n",
        "        \":@\":\"sad\",\n",
        "        \">:(\":\"sad\",\n",
        "        \":'‑(\":\"sad\",\n",
        "        \":'(\":\"sad\",\n",
        "        \":‑P\":\"playful\",\n",
        "        \"X‑P\":\"playful\",\n",
        "        \"x‑p\":\"playful\",\n",
        "        \":‑p\":\"playful\",\n",
        "        \":‑Þ\":\"playful\",\n",
        "        \":‑þ\":\"playful\",\n",
        "        \":‑b\":\"playful\",\n",
        "        \":P\":\"playful\",\n",
        "        \"XP\":\"playful\",\n",
        "        \"xp\":\"playful\",\n",
        "        \":p\":\"playful\",\n",
        "        \":Þ\":\"playful\",\n",
        "        \":þ\":\"playful\",\n",
        "        \":b\":\"playful\",\n",
        "        \"<3\":\"love\"\n",
        "        }\n",
        "\n",
        "def load_dict_contractions():\n",
        "    \n",
        "    return {\n",
        "        \"ain't\":\"is not\",\n",
        "        \"amn't\":\"am not\",\n",
        "        \"aren't\":\"are not\",\n",
        "        \"can't\":\"cannot\",\n",
        "        \"'cause\":\"because\",\n",
        "        \"couldn't\":\"could not\",\n",
        "        \"couldn't've\":\"could not have\",\n",
        "        \"could've\":\"could have\",\n",
        "        \"daren't\":\"dare not\",\n",
        "        \"daresn't\":\"dare not\",\n",
        "        \"dasn't\":\"dare not\",\n",
        "        \"didn't\":\"did not\",\n",
        "        \"doesn't\":\"does not\",\n",
        "        \"don't\":\"do not\",\n",
        "        \"e'er\":\"ever\",\n",
        "        \"em\":\"them\",\n",
        "        \"everyone's\":\"everyone is\",\n",
        "        \"finna\":\"fixing to\",\n",
        "        \"gimme\":\"give me\",\n",
        "        \"gonna\":\"going to\",\n",
        "        \"gon't\":\"go not\",\n",
        "        \"gotta\":\"got to\",\n",
        "        \"hadn't\":\"had not\",\n",
        "        \"hasn't\":\"has not\",\n",
        "        \"haven't\":\"have not\",\n",
        "        \"he'd\":\"he would\",\n",
        "        \"he'll\":\"he will\",\n",
        "        \"he's\":\"he is\",\n",
        "        \"he've\":\"he have\",\n",
        "        \"how'd\":\"how would\",\n",
        "        \"how'll\":\"how will\",\n",
        "        \"how're\":\"how are\",\n",
        "        \"how's\":\"how is\",\n",
        "        \"I'd\":\"I would\",\n",
        "        \"I'll\":\"I will\",\n",
        "        \"I'm\":\"I am\",\n",
        "        \"I'm'a\":\"I am about to\",\n",
        "        \"I'm'o\":\"I am going to\",\n",
        "        \"isn't\":\"is not\",\n",
        "        \"it'd\":\"it would\",\n",
        "        \"it'll\":\"it will\",\n",
        "        \"it's\":\"it is\",\n",
        "        \"I've\":\"I have\",\n",
        "        \"kinda\":\"kind of\",\n",
        "        \"let's\":\"let us\",\n",
        "        \"mayn't\":\"may not\",\n",
        "        \"may've\":\"may have\",\n",
        "        \"mightn't\":\"might not\",\n",
        "        \"might've\":\"might have\",\n",
        "        \"mustn't\":\"must not\",\n",
        "        \"mustn't've\":\"must not have\",\n",
        "        \"must've\":\"must have\",\n",
        "        \"needn't\":\"need not\",\n",
        "        \"ne'er\":\"never\",\n",
        "        \"o'\":\"of\",\n",
        "        \"o'er\":\"over\",\n",
        "        \"ol'\":\"old\",\n",
        "        \"oughtn't\":\"ought not\",\n",
        "        \"shalln't\":\"shall not\",\n",
        "        \"shan't\":\"shall not\",\n",
        "        \"she'd\":\"she would\",\n",
        "        \"she'll\":\"she will\",\n",
        "        \"she's\":\"she is\",\n",
        "        \"shouldn't\":\"should not\",\n",
        "        \"shouldn't've\":\"should not have\",\n",
        "        \"should've\":\"should have\",\n",
        "        \"somebody's\":\"somebody is\",\n",
        "        \"someone's\":\"someone is\",\n",
        "        \"something's\":\"something is\",\n",
        "        \"that'd\":\"that would\",\n",
        "        \"that'll\":\"that will\",\n",
        "        \"that're\":\"that are\",\n",
        "        \"that's\":\"that is\",\n",
        "        \"there'd\":\"there would\",\n",
        "        \"there'll\":\"there will\",\n",
        "        \"there're\":\"there are\",\n",
        "        \"there's\":\"there is\",\n",
        "        \"these're\":\"these are\",\n",
        "        \"they'd\":\"they would\",\n",
        "        \"they'll\":\"they will\",\n",
        "        \"they're\":\"they are\",\n",
        "        \"they've\":\"they have\",\n",
        "        \"this's\":\"this is\",\n",
        "        \"those're\":\"those are\",\n",
        "        \"'tis\":\"it is\",\n",
        "        \"'twas\":\"it was\",\n",
        "        \"wanna\":\"want to\",\n",
        "        \"wasn't\":\"was not\",\n",
        "        \"we'd\":\"we would\",\n",
        "        \"we'd've\":\"we would have\",\n",
        "        \"we'll\":\"we will\",\n",
        "        \"we're\":\"we are\",\n",
        "        \"weren't\":\"were not\",\n",
        "        \"we've\":\"we have\",\n",
        "        \"what'd\":\"what did\",\n",
        "        \"what'll\":\"what will\",\n",
        "        \"what're\":\"what are\",\n",
        "        \"what's\":\"what is\",\n",
        "        \"what've\":\"what have\",\n",
        "        \"when's\":\"when is\",\n",
        "        \"where'd\":\"where did\",\n",
        "        \"where're\":\"where are\",\n",
        "        \"where's\":\"where is\",\n",
        "        \"where've\":\"where have\",\n",
        "        \"which's\":\"which is\",\n",
        "        \"who'd\":\"who would\",\n",
        "        \"who'd've\":\"who would have\",\n",
        "        \"who'll\":\"who will\",\n",
        "        \"who're\":\"who are\",\n",
        "        \"who's\":\"who is\",\n",
        "        \"who've\":\"who have\",\n",
        "        \"why'd\":\"why did\",\n",
        "        \"why're\":\"why are\",\n",
        "        \"why's\":\"why is\",\n",
        "        \"won't\":\"will not\",\n",
        "        \"wouldn't\":\"would not\",\n",
        "        \"would've\":\"would have\",\n",
        "        \"y'all\":\"you all\",\n",
        "        \"you'd\":\"you would\",\n",
        "        \"you'll\":\"you will\",\n",
        "        \"you're\":\"you are\",\n",
        "        \"you've\":\"you have\",\n",
        "        \"Whatcha\":\"What are you\",\n",
        "        \"luv\":\"love\",\n",
        "        \"sux\":\"sucks\"\n",
        "        }\n",
        "\n",
        "def strip_accents(text):\n",
        "    if 'ø' in text or  'Ø' in text:\n",
        "        #Do nothing when finding ø \n",
        "        return text   \n",
        "    text = text.encode('ascii', 'ignore')\n",
        "    text = text.decode(\"utf-8\")\n",
        "    return str(text)\n",
        "\n",
        "def tweet_cleaning_for_sentiment_analysis(tweet):    \n",
        "    tweet = re.sub(r\"(http?\\://|https?\\://|www|pic.)\\S+\", \"\", tweet) #Remove http links\n",
        "    #Escaping HTML characters\n",
        "    tweet = BeautifulSoup(tweet).get_text()\n",
        "    #Special case not handled previously.\n",
        "    tweet = tweet.replace('\\x92',\"'\")\n",
        "    #Removal of hastags/account\n",
        "    #tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", tweet).split())\n",
        "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \")\n",
        "    #Removal of address\n",
        "    tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
        "    #Removal of Punctuation\n",
        "    tweet = ' '.join(re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=]\", \" \", tweet).split())\n",
        "    #Lower case\n",
        "    tweet = tweet.lower()\n",
        "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)\", \"USER\", tweet).split())\n",
        "    #CONTRACTIONS source: https://en.wikipedia.org/wiki/Contraction_%28grammar%29\n",
        "    CONTRACTIONS = load_dict_contractions()\n",
        "    tweet = tweet.replace(\"’\",\"'\")\n",
        "    words = tweet.split()\n",
        "    reformed = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    # Standardizing words\n",
        "    tweet = ''.join(''.join(s)[:2] for _, s in itertools.groupby(tweet))\n",
        "    #Deal with smileys\n",
        "    #source: https://en.wikipedia.org/wiki/List_of_emoticons\n",
        "    SMILEY = load_dict_smileys()  \n",
        "    words = tweet.split()\n",
        "    reformed = [SMILEY[word] if word in SMILEY else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    #Deal with emojis\n",
        "    tweet = emoji.demojize(tweet)\n",
        "    #Strip accents\n",
        "    #tweet= strip_accents(tweet)\n",
        "    tweet = tweet.replace(\":\",\" \")\n",
        "    tweet = ' '.join(tweet.split())\n",
        "    \n",
        "    # DO NOT REMOVE STOP WORDS FOR SENTIMENT ANALYSIS - OR AT LEAST NOT NEGATIVE ONES\n",
        "\n",
        "    return tweet"
      ],
      "metadata": {
        "id": "IIBsi37PfGf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_cleaning_for_sentiment_analysis(data.iloc[6, :]['tweet'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1c42568d-c5b5-4fb8-acb8-9e11d6bef7e5",
        "id": "_t_-qlOEfGgA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'our kaptaan sahaab has scored 550+ runs in five consecutive seasons smiling_face_with_sunglasses abapnibaarihai flexed_biceps ipl2022 trophy bhaukaalmachadenge lsg lucknowsupergiants t20 tataipl lucknow uttarpradesh lsg2022'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word embeddings"
      ],
      "metadata": {
        "id": "yoea7YpafGgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download embedddings"
      ],
      "metadata": {
        "id": "GwKs5kRrfGgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir fasttext-embeddings\n",
        "%cd fasttext-embeddings\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
        "!unzip crawl-300d-2M-subword.zip\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da1e620b-830b-49e8-964d-ea9a77484861",
        "id": "2xH2hC72fGgD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fasttext-embeddings\n",
            "--2022-08-01 08:21:38--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5828358084 (5.4G) [application/zip]\n",
            "Saving to: ‘crawl-300d-2M-subword.zip’\n",
            "\n",
            "crawl-300d-2M-subwo 100%[===================>]   5.43G  12.5MB/s    in 8m 40s  \n",
            "\n",
            "2022-08-01 08:30:20 (10.7 MB/s) - ‘crawl-300d-2M-subword.zip’ saved [5828358084/5828358084]\n",
            "\n",
            "Archive:  crawl-300d-2M-subword.zip\n",
            "  inflating: crawl-300d-2M-subword.vec  \n",
            "  inflating: crawl-300d-2M-subword.bin  \n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir fasttext-embeddings\n",
        "%cd fasttext-embeddings\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M-subword.vec.zip\n",
        "!unzip wiki-news-300d-1M-subword.vec.zip\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcb71d8-c025-472c-ad52-096d48ea23c4",
        "id": "77o6tCTGfGgE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘fasttext-embeddings’: File exists\n",
            "/content/fasttext-embeddings\n",
            "--2022-07-21 15:24:21--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M-subword.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 587879973 (561M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M-subword.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M-s 100%[===================>] 560.65M  36.8MB/s    in 16s     \n",
            "\n",
            "2022-07-21 15:24:38 (34.7 MB/s) - ‘wiki-news-300d-1M-subword.vec.zip’ saved [587879973/587879973]\n",
            "\n",
            "Archive:  wiki-news-300d-1M-subword.vec.zip\n",
            "  inflating: wiki-news-300d-1M-subword.vec  \n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir fasttext-embeddings\n",
        "%cd fasttext-embeddings\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
        "!gzip -d cc.en.300.bin.gz\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8175877b-cad6-429c-bd9f-0f8a22b0431f",
        "id": "mZdrCP-4fGgF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘fasttext-embeddings’: File exists\n",
            "/content/fasttext-embeddings\n",
            "--2022-07-21 15:28:31--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.en.300.bin.gz’\n",
            "\n",
            "cc.en.300.bin.gz    100%[===================>]   4.19G  28.1MB/s    in 2m 18s  \n",
            "\n",
            "2022-07-21 15:30:49 (31.2 MB/s) - ‘cc.en.300.bin.gz’ saved [4503593528/4503593528]\n",
            "\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir fasttext-embeddings\n",
        "# %cd fasttext-embeddings\n",
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
        "# !unzip crawl-300d-2M.vec.zip"
      ],
      "metadata": {
        "id": "vfMkAYMlfGgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8999de25-9fdc-4294-bd9b-b9a3b96fa783",
        "id": "wq0hlGYCfGgH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading model"
      ],
      "metadata": {
        "id": "j0LKMBcLfGgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# fasttext_emb = fasttext.load_model('/content/fasttext-embeddings/cc.en.300.bin')\n",
        "# print(ft.get_dimension())\n",
        "\n",
        "# fasttext.util.reduce_model(ft, 100)\n",
        "# print(ft.get_dimension())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "cc7a0d25-c57a-42e7-8bf4-3cab33cc8ab6",
        "id": "iJhYbsn_fGgI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-f87c31fcc971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfasttext_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/fasttext-embeddings/cc.en.300.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ft' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_emb = fasttext.FastText.load_model('./fasttext-embeddings/crawl-300d-2M-subword.bin')\n",
        "#fasttext_emb = fasttext.FastText.load_model('./fasttext-embeddings/wiki-news-300d-1M-subword.vec')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a78c8ed2-8884-4909-dd5a-888cbadf0ce6",
        "id": "c2o8hcBpfGgK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_emb.get_nearest_neighbors(\"__user__\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30353ad-74b4-42bf-e163-d67314f4a201",
        "id": "dVivIx66fGgK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.6122851371765137, 'intrebari'),\n",
              " (0.6034965515136719, 'vmware-modconfig'),\n",
              " (0.5972209572792053, 'eclipselink-orm.xml'),\n",
              " (0.5965851545333862, 'base-config'),\n",
              " (0.5962321162223816, 'hostnamectl'),\n",
              " (0.5956684350967407, 'myconfig'),\n",
              " (0.593761146068573, 'webpack.config.js'),\n",
              " (0.5922401547431946, 'mkvirtualenv'),\n",
              " (0.5871965289115906, 'libxml2-dev'),\n",
              " (0.5849608182907104, 'jboss-service.xml')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing data"
      ],
      "metadata": {
        "id": "znCjOEjrfGgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"Sentiment models - Labelled Test Data.csv\")\n",
        "\n",
        "data['cleaned_tweets'] = data.tweet.astype(str).apply(tweet_cleaning_for_sentiment_analysis)\n",
        "data['sent_vec'] = data.cleaned_tweets.apply(fasttext_emb.get_sentence_vector)\n",
        "\n",
        "with open(\"twitter-test-data-without-emojis.pkl\", \"wb\") as f:\n",
        "  pickle.dump(data, f)\n",
        "\n",
        "# del data"
      ],
      "metadata": {
        "id": "MG9hrqF1fGgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(pickle_filepath):\n",
        "  data = pickle.load(open(pickle_filepath,'rb'))\n",
        "  \n",
        "  X = np.array(list(data.sent_vec.apply(lambda x: list(x)).values))\n",
        "  \n",
        "  return X, data.label.values"
      ],
      "metadata": {
        "id": "4_PewcEPfGgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest, ytest = prepare_data(\"twitter-test-data-without-emojis.pkl\")"
      ],
      "metadata": {
        "id": "ITqrcqhffGgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest.shape, ytest.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302d4012-b498-44df-82bc-824451127334",
        "id": "mD9sv4YYfGgN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((62, 300), (62,))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del fasttext_emb"
      ],
      "metadata": {
        "id": "1lSpdAZMj2TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test models"
      ],
      "metadata": {
        "id": "G1BJ7TIXfGgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/file/d/16RTmAYGJ-FWRJ1R_oYcNE-3opdopb37X/view --fuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1c324c0-e961-425d-9af6-34d6de39efa5",
        "id": "tg4-m7b1fGgO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16RTmAYGJ-FWRJ1R_oYcNE-3opdopb37X\n",
            "To: /content/models.rar\n",
            "100% 116M/116M [00:00<00:00, 200MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models\n",
        "!unrar e models.rar /content/models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73588f5f-d627-4cb5-dbc7-fed527bf627c",
        "id": "LQzDQw4ZfGgO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from models.rar\n",
            "\n",
            "Extracting  /content/models/finaldata_random_forest.joblib               \b\b\b\b  3%\b\b\b\b  7%\b\b\b\b 10%\b\b\b\b 14%\b\b\b\b 18%\b\b\b\b 21%\b\b\b\b 25%\b\b\b\b 28%\b\b\b\b 32%\b\b\b\b 36%\b\b\b\b 39%\b\b\b\b 43%\b\b\b\b 46%\b\b\b\b 50%\b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_random_forest_undersampled.joblib     \b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_xgboost_model.json                 \b\b\b\b 60%\b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_xgboost_model_undersampled.json     \b\b\b\b 67%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_xgboost_model_undersampled.joblib     \b\b\b\b 75%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_xgboost_model.pkl                  \b\b\b\b 83%\b\b\b\b 85%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_xgboost_model.joblib               \b\b\b\b 89%\b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_xgboost_model_undersampled.pkl     \b\b\b\b 95%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "LagpjpU8fGgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "eKPuvxlmfGgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = joblib.load(\"/content/models/finaldata_random_forest.joblib\")"
      ],
      "metadata": {
        "id": "BI_rRzn3fGgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = rf.predict(Xtest)\n",
        "print(classification_report(ytest, predictions)) #Random forest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "decd15f3-5201-42f3-b406-a5196b8038c5",
        "id": "RKkEGfLOfGgQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.27      0.15      0.19        20\n",
            "     NEUTRAL       0.20      0.64      0.31        14\n",
            "    POSITIVE       0.50      0.11      0.18        28\n",
            "\n",
            "    accuracy                           0.24        62\n",
            "   macro avg       0.32      0.30      0.23        62\n",
            "weighted avg       0.36      0.24      0.21        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf = pd.DataFrame()"
      ],
      "metadata": {
        "id": "vJcrs-9ffGgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['Random Forest'] = predictions"
      ],
      "metadata": {
        "id": "Yk5qlzV4fGgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest - Undersampled"
      ],
      "metadata": {
        "id": "De0ou478fGgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = joblib.load(\"/content/models/finaldata_random_forest_undersampled.joblib\")"
      ],
      "metadata": {
        "id": "GgJa490PfGgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = rf.predict(Xtest)\n",
        "print(classification_report(ytest, predictions)) #Random forest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qc9SzvBkPvE",
        "outputId": "04ea957f-d71c-41b6-b160-ed9e1c1a2042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.38      0.40      0.39        20\n",
            "     NEUTRAL       0.21      0.36      0.26        14\n",
            "    POSITIVE       0.65      0.39      0.49        28\n",
            "\n",
            "    accuracy                           0.39        62\n",
            "   macro avg       0.41      0.38      0.38        62\n",
            "weighted avg       0.46      0.39      0.41        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['Random Forest - Undersampled'] = predictions"
      ],
      "metadata": {
        "id": "7ORO19sQfGgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "gaEXlc5vfGgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = joblib.load(\"/content/models/finaldata_xgboost_model.joblib\")"
      ],
      "metadata": {
        "id": "x2cHIBbEkYy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = xgb_model.predict(Xtest)\n",
        "print(classification_report(ytest, predictions)) #xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh95qLvUkd-x",
        "outputId": "b300a7a2-1485-4133-e95f-3c79eaa7847c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.41      0.35      0.38        20\n",
            "     NEUTRAL       0.17      0.29      0.22        14\n",
            "    POSITIVE       0.59      0.46      0.52        28\n",
            "\n",
            "    accuracy                           0.39        62\n",
            "   macro avg       0.39      0.37      0.37        62\n",
            "weighted avg       0.44      0.39      0.41        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['XGBoost'] = predictions"
      ],
      "metadata": {
        "id": "Gp0t8V8UfGgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost - Undersampled"
      ],
      "metadata": {
        "id": "KVzNbYdHfGgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = joblib.load(\"/content/models/finaldata_xgboost_model_undersampled.joblib\")"
      ],
      "metadata": {
        "id": "3j029lEUkjEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = xgb_model.predict(Xtest)\n",
        "print(classification_report(ytest, predictions)) #xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRZ2KP9_klwn",
        "outputId": "ae3d491f-9bb8-44f5-851e-e875a34cdc94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.48      0.55      0.51        20\n",
            "     NEUTRAL       0.36      0.36      0.36        14\n",
            "    POSITIVE       0.68      0.61      0.64        28\n",
            "\n",
            "    accuracy                           0.53        62\n",
            "   macro avg       0.51      0.50      0.50        62\n",
            "weighted avg       0.54      0.53      0.54        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['XGBoost - Undersampled'] = predictions"
      ],
      "metadata": {
        "id": "YWK-2T0HfGgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "8f080720-cee8-4678-8379-4d3401fb987c",
        "id": "33j8E5GLfGgW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Random Forest Random Forest - Undersampled   XGBoost XGBoost - Undersampled\n",
              "0        NEUTRAL                     POSITIVE  POSITIVE               POSITIVE\n",
              "1        NEUTRAL                      NEUTRAL   NEUTRAL                NEUTRAL\n",
              "2        NEUTRAL                     POSITIVE  POSITIVE               POSITIVE\n",
              "3        NEUTRAL                      NEUTRAL   NEUTRAL                NEUTRAL\n",
              "4        NEUTRAL                     NEGATIVE  NEGATIVE               NEGATIVE\n",
              "..           ...                          ...       ...                    ...\n",
              "57       NEUTRAL                      NEUTRAL   NEUTRAL               POSITIVE\n",
              "58       NEUTRAL                     NEGATIVE  NEGATIVE               NEGATIVE\n",
              "59       NEUTRAL                     POSITIVE  POSITIVE               POSITIVE\n",
              "60       NEUTRAL                     NEGATIVE   NEUTRAL               NEGATIVE\n",
              "61       NEUTRAL                     POSITIVE  POSITIVE               POSITIVE\n",
              "\n",
              "[62 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8d4811b-c93c-461c-9c2a-50f7295d184d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>Random Forest - Undersampled</th>\n",
              "      <th>XGBoost</th>\n",
              "      <th>XGBoost - Undersampled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8d4811b-c93c-461c-9c2a-50f7295d184d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e8d4811b-c93c-461c-9c2a-50f7295d184d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e8d4811b-c93c-461c-9c2a-50f7295d184d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERTweet"
      ],
      "metadata": {
        "id": "v0NiFpuLfGgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pickle.load(open(\"/content/twitter-test-data-without-emojis.pkl\", \"rb\"))\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "b4140bad-2835-4007-b85b-54044b9d1843",
        "id": "5kjC1MppfGgX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                tweet     label  \\\n",
              "0   ‘It has been a really memorable season’ – Jos ...  POSITIVE   \n",
              "1   Mumbai Indians and Titans Cricket batter, Dewa...  POSITIVE   \n",
              "2   There were several uncapped players who proved...  POSITIVE   \n",
              "3   AFTER ARGUING WITH VERIZON REGARDING THE DROPP...  NEGATIVE   \n",
              "4   A usable keyboard actually turns a PDA into a ...  POSITIVE   \n",
              "..                                                ...       ...   \n",
              "57  @satyanadella @Microsoft thanks for celebratin...  POSITIVE   \n",
              "58                         Thatâ€™s the best one wtf?  POSITIVE   \n",
              "59  AOC you make some very ignorant comments\\n Whe...   NEUTRAL   \n",
              "60  oooooh shit i think my motherboard is already ...  POSITIVE   \n",
              "61  NYUMMM DELICIOUS FINALLY SOME GOOD CONTENT NYU...   NEUTRAL   \n",
              "\n",
              "                                       cleaned_tweets  \\\n",
              "0   ‘it has been a really memorable season' – jos ...   \n",
              "1   mumbai indians and titans cricket batter dewal...   \n",
              "2   there were several uncapped players who proved...   \n",
              "3   after arguing with verizon regarding the dropp...   \n",
              "4   a usable keyboard actually turns a pda into a ...   \n",
              "..                                                ...   \n",
              "57  USER USER thanks for celebrating diversity we ...   \n",
              "58               thatâ€ trade_mark s the best one wtf   \n",
              "59  aoc you make some very ignorant comments when ...   \n",
              "60  ooh shit i think my motherboard is already com...   \n",
              "61  nyumm delicious finally some good content nyum...   \n",
              "\n",
              "                                             sent_vec  \n",
              "0   [0.0044800234, -0.024687007, 0.03165525, 0.026...  \n",
              "1   [-0.013870388, -0.042408988, 0.0869929, 0.0214...  \n",
              "2   [-0.012238055, -0.05264265, 0.08353262, 0.0121...  \n",
              "3   [0.0059597986, -0.049668398, 0.0746304, 0.0094...  \n",
              "4   [-0.0028914495, 0.009457815, 0.075295255, 0.00...  \n",
              "..                                                ...  \n",
              "57  [-0.0034089629, -0.049936995, 0.08740346, 0.02...  \n",
              "58  [0.010495955, -0.015235853, 0.10701324, 0.0062...  \n",
              "59  [-0.0043282043, -0.063566, 0.087194875, 0.0080...  \n",
              "60  [-0.0018573017, 0.026468603, 0.07860464, 0.002...  \n",
              "61  [-0.0055657444, -0.0040176334, 0.07378124, 0.0...  \n",
              "\n",
              "[62 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3945c18-f7b3-48e7-babb-3ba7791cb4ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_tweets</th>\n",
              "      <th>sent_vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>‘It has been a really memorable season’ – Jos ...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>‘it has been a really memorable season' – jos ...</td>\n",
              "      <td>[0.0044800234, -0.024687007, 0.03165525, 0.026...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mumbai Indians and Titans Cricket batter, Dewa...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>mumbai indians and titans cricket batter dewal...</td>\n",
              "      <td>[-0.013870388, -0.042408988, 0.0869929, 0.0214...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>There were several uncapped players who proved...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>there were several uncapped players who proved...</td>\n",
              "      <td>[-0.012238055, -0.05264265, 0.08353262, 0.0121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AFTER ARGUING WITH VERIZON REGARDING THE DROPP...</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>after arguing with verizon regarding the dropp...</td>\n",
              "      <td>[0.0059597986, -0.049668398, 0.0746304, 0.0094...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A usable keyboard actually turns a PDA into a ...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>a usable keyboard actually turns a pda into a ...</td>\n",
              "      <td>[-0.0028914495, 0.009457815, 0.075295255, 0.00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>@satyanadella @Microsoft thanks for celebratin...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>USER USER thanks for celebrating diversity we ...</td>\n",
              "      <td>[-0.0034089629, -0.049936995, 0.08740346, 0.02...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>Thatâ€™s the best one wtf?</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>thatâ€ trade_mark s the best one wtf</td>\n",
              "      <td>[0.010495955, -0.015235853, 0.10701324, 0.0062...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>AOC you make some very ignorant comments\\n Whe...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>aoc you make some very ignorant comments when ...</td>\n",
              "      <td>[-0.0043282043, -0.063566, 0.087194875, 0.0080...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>oooooh shit i think my motherboard is already ...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>ooh shit i think my motherboard is already com...</td>\n",
              "      <td>[-0.0018573017, 0.026468603, 0.07860464, 0.002...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>NYUMMM DELICIOUS FINALLY SOME GOOD CONTENT NYU...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>nyumm delicious finally some good content nyum...</td>\n",
              "      <td>[-0.0055657444, -0.0040176334, 0.07378124, 0.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3945c18-f7b3-48e7-babb-3ba7791cb4ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f3945c18-f7b3-48e7-babb-3ba7791cb4ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f3945c18-f7b3-48e7-babb-3ba7791cb4ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['BERTweet'] = data['cleaned_tweets'].apply(sa1.inference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0394be6-b4a5-4783-aa66-3f6397b34501",
        "id": "W8uO_q6WfGgY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(ytest, testdf['BERTweet'].values)) #BERtweet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c8c999f-646f-4efd-e56b-183b5ddd30ed",
        "id": "BjOHs-VFfGgZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.50      0.60      0.55        20\n",
            "     NEUTRAL       0.21      0.21      0.21        14\n",
            "    POSITIVE       0.83      0.71      0.77        28\n",
            "\n",
            "    accuracy                           0.56        62\n",
            "   macro avg       0.52      0.51      0.51        62\n",
            "weighted avg       0.59      0.56      0.57        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT base"
      ],
      "metadata": {
        "id": "CVmLO_JXfGgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['bert-base-multilingual-uncased-sentiment_clean'] = data['cleaned_tweets'].apply(sa2.inference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cec0b4c-e650-4c62-f596-38925a066579",
        "id": "vy_C13fBfGgZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(ytest, testdf['bert-base-multilingual-uncased-sentiment_clean'].values)) #BERT Base"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d58e23-98f4-428f-eea8-ef8e845e0165",
        "id": "nL4nFYTLfGgb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.52      0.70      0.60        20\n",
            "     NEUTRAL       1.00      0.07      0.13        14\n",
            "    POSITIVE       0.71      0.86      0.77        28\n",
            "\n",
            "    accuracy                           0.63        62\n",
            "   macro avg       0.74      0.54      0.50        62\n",
            "weighted avg       0.71      0.63      0.57        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['tweet'] = data['tweet']\n",
        "testdf['label'] = data['label']\n",
        "\n",
        "testdf['cleaned_tweets'] = data['cleaned_tweets']\n",
        "\n",
        "testdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "4a766560-189c-44fd-b781-05ee59e56421",
        "id": "NdofmlPJfGgc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Random Forest Random Forest - Undersampled   XGBoost  \\\n",
              "0        NEUTRAL                     POSITIVE  POSITIVE   \n",
              "1        NEUTRAL                      NEUTRAL   NEUTRAL   \n",
              "2        NEUTRAL                     POSITIVE  POSITIVE   \n",
              "3        NEUTRAL                      NEUTRAL   NEUTRAL   \n",
              "4        NEUTRAL                     NEGATIVE  NEGATIVE   \n",
              "..           ...                          ...       ...   \n",
              "57       NEUTRAL                      NEUTRAL   NEUTRAL   \n",
              "58       NEUTRAL                     NEGATIVE  NEGATIVE   \n",
              "59       NEUTRAL                     POSITIVE  POSITIVE   \n",
              "60       NEUTRAL                     NEGATIVE   NEUTRAL   \n",
              "61       NEUTRAL                     POSITIVE  POSITIVE   \n",
              "\n",
              "   XGBoost - Undersampled  BERTweet  \\\n",
              "0                POSITIVE  POSITIVE   \n",
              "1                 NEUTRAL  POSITIVE   \n",
              "2                POSITIVE  POSITIVE   \n",
              "3                 NEUTRAL  NEGATIVE   \n",
              "4                NEGATIVE  POSITIVE   \n",
              "..                    ...       ...   \n",
              "57               POSITIVE  POSITIVE   \n",
              "58               NEGATIVE  POSITIVE   \n",
              "59               POSITIVE  NEGATIVE   \n",
              "60               NEGATIVE  NEGATIVE   \n",
              "61               POSITIVE  POSITIVE   \n",
              "\n",
              "   bert-base-multilingual-uncased-sentiment_clean  \\\n",
              "0                                        POSITIVE   \n",
              "1                                        POSITIVE   \n",
              "2                                        POSITIVE   \n",
              "3                                        NEGATIVE   \n",
              "4                                        POSITIVE   \n",
              "..                                            ...   \n",
              "57                                       POSITIVE   \n",
              "58                                       POSITIVE   \n",
              "59                                       NEGATIVE   \n",
              "60                                       NEGATIVE   \n",
              "61                                       POSITIVE   \n",
              "\n",
              "                                                tweet     label  \\\n",
              "0   ‘It has been a really memorable season’ – Jos ...  POSITIVE   \n",
              "1   Mumbai Indians and Titans Cricket batter, Dewa...  POSITIVE   \n",
              "2   There were several uncapped players who proved...  POSITIVE   \n",
              "3   AFTER ARGUING WITH VERIZON REGARDING THE DROPP...  NEGATIVE   \n",
              "4   A usable keyboard actually turns a PDA into a ...  POSITIVE   \n",
              "..                                                ...       ...   \n",
              "57  @satyanadella @Microsoft thanks for celebratin...  POSITIVE   \n",
              "58                         Thatâ€™s the best one wtf?  POSITIVE   \n",
              "59  AOC you make some very ignorant comments\\n Whe...   NEUTRAL   \n",
              "60  oooooh shit i think my motherboard is already ...  POSITIVE   \n",
              "61  NYUMMM DELICIOUS FINALLY SOME GOOD CONTENT NYU...   NEUTRAL   \n",
              "\n",
              "                                       cleaned_tweets  \n",
              "0   ‘it has been a really memorable season' – jos ...  \n",
              "1   mumbai indians and titans cricket batter dewal...  \n",
              "2   there were several uncapped players who proved...  \n",
              "3   after arguing with verizon regarding the dropp...  \n",
              "4   a usable keyboard actually turns a pda into a ...  \n",
              "..                                                ...  \n",
              "57  USER USER thanks for celebrating diversity we ...  \n",
              "58               thatâ€ trade_mark s the best one wtf  \n",
              "59  aoc you make some very ignorant comments when ...  \n",
              "60  ooh shit i think my motherboard is already com...  \n",
              "61  nyumm delicious finally some good content nyum...  \n",
              "\n",
              "[62 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-079dca89-970a-4e9f-bae6-0c05e5ac4d4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>Random Forest - Undersampled</th>\n",
              "      <th>XGBoost</th>\n",
              "      <th>XGBoost - Undersampled</th>\n",
              "      <th>BERTweet</th>\n",
              "      <th>bert-base-multilingual-uncased-sentiment_clean</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>‘It has been a really memorable season’ – Jos ...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>‘it has been a really memorable season' – jos ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>Mumbai Indians and Titans Cricket batter, Dewa...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>mumbai indians and titans cricket batter dewal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>There were several uncapped players who proved...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>there were several uncapped players who proved...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>AFTER ARGUING WITH VERIZON REGARDING THE DROPP...</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>after arguing with verizon regarding the dropp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>A usable keyboard actually turns a PDA into a ...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>a usable keyboard actually turns a pda into a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>@satyanadella @Microsoft thanks for celebratin...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>USER USER thanks for celebrating diversity we ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>Thatâ€™s the best one wtf?</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>thatâ€ trade_mark s the best one wtf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>AOC you make some very ignorant comments\\n Whe...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>aoc you make some very ignorant comments when ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>oooooh shit i think my motherboard is already ...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>ooh shit i think my motherboard is already com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>NYUMMM DELICIOUS FINALLY SOME GOOD CONTENT NYU...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>nyumm delicious finally some good content nyum...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-079dca89-970a-4e9f-bae6-0c05e5ac4d4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-079dca89-970a-4e9f-bae6-0c05e5ac4d4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-079dca89-970a-4e9f-bae6-0c05e5ac4d4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf.to_excel(\"twitter-sample-data-results-without-emojis.xlsx\")"
      ],
      "metadata": {
        "id": "KYJERZElfGgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./test-predictions-undersampled.pkl\",\"wb\") as f:\n",
        "  pickle.dump(testdf, f)"
      ],
      "metadata": {
        "id": "opauGEqtfGgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Twitter custom test dataset - Part 2"
      ],
      "metadata": {
        "id": "RulU8QzAX4aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext emoji -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed3c564-d759-4ffb-ddea-86120c148728",
        "id": "ChEQ0KFbX4aS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 68 kB 3.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 197 kB 10.4 MB/s \n",
            "\u001b[?25h  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import re\n",
        "import itertools\n",
        "import emoji\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "import fasttext\n",
        "import fasttext.util"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf83930-e823-4e77-db5e-e0d3d6617a89",
        "id": "FfXcN83XX4ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning data"
      ],
      "metadata": {
        "id": "1x2Muih6X4aY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dict_smileys():\n",
        "    \n",
        "    return {\n",
        "        \":‑)\":\"smiley\",\n",
        "        \":-]\":\"smiley\",\n",
        "        \":-3\":\"smiley\",\n",
        "        \":->\":\"smiley\",\n",
        "        \"8-)\":\"smiley\",\n",
        "        \":-}\":\"smiley\",\n",
        "        \":)\":\"smiley\",\n",
        "        \":]\":\"smiley\",\n",
        "        \":3\":\"smiley\",\n",
        "        \":>\":\"smiley\",\n",
        "        \"8)\":\"smiley\",\n",
        "        \":}\":\"smiley\",\n",
        "        \":o)\":\"smiley\",\n",
        "        \":c)\":\"smiley\",\n",
        "        \":^)\":\"smiley\",\n",
        "        \"=]\":\"smiley\",\n",
        "        \"=)\":\"smiley\",\n",
        "        \":-))\":\"smiley\",\n",
        "        \":‑D\":\"smiley\",\n",
        "        \"8‑D\":\"smiley\",\n",
        "        \"x‑D\":\"smiley\",\n",
        "        \"X‑D\":\"smiley\",\n",
        "        \":D\":\"smiley\",\n",
        "        \"8D\":\"smiley\",\n",
        "        \"xD\":\"smiley\",\n",
        "        \"XD\":\"smiley\",\n",
        "        \":‑(\":\"sad\",\n",
        "        \":‑c\":\"sad\",\n",
        "        \":‑<\":\"sad\",\n",
        "        \":‑[\":\"sad\",\n",
        "        \":(\":\"sad\",\n",
        "        \":c\":\"sad\",\n",
        "        \":<\":\"sad\",\n",
        "        \":[\":\"sad\",\n",
        "        \":-||\":\"sad\",\n",
        "        \">:[\":\"sad\",\n",
        "        \":{\":\"sad\",\n",
        "        \":@\":\"sad\",\n",
        "        \">:(\":\"sad\",\n",
        "        \":'‑(\":\"sad\",\n",
        "        \":'(\":\"sad\",\n",
        "        \":‑P\":\"playful\",\n",
        "        \"X‑P\":\"playful\",\n",
        "        \"x‑p\":\"playful\",\n",
        "        \":‑p\":\"playful\",\n",
        "        \":‑Þ\":\"playful\",\n",
        "        \":‑þ\":\"playful\",\n",
        "        \":‑b\":\"playful\",\n",
        "        \":P\":\"playful\",\n",
        "        \"XP\":\"playful\",\n",
        "        \"xp\":\"playful\",\n",
        "        \":p\":\"playful\",\n",
        "        \":Þ\":\"playful\",\n",
        "        \":þ\":\"playful\",\n",
        "        \":b\":\"playful\",\n",
        "        \"<3\":\"love\"\n",
        "        }\n",
        "\n",
        "def load_dict_contractions():\n",
        "    \n",
        "    return {\n",
        "        \"ain't\":\"is not\",\n",
        "        \"amn't\":\"am not\",\n",
        "        \"aren't\":\"are not\",\n",
        "        \"can't\":\"cannot\",\n",
        "        \"'cause\":\"because\",\n",
        "        \"couldn't\":\"could not\",\n",
        "        \"couldn't've\":\"could not have\",\n",
        "        \"could've\":\"could have\",\n",
        "        \"daren't\":\"dare not\",\n",
        "        \"daresn't\":\"dare not\",\n",
        "        \"dasn't\":\"dare not\",\n",
        "        \"didn't\":\"did not\",\n",
        "        \"doesn't\":\"does not\",\n",
        "        \"don't\":\"do not\",\n",
        "        \"e'er\":\"ever\",\n",
        "        \"em\":\"them\",\n",
        "        \"everyone's\":\"everyone is\",\n",
        "        \"finna\":\"fixing to\",\n",
        "        \"gimme\":\"give me\",\n",
        "        \"gonna\":\"going to\",\n",
        "        \"gon't\":\"go not\",\n",
        "        \"gotta\":\"got to\",\n",
        "        \"hadn't\":\"had not\",\n",
        "        \"hasn't\":\"has not\",\n",
        "        \"haven't\":\"have not\",\n",
        "        \"he'd\":\"he would\",\n",
        "        \"he'll\":\"he will\",\n",
        "        \"he's\":\"he is\",\n",
        "        \"he've\":\"he have\",\n",
        "        \"how'd\":\"how would\",\n",
        "        \"how'll\":\"how will\",\n",
        "        \"how're\":\"how are\",\n",
        "        \"how's\":\"how is\",\n",
        "        \"I'd\":\"I would\",\n",
        "        \"I'll\":\"I will\",\n",
        "        \"I'm\":\"I am\",\n",
        "        \"I'm'a\":\"I am about to\",\n",
        "        \"I'm'o\":\"I am going to\",\n",
        "        \"isn't\":\"is not\",\n",
        "        \"it'd\":\"it would\",\n",
        "        \"it'll\":\"it will\",\n",
        "        \"it's\":\"it is\",\n",
        "        \"I've\":\"I have\",\n",
        "        \"kinda\":\"kind of\",\n",
        "        \"let's\":\"let us\",\n",
        "        \"mayn't\":\"may not\",\n",
        "        \"may've\":\"may have\",\n",
        "        \"mightn't\":\"might not\",\n",
        "        \"might've\":\"might have\",\n",
        "        \"mustn't\":\"must not\",\n",
        "        \"mustn't've\":\"must not have\",\n",
        "        \"must've\":\"must have\",\n",
        "        \"needn't\":\"need not\",\n",
        "        \"ne'er\":\"never\",\n",
        "        \"o'\":\"of\",\n",
        "        \"o'er\":\"over\",\n",
        "        \"ol'\":\"old\",\n",
        "        \"oughtn't\":\"ought not\",\n",
        "        \"shalln't\":\"shall not\",\n",
        "        \"shan't\":\"shall not\",\n",
        "        \"she'd\":\"she would\",\n",
        "        \"she'll\":\"she will\",\n",
        "        \"she's\":\"she is\",\n",
        "        \"shouldn't\":\"should not\",\n",
        "        \"shouldn't've\":\"should not have\",\n",
        "        \"should've\":\"should have\",\n",
        "        \"somebody's\":\"somebody is\",\n",
        "        \"someone's\":\"someone is\",\n",
        "        \"something's\":\"something is\",\n",
        "        \"that'd\":\"that would\",\n",
        "        \"that'll\":\"that will\",\n",
        "        \"that're\":\"that are\",\n",
        "        \"that's\":\"that is\",\n",
        "        \"there'd\":\"there would\",\n",
        "        \"there'll\":\"there will\",\n",
        "        \"there're\":\"there are\",\n",
        "        \"there's\":\"there is\",\n",
        "        \"these're\":\"these are\",\n",
        "        \"they'd\":\"they would\",\n",
        "        \"they'll\":\"they will\",\n",
        "        \"they're\":\"they are\",\n",
        "        \"they've\":\"they have\",\n",
        "        \"this's\":\"this is\",\n",
        "        \"those're\":\"those are\",\n",
        "        \"'tis\":\"it is\",\n",
        "        \"'twas\":\"it was\",\n",
        "        \"wanna\":\"want to\",\n",
        "        \"wasn't\":\"was not\",\n",
        "        \"we'd\":\"we would\",\n",
        "        \"we'd've\":\"we would have\",\n",
        "        \"we'll\":\"we will\",\n",
        "        \"we're\":\"we are\",\n",
        "        \"weren't\":\"were not\",\n",
        "        \"we've\":\"we have\",\n",
        "        \"what'd\":\"what did\",\n",
        "        \"what'll\":\"what will\",\n",
        "        \"what're\":\"what are\",\n",
        "        \"what's\":\"what is\",\n",
        "        \"what've\":\"what have\",\n",
        "        \"when's\":\"when is\",\n",
        "        \"where'd\":\"where did\",\n",
        "        \"where're\":\"where are\",\n",
        "        \"where's\":\"where is\",\n",
        "        \"where've\":\"where have\",\n",
        "        \"which's\":\"which is\",\n",
        "        \"who'd\":\"who would\",\n",
        "        \"who'd've\":\"who would have\",\n",
        "        \"who'll\":\"who will\",\n",
        "        \"who're\":\"who are\",\n",
        "        \"who's\":\"who is\",\n",
        "        \"who've\":\"who have\",\n",
        "        \"why'd\":\"why did\",\n",
        "        \"why're\":\"why are\",\n",
        "        \"why's\":\"why is\",\n",
        "        \"won't\":\"will not\",\n",
        "        \"wouldn't\":\"would not\",\n",
        "        \"would've\":\"would have\",\n",
        "        \"y'all\":\"you all\",\n",
        "        \"you'd\":\"you would\",\n",
        "        \"you'll\":\"you will\",\n",
        "        \"you're\":\"you are\",\n",
        "        \"you've\":\"you have\",\n",
        "        \"Whatcha\":\"What are you\",\n",
        "        \"luv\":\"love\",\n",
        "        \"sux\":\"sucks\"\n",
        "        }\n",
        "\n",
        "def strip_accents(text):\n",
        "    if 'ø' in text or  'Ø' in text:\n",
        "        #Do nothing when finding ø \n",
        "        return text   \n",
        "    text = text.encode('ascii', 'ignore')\n",
        "    text = text.decode(\"utf-8\")\n",
        "    return str(text)\n",
        "\n",
        "def tweet_cleaning_for_sentiment_analysis(tweet):    \n",
        "    tweet = re.sub(r\"(http?\\://|https?\\://|www|pic.)\\S+\", \"\", tweet) #Remove http links\n",
        "    #Escaping HTML characters\n",
        "    tweet = BeautifulSoup(tweet).get_text()\n",
        "    #Special case not handled previously.\n",
        "    tweet = tweet.replace('\\x92',\"'\")\n",
        "    #Removal of hastags/account\n",
        "    #tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", tweet).split())\n",
        "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \")\n",
        "    #Removal of address\n",
        "    tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
        "    #Removal of Punctuation\n",
        "    tweet = ' '.join(re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=]\", \" \", tweet).split())\n",
        "    #Lower case\n",
        "    tweet = tweet.lower()\n",
        "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)\", \"USER\", tweet).split())\n",
        "    #CONTRACTIONS source: https://en.wikipedia.org/wiki/Contraction_%28grammar%29\n",
        "    CONTRACTIONS = load_dict_contractions()\n",
        "    tweet = tweet.replace(\"’\",\"'\")\n",
        "    words = tweet.split()\n",
        "    reformed = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    # Standardizing words\n",
        "    tweet = ''.join(''.join(s)[:2] for _, s in itertools.groupby(tweet))\n",
        "    #Deal with smileys\n",
        "    #source: https://en.wikipedia.org/wiki/List_of_emoticons\n",
        "    SMILEY = load_dict_smileys()  \n",
        "    words = tweet.split()\n",
        "    reformed = [SMILEY[word] if word in SMILEY else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    #Deal with emojis\n",
        "    # tweet = emoji.demojize(tweet)\n",
        "    #Strip accents\n",
        "    #tweet= strip_accents(tweet)\n",
        "    tweet = tweet.replace(\":\",\" \")\n",
        "    tweet = ' '.join(tweet.split())\n",
        "    \n",
        "    # DO NOT REMOVE STOP WORDS FOR SENTIMENT ANALYSIS - OR AT LEAST NOT NEGATIVE ONES\n",
        "\n",
        "    return tweet"
      ],
      "metadata": {
        "id": "8Q6E_mqzX4ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_cleaning_for_sentiment_analysis(data.iloc[6, :]['tweet'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1c42568d-c5b5-4fb8-acb8-9e11d6bef7e5",
        "id": "AFUPNRr3X4ap"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'our kaptaan sahaab has scored 550+ runs in five consecutive seasons smiling_face_with_sunglasses abapnibaarihai flexed_biceps ipl2022 trophy bhaukaalmachadenge lsg lucknowsupergiants t20 tataipl lucknow uttarpradesh lsg2022'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word embeddings"
      ],
      "metadata": {
        "id": "2A5QakgYX4at"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download embedddings"
      ],
      "metadata": {
        "id": "Lq0j8jdcX4av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir fasttext-embeddings\n",
        "%cd fasttext-embeddings\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
        "!unzip crawl-300d-2M-subword.zip\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33067055-4d5a-4679-d168-46199ec91382",
        "id": "nC2S2QlfX4ay"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fasttext-embeddings\n",
            "--2022-08-02 11:46:58--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5828358084 (5.4G) [application/zip]\n",
            "Saving to: ‘crawl-300d-2M-subword.zip’\n",
            "\n",
            "crawl-300d-2M-subwo 100%[===================>]   5.43G  35.0MB/s    in 2m 22s  \n",
            "\n",
            "2022-08-02 11:49:21 (39.1 MB/s) - ‘crawl-300d-2M-subword.zip’ saved [5828358084/5828358084]\n",
            "\n",
            "Archive:  crawl-300d-2M-subword.zip\n",
            "  inflating: crawl-300d-2M-subword.vec  \n",
            "  inflating: crawl-300d-2M-subword.bin  \n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir fasttext-embeddings\n",
        "# %cd fasttext-embeddings\n",
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M-subword.vec.zip\n",
        "# !unzip wiki-news-300d-1M-subword.vec.zip\n",
        "# %cd /content"
      ],
      "metadata": {
        "id": "630LMnzyX4a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir fasttext-embeddings\n",
        "# %cd fasttext-embeddings\n",
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
        "# !gzip -d cc.en.300.bin.gz\n",
        "# %cd /content"
      ],
      "metadata": {
        "id": "zp2heIMrX4a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir fasttext-embeddings\n",
        "# %cd fasttext-embeddings\n",
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
        "# !unzip crawl-300d-2M.vec.zip"
      ],
      "metadata": {
        "id": "p1YL7yJiX4a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "247d17fb-e598-4de8-e0e9-8c6e45cfbe63",
        "id": "SRWbpZ96X4bA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading model"
      ],
      "metadata": {
        "id": "neShPheDX4bB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# fasttext_emb = fasttext.load_model('/content/fasttext-embeddings/cc.en.300.bin')\n",
        "# print(ft.get_dimension())\n",
        "\n",
        "# fasttext.util.reduce_model(ft, 100)\n",
        "# print(ft.get_dimension())"
      ],
      "metadata": {
        "id": "ITDPgB1XX4bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_emb = fasttext.FastText.load_model('./fasttext-embeddings/crawl-300d-2M-subword.bin')\n",
        "#fasttext_emb = fasttext.FastText.load_model('./fasttext-embeddings/wiki-news-300d-1M-subword.vec')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb1eec6-f461-4444-c19f-c4b49b61e101",
        "id": "vCJWVZQDX4bG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_emb.get_nearest_neighbors(\"smiling_face_with_sunglasses\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce94def0-7abc-468a-e72e-aab2578c4fa4",
        "id": "WQDh7NMgX4bI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.6122851371765137, 'intrebari'),\n",
              " (0.6034965515136719, 'vmware-modconfig'),\n",
              " (0.5972209572792053, 'eclipselink-orm.xml'),\n",
              " (0.5965851545333862, 'base-config'),\n",
              " (0.5962321162223816, 'hostnamectl'),\n",
              " (0.5956684350967407, 'myconfig'),\n",
              " (0.593761146068573, 'webpack.config.js'),\n",
              " (0.5922401547431946, 'mkvirtualenv'),\n",
              " (0.5871965289115906, 'libxml2-dev'),\n",
              " (0.5849608182907104, 'jboss-service.xml')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing data"
      ],
      "metadata": {
        "id": "xIYx-08oX4bL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"Sentiment models - New.csv\")\n",
        "\n",
        "data['cleaned_tweets'] = data.tweet.astype(str).apply(tweet_cleaning_for_sentiment_analysis)\n",
        "data['sent_vec'] = data.cleaned_tweets.apply(fasttext_emb.get_sentence_vector)\n",
        "\n",
        "with open(\"twitter-test-data-new.pkl\", \"wb\") as f:\n",
        "  pickle.dump(data, f)\n",
        "\n",
        "del data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "Ccloou82X4bM",
        "outputId": "c6cc4f4f-00a7-4456-e2fe-e5fda48f10df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    label                                              tweet  \\\n",
              "0       0  @user when a father is dysfunctional and is so...   \n",
              "1       0  @user @user thanks for #lyft credit i can't us...   \n",
              "2       0                                bihday your majesty   \n",
              "3       0  #model i love u take with u all the time in ur...   \n",
              "4       0                factsguide: society now #motivation   \n",
              "..    ...                                                ...   \n",
              "94      0  omg!!! loving this station!!! way to jam out a...   \n",
              "95      0  @user i'll always hope that one day i'll get t...   \n",
              "96      0  #model i love u take with u all the time in ur...   \n",
              "97      0         couple having sex fat naked japanese girls   \n",
              "98      0  #hump on that #hump day #humpersÃ°ÂŸÂ˜Â© @ edw...   \n",
              "\n",
              "                                       cleaned_tweets  \\\n",
              "0   USER when a father is dysfunctional and is so ...   \n",
              "1   USER USER thanks for lyft credit i cannot use ...   \n",
              "2                                 bihday your majesty   \n",
              "3   model i love u take with u all the time in urã...   \n",
              "4                   factsguide society now motivation   \n",
              "..                                                ...   \n",
              "94  omg loving this station way to jam out at work...   \n",
              "95  USER i'll always hope that one day i'll get to...   \n",
              "96  model i love u take with u all the time in urã...   \n",
              "97         couple having sex fat naked japanese girls   \n",
              "98  hump on that hump day humpersã°âÿâ˜â© @ edward...   \n",
              "\n",
              "                                             sent_vec  \n",
              "0   [-0.014220357, -0.008476666, 0.08933757, 0.003...  \n",
              "1   [-0.0136345625, -0.04320838, 0.083086476, -0.0...  \n",
              "2   [-0.024211615, -0.04941867, 0.0942983, -0.0160...  \n",
              "3   [-0.0042502587, -0.044887587, 0.06716646, 0.02...  \n",
              "4   [-0.016824858, -0.011649432, 0.100801155, -0.0...  \n",
              "..                                                ...  \n",
              "94  [-0.011202576, -0.030689226, 0.08444457, 0.012...  \n",
              "95  [0.004627814, -0.003055276, 0.09976651, 0.0032...  \n",
              "96  [-0.0042502587, -0.044887587, 0.06716646, 0.02...  \n",
              "97  [-0.0075420453, -0.032993905, 0.0986156, 0.018...  \n",
              "98  [-0.0011090297, 0.014553873, 0.06476017, 0.029...  \n",
              "\n",
              "[99 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63695255-dec3-43ea-8b92-759fe89546d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned_tweets</th>\n",
              "      <th>sent_vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is so...</td>\n",
              "      <td>USER when a father is dysfunctional and is so ...</td>\n",
              "      <td>[-0.014220357, -0.008476666, 0.08933757, 0.003...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>USER USER thanks for lyft credit i cannot use ...</td>\n",
              "      <td>[-0.0136345625, -0.04320838, 0.083086476, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>[-0.024211615, -0.04941867, 0.0942983, -0.0160...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model i love u take with u all the time in ur...</td>\n",
              "      <td>model i love u take with u all the time in urã...</td>\n",
              "      <td>[-0.0042502587, -0.044887587, 0.06716646, 0.02...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now #motivation</td>\n",
              "      <td>factsguide society now motivation</td>\n",
              "      <td>[-0.016824858, -0.011649432, 0.100801155, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>0</td>\n",
              "      <td>omg!!! loving this station!!! way to jam out a...</td>\n",
              "      <td>omg loving this station way to jam out at work...</td>\n",
              "      <td>[-0.011202576, -0.030689226, 0.08444457, 0.012...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0</td>\n",
              "      <td>@user i'll always hope that one day i'll get t...</td>\n",
              "      <td>USER i'll always hope that one day i'll get to...</td>\n",
              "      <td>[0.004627814, -0.003055276, 0.09976651, 0.0032...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0</td>\n",
              "      <td>#model i love u take with u all the time in ur...</td>\n",
              "      <td>model i love u take with u all the time in urã...</td>\n",
              "      <td>[-0.0042502587, -0.044887587, 0.06716646, 0.02...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0</td>\n",
              "      <td>couple having sex fat naked japanese girls</td>\n",
              "      <td>couple having sex fat naked japanese girls</td>\n",
              "      <td>[-0.0075420453, -0.032993905, 0.0986156, 0.018...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0</td>\n",
              "      <td>#hump on that #hump day #humpersÃ°ÂŸÂ˜Â© @ edw...</td>\n",
              "      <td>hump on that hump day humpersã°âÿâ˜â© @ edward...</td>\n",
              "      <td>[-0.0011090297, 0.014553873, 0.06476017, 0.029...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63695255-dec3-43ea-8b92-759fe89546d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63695255-dec3-43ea-8b92-759fe89546d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63695255-dec3-43ea-8b92-759fe89546d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(pickle_filepath):\n",
        "  data = pickle.load(open(pickle_filepath,'rb'))\n",
        "  \n",
        "  X = np.array(list(data.sent_vec.apply(lambda x: list(x)).values))\n",
        "  \n",
        "  return X, data.label.values"
      ],
      "metadata": {
        "id": "X6kn2LWcX4bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest, ytest = prepare_data(\"twitter-test-data-new.pkl\")"
      ],
      "metadata": {
        "id": "CUe_DpZ6X4bP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest.shape, ytest.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01aae51e-8c78-4aa3-908e-aa57a35e1ef7",
        "id": "cRBmN_ANX4bQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((99, 300), (99,))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del fasttext_emb"
      ],
      "metadata": {
        "id": "S6fB8gbvX4bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test models"
      ],
      "metadata": {
        "id": "mQh0jgkIX4bS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/file/d/16RTmAYGJ-FWRJ1R_oYcNE-3opdopb37X/view --fuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04746a6-68cc-4c75-f18c-b5ce22c5acce",
        "id": "bjrj8ui-X4bT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16RTmAYGJ-FWRJ1R_oYcNE-3opdopb37X\n",
            "To: /content/models.rar\n",
            "100% 116M/116M [00:01<00:00, 72.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models\n",
        "!unrar e models.rar /content/models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3456b136-768a-4d1b-b603-051f0629b09e",
        "id": "sQMY5TZxX4bU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from models.rar\n",
            "\n",
            "Extracting  /content/models/finaldata_random_forest.joblib               \b\b\b\b  3%\b\b\b\b  7%\b\b\b\b 10%\b\b\b\b 14%\b\b\b\b 18%\b\b\b\b 21%\b\b\b\b 25%\b\b\b\b 28%\b\b\b\b 32%\b\b\b\b 36%\b\b\b\b 39%\b\b\b\b 43%\b\b\b\b 46%\b\b\b\b 50%\b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_random_forest_undersampled.joblib     \b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_xgboost_model.json                 \b\b\b\b 60%\b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_xgboost_model_undersampled.json     \b\b\b\b 67%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_xgboost_model_undersampled.joblib     \b\b\b\b 75%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_xgboost_model.pkl                  \b\b\b\b 83%\b\b\b\b 85%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_xgboost_model.joblib               \b\b\b\b 89%\b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/finaldata_xgboost_model_undersampled.pkl     \b\b\b\b 95%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "U0Yf9K6vX4bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "SSD8vorYX4bW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = joblib.load(\"/content/models/finaldata_random_forest.joblib\")"
      ],
      "metadata": {
        "id": "ACDlBMmkX4bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = rf.predict(Xtest)\n",
        "# print(classification_report(ytest, predictions)) #Random forest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "48067908-93e2-409e-ab43-7210fb483603",
        "id": "Sq2BMKXsX4bY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-f17115e751e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Random forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2114\u001b[0m         \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf = pd.DataFrame()"
      ],
      "metadata": {
        "id": "NdW_JUIQX4ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['Random Forest'] = predictions"
      ],
      "metadata": {
        "id": "0HPXDQDRX4ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest - Undersampled"
      ],
      "metadata": {
        "id": "3NOvEUtOX4bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = joblib.load(\"/content/models/finaldata_random_forest_undersampled.joblib\")"
      ],
      "metadata": {
        "id": "uxiE-pv8X4bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = rf.predict(Xtest)\n",
        "# print(classification_report(ytest, predictions)) #Random forest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "dec3ad90-5fa6-4946-ce25-aafbd6522f30",
        "id": "dYPWd8SPX4bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-f17115e751e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Random forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2114\u001b[0m         \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['Random Forest - Undersampled'] = predictions"
      ],
      "metadata": {
        "id": "ZKe1KJLQX4bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "EzZagPUZX4be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = joblib.load(\"/content/models/finaldata_xgboost_model.joblib\")"
      ],
      "metadata": {
        "id": "KlfghBxwX4be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = xgb_model.predict(Xtest)\n",
        "# print(classification_report(ytest, predictions)) #xgboost"
      ],
      "metadata": {
        "id": "hIJFGb0rX4bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['XGBoost'] = predictions"
      ],
      "metadata": {
        "id": "SEOpdnZaX4bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost - Undersampled"
      ],
      "metadata": {
        "id": "Wv6JTiZRX4bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = joblib.load(\"/content/models/finaldata_xgboost_model_undersampled.joblib\")"
      ],
      "metadata": {
        "id": "NHrhqJiIX4bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = xgb_model.predict(Xtest)\n",
        "# print(classification_report(ytest, predictions)) #xgboost"
      ],
      "metadata": {
        "id": "I3XetaWHX4bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['XGBoost - Undersampled'] = predictions"
      ],
      "metadata": {
        "id": "gU9QtA1pX4bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "af3b7cab-a7e3-428e-a1d7-f97d295129aa",
        "id": "bzczApxSX4bj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Random Forest Random Forest - Undersampled   XGBoost XGBoost - Undersampled\n",
              "0       NEGATIVE                     NEGATIVE  NEGATIVE               NEGATIVE\n",
              "1        NEUTRAL                      NEUTRAL  NEGATIVE               NEGATIVE\n",
              "2        NEUTRAL                      NEUTRAL  POSITIVE               POSITIVE\n",
              "3        NEUTRAL                      NEUTRAL   NEUTRAL               POSITIVE\n",
              "4        NEUTRAL                      NEUTRAL   NEUTRAL                NEUTRAL\n",
              "..           ...                          ...       ...                    ...\n",
              "94      POSITIVE                     POSITIVE  POSITIVE               POSITIVE\n",
              "95       NEUTRAL                     NEGATIVE  POSITIVE               POSITIVE\n",
              "96       NEUTRAL                      NEUTRAL   NEUTRAL               POSITIVE\n",
              "97       NEUTRAL                     NEGATIVE  NEGATIVE               NEGATIVE\n",
              "98       NEUTRAL                      NEUTRAL   NEUTRAL                NEUTRAL\n",
              "\n",
              "[99 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c2678d1-bd97-46b4-8a5e-3d254003e6b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>Random Forest - Undersampled</th>\n",
              "      <th>XGBoost</th>\n",
              "      <th>XGBoost - Undersampled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c2678d1-bd97-46b4-8a5e-3d254003e6b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c2678d1-bd97-46b4-8a5e-3d254003e6b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c2678d1-bd97-46b4-8a5e-3d254003e6b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERTweet"
      ],
      "metadata": {
        "id": "Pn7JZ6eTX4bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pickle.load(open(\"/content/twitter-test-data-new.pkl\", \"rb\"))\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "27e01de3-5ad3-4b8a-e2f8-e157d1be67a7",
        "id": "IurarxebX4bl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    label                                              tweet  \\\n",
              "0       0  @user when a father is dysfunctional and is so...   \n",
              "1       0  @user @user thanks for #lyft credit i can't us...   \n",
              "2       0                                bihday your majesty   \n",
              "3       0  #model i love u take with u all the time in ur...   \n",
              "4       0                factsguide: society now #motivation   \n",
              "..    ...                                                ...   \n",
              "94      0  omg!!! loving this station!!! way to jam out a...   \n",
              "95      0  @user i'll always hope that one day i'll get t...   \n",
              "96      0  #model i love u take with u all the time in ur...   \n",
              "97      0         couple having sex fat naked japanese girls   \n",
              "98      0  #hump on that #hump day #humpersÃ°ÂŸÂ˜Â© @ edw...   \n",
              "\n",
              "                                       cleaned_tweets  \\\n",
              "0   USER when a father is dysfunctional and is so ...   \n",
              "1   USER USER thanks for lyft credit i cannot use ...   \n",
              "2                                 bihday your majesty   \n",
              "3   model i love u take with u all the time in urã...   \n",
              "4                   factsguide society now motivation   \n",
              "..                                                ...   \n",
              "94  omg loving this station way to jam out at work...   \n",
              "95  USER i'll always hope that one day i'll get to...   \n",
              "96  model i love u take with u all the time in urã...   \n",
              "97         couple having sex fat naked japanese girls   \n",
              "98  hump on that hump day humpersã°âÿâ˜â© @ edward...   \n",
              "\n",
              "                                             sent_vec  \n",
              "0   [-0.014220357, -0.008476666, 0.08933757, 0.003...  \n",
              "1   [-0.0136345625, -0.04320838, 0.083086476, -0.0...  \n",
              "2   [-0.024211615, -0.04941867, 0.0942983, -0.0160...  \n",
              "3   [-0.0042502587, -0.044887587, 0.06716646, 0.02...  \n",
              "4   [-0.016824858, -0.011649432, 0.100801155, -0.0...  \n",
              "..                                                ...  \n",
              "94  [-0.011202576, -0.030689226, 0.08444457, 0.012...  \n",
              "95  [0.004627814, -0.003055276, 0.09976651, 0.0032...  \n",
              "96  [-0.0042502587, -0.044887587, 0.06716646, 0.02...  \n",
              "97  [-0.0075420453, -0.032993905, 0.0986156, 0.018...  \n",
              "98  [-0.0011090297, 0.014553873, 0.06476017, 0.029...  \n",
              "\n",
              "[99 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c6626d8-bcd6-48b7-a318-c1f9b3f82771\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned_tweets</th>\n",
              "      <th>sent_vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is so...</td>\n",
              "      <td>USER when a father is dysfunctional and is so ...</td>\n",
              "      <td>[-0.014220357, -0.008476666, 0.08933757, 0.003...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>USER USER thanks for lyft credit i cannot use ...</td>\n",
              "      <td>[-0.0136345625, -0.04320838, 0.083086476, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>[-0.024211615, -0.04941867, 0.0942983, -0.0160...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model i love u take with u all the time in ur...</td>\n",
              "      <td>model i love u take with u all the time in urã...</td>\n",
              "      <td>[-0.0042502587, -0.044887587, 0.06716646, 0.02...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now #motivation</td>\n",
              "      <td>factsguide society now motivation</td>\n",
              "      <td>[-0.016824858, -0.011649432, 0.100801155, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>0</td>\n",
              "      <td>omg!!! loving this station!!! way to jam out a...</td>\n",
              "      <td>omg loving this station way to jam out at work...</td>\n",
              "      <td>[-0.011202576, -0.030689226, 0.08444457, 0.012...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0</td>\n",
              "      <td>@user i'll always hope that one day i'll get t...</td>\n",
              "      <td>USER i'll always hope that one day i'll get to...</td>\n",
              "      <td>[0.004627814, -0.003055276, 0.09976651, 0.0032...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0</td>\n",
              "      <td>#model i love u take with u all the time in ur...</td>\n",
              "      <td>model i love u take with u all the time in urã...</td>\n",
              "      <td>[-0.0042502587, -0.044887587, 0.06716646, 0.02...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0</td>\n",
              "      <td>couple having sex fat naked japanese girls</td>\n",
              "      <td>couple having sex fat naked japanese girls</td>\n",
              "      <td>[-0.0075420453, -0.032993905, 0.0986156, 0.018...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0</td>\n",
              "      <td>#hump on that #hump day #humpersÃ°ÂŸÂ˜Â© @ edw...</td>\n",
              "      <td>hump on that hump day humpersã°âÿâ˜â© @ edward...</td>\n",
              "      <td>[-0.0011090297, 0.014553873, 0.06476017, 0.029...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c6626d8-bcd6-48b7-a318-c1f9b3f82771')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c6626d8-bcd6-48b7-a318-c1f9b3f82771 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c6626d8-bcd6-48b7-a318-c1f9b3f82771');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['BERTweet'] = data['cleaned_tweets'].apply(sa1.inference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e2d774b-3832-4f0c-e28a-d67f85df4032",
        "id": "MDta6KGxX4bl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(classification_report(ytest, testdf['BERTweet'].values)) #BERtweet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c8c999f-646f-4efd-e56b-183b5ddd30ed",
        "id": "8lkDlOYkX4bm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.50      0.60      0.55        20\n",
            "     NEUTRAL       0.21      0.21      0.21        14\n",
            "    POSITIVE       0.83      0.71      0.77        28\n",
            "\n",
            "    accuracy                           0.56        62\n",
            "   macro avg       0.52      0.51      0.51        62\n",
            "weighted avg       0.59      0.56      0.57        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT base"
      ],
      "metadata": {
        "id": "p94cyb_6X4bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['bert-base-multilingual-uncased-sentiment_clean'] = data['cleaned_tweets'].apply(sa2.inference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ade479b4-f9ca-40e9-d22a-c35a615fd3a2",
        "id": "sFOIHSkeX4bo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(classification_report(ytest, testdf['bert-base-multilingual-uncased-sentiment_clean'].values)) #BERT Base"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d58e23-98f4-428f-eea8-ef8e845e0165",
        "id": "nwkl37MzX4bp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.52      0.70      0.60        20\n",
            "     NEUTRAL       1.00      0.07      0.13        14\n",
            "    POSITIVE       0.71      0.86      0.77        28\n",
            "\n",
            "    accuracy                           0.63        62\n",
            "   macro avg       0.74      0.54      0.50        62\n",
            "weighted avg       0.71      0.63      0.57        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf['tweet'] = data['tweet']\n",
        "testdf['label'] = data['label']\n",
        "\n",
        "testdf['cleaned_tweets'] = data['cleaned_tweets']\n",
        "\n",
        "testdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "outputId": "db53ce53-77a2-4859-de0b-ec470451a9d4",
        "id": "_Aul9hDAX4bq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Random Forest Random Forest - Undersampled   XGBoost  \\\n",
              "0       NEGATIVE                     NEGATIVE  NEGATIVE   \n",
              "1        NEUTRAL                      NEUTRAL  NEGATIVE   \n",
              "2        NEUTRAL                      NEUTRAL  POSITIVE   \n",
              "3        NEUTRAL                      NEUTRAL   NEUTRAL   \n",
              "4        NEUTRAL                      NEUTRAL   NEUTRAL   \n",
              "..           ...                          ...       ...   \n",
              "94      POSITIVE                     POSITIVE  POSITIVE   \n",
              "95       NEUTRAL                     NEGATIVE  POSITIVE   \n",
              "96       NEUTRAL                      NEUTRAL   NEUTRAL   \n",
              "97       NEUTRAL                     NEGATIVE  NEGATIVE   \n",
              "98       NEUTRAL                      NEUTRAL   NEUTRAL   \n",
              "\n",
              "   XGBoost - Undersampled  BERTweet  \\\n",
              "0                NEGATIVE  NEGATIVE   \n",
              "1                NEGATIVE  NEGATIVE   \n",
              "2                POSITIVE  POSITIVE   \n",
              "3                POSITIVE  POSITIVE   \n",
              "4                 NEUTRAL   NEUTRAL   \n",
              "..                    ...       ...   \n",
              "94               POSITIVE  POSITIVE   \n",
              "95               POSITIVE   NEUTRAL   \n",
              "96               POSITIVE  POSITIVE   \n",
              "97               NEGATIVE   NEUTRAL   \n",
              "98                NEUTRAL   NEUTRAL   \n",
              "\n",
              "   bert-base-multilingual-uncased-sentiment_clean  \\\n",
              "0                                        NEGATIVE   \n",
              "1                                        NEGATIVE   \n",
              "2                                        POSITIVE   \n",
              "3                                        POSITIVE   \n",
              "4                                        POSITIVE   \n",
              "..                                            ...   \n",
              "94                                       POSITIVE   \n",
              "95                                        NEUTRAL   \n",
              "96                                       POSITIVE   \n",
              "97                                       NEGATIVE   \n",
              "98                                       POSITIVE   \n",
              "\n",
              "                                                tweet  label  \\\n",
              "0   @user when a father is dysfunctional and is so...      0   \n",
              "1   @user @user thanks for #lyft credit i can't us...      0   \n",
              "2                                 bihday your majesty      0   \n",
              "3   #model i love u take with u all the time in ur...      0   \n",
              "4                 factsguide: society now #motivation      0   \n",
              "..                                                ...    ...   \n",
              "94  omg!!! loving this station!!! way to jam out a...      0   \n",
              "95  @user i'll always hope that one day i'll get t...      0   \n",
              "96  #model i love u take with u all the time in ur...      0   \n",
              "97         couple having sex fat naked japanese girls      0   \n",
              "98  #hump on that #hump day #humpersÃ°ÂŸÂ˜Â© @ edw...      0   \n",
              "\n",
              "                                       cleaned_tweets  \n",
              "0   USER when a father is dysfunctional and is so ...  \n",
              "1   USER USER thanks for lyft credit i cannot use ...  \n",
              "2                                 bihday your majesty  \n",
              "3   model i love u take with u all the time in urã...  \n",
              "4                   factsguide society now motivation  \n",
              "..                                                ...  \n",
              "94  omg loving this station way to jam out at work...  \n",
              "95  USER i'll always hope that one day i'll get to...  \n",
              "96  model i love u take with u all the time in urã...  \n",
              "97         couple having sex fat naked japanese girls  \n",
              "98  hump on that hump day humpersã°âÿâ˜â© @ edward...  \n",
              "\n",
              "[99 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24ece09a-0f94-4e88-84e2-fa991a221414\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>Random Forest - Undersampled</th>\n",
              "      <th>XGBoost</th>\n",
              "      <th>XGBoost - Undersampled</th>\n",
              "      <th>BERTweet</th>\n",
              "      <th>bert-base-multilingual-uncased-sentiment_clean</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>@user when a father is dysfunctional and is so...</td>\n",
              "      <td>0</td>\n",
              "      <td>USER when a father is dysfunctional and is so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>0</td>\n",
              "      <td>USER USER thanks for lyft credit i cannot use ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>#model i love u take with u all the time in ur...</td>\n",
              "      <td>0</td>\n",
              "      <td>model i love u take with u all the time in urã...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>factsguide: society now #motivation</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide society now motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>omg!!! loving this station!!! way to jam out a...</td>\n",
              "      <td>0</td>\n",
              "      <td>omg loving this station way to jam out at work...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>@user i'll always hope that one day i'll get t...</td>\n",
              "      <td>0</td>\n",
              "      <td>USER i'll always hope that one day i'll get to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>#model i love u take with u all the time in ur...</td>\n",
              "      <td>0</td>\n",
              "      <td>model i love u take with u all the time in urã...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>couple having sex fat naked japanese girls</td>\n",
              "      <td>0</td>\n",
              "      <td>couple having sex fat naked japanese girls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>#hump on that #hump day #humpersÃ°ÂŸÂ˜Â© @ edw...</td>\n",
              "      <td>0</td>\n",
              "      <td>hump on that hump day humpersã°âÿâ˜â© @ edward...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24ece09a-0f94-4e88-84e2-fa991a221414')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24ece09a-0f94-4e88-84e2-fa991a221414 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24ece09a-0f94-4e88-84e2-fa991a221414');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdf.to_excel(\"twitter-sample-data-results-new.xlsx\")"
      ],
      "metadata": {
        "id": "ik3AKBsFX4br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./test-predictions-undersampled.pkl\",\"wb\") as f:\n",
        "  pickle.dump(testdf, f)"
      ],
      "metadata": {
        "id": "EyHfiIS0X4br"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Sentiment-classification",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}